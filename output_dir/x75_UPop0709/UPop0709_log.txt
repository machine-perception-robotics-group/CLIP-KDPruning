| distributed init (rank 2, word 4): env://
| distributed init (rank 3, word 4): env://
| distributed init (rank 1, word 4): env://
| distributed init (rank 0, word 4): env://
node06:18919:18919 [0] NCCL INFO Bootstrap : Using eno1:192.168.170.56<0>
node06:18919:18919 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node06:18919:18919 [0] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.56<0> [1]eno2:10.0.0.6<0> [2]vethe80d3bc:fe80::70d3:caff:fef1:8721%vethe80d3bc<0>
node06:18919:18919 [0] NCCL INFO Using network Socket
NCCL version 2.10.3+cuda11.3
node06:18921:18921 [2] NCCL INFO Bootstrap : Using eno1:192.168.170.56<0>
node06:18920:18920 [1] NCCL INFO Bootstrap : Using eno1:192.168.170.56<0>
node06:18921:18921 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node06:18921:18921 [2] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.56<0> [1]eno2:10.0.0.6<0> [2]vethe80d3bc:fe80::70d3:caff:fef1:8721%vethe80d3bc<0>
node06:18921:18921 [2] NCCL INFO Using network Socket
node06:18920:18920 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node06:18920:18920 [1] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.56<0> [1]eno2:10.0.0.6<0> [2]vethe80d3bc:fe80::70d3:caff:fef1:8721%vethe80d3bc<0>
node06:18920:18920 [1] NCCL INFO Using network Socket
node06:18922:18922 [3] NCCL INFO Bootstrap : Using eno1:192.168.170.56<0>
node06:18922:18922 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node06:18922:18922 [3] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.56<0> [1]eno2:10.0.0.6<0> [2]vethe80d3bc:fe80::70d3:caff:fef1:8721%vethe80d3bc<0>
node06:18922:18922 [3] NCCL INFO Using network Socket
node06:18922:18978 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
node06:18919:18975 [0] NCCL INFO Channel 00/02 :    0   1   2   3
node06:18919:18975 [0] NCCL INFO Channel 01/02 :    0   1   2   3
node06:18919:18975 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
node06:18919:18975 [0] NCCL INFO Setting affinity for GPU 0 to ffff,00000000,0000ffff
node06:18920:18977 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
node06:18920:18977 [1] NCCL INFO Setting affinity for GPU 1 to ffff,00000000,0000ffff
node06:18921:18976 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
node06:18922:18978 [3] NCCL INFO Channel 00 : 3[b8000] -> 0[27000] via direct shared memory
node06:18922:18978 [3] NCCL INFO Channel 01 : 3[b8000] -> 0[27000] via direct shared memory
node06:18920:18977 [1] NCCL INFO Channel 00 : 1[38000] -> 2[a8000] via direct shared memory
node06:18921:18976 [2] NCCL INFO Channel 00 : 2[a8000] -> 3[b8000] via direct shared memory
node06:18920:18977 [1] NCCL INFO Channel 01 : 1[38000] -> 2[a8000] via direct shared memory
node06:18921:18976 [2] NCCL INFO Channel 01 : 2[a8000] -> 3[b8000] via direct shared memory
node06:18919:18975 [0] NCCL INFO Channel 00 : 0[27000] -> 1[38000] via direct shared memory
node06:18919:18975 [0] NCCL INFO Channel 01 : 0[27000] -> 1[38000] via direct shared memory
node06:18921:18976 [2] NCCL INFO Connected all rings
node06:18920:18977 [1] NCCL INFO Connected all rings
node06:18919:18975 [0] NCCL INFO Connected all rings
node06:18922:18978 [3] NCCL INFO Connected all rings
node06:18922:18978 [3] NCCL INFO Channel 00 : 3[b8000] -> 2[a8000] via direct shared memory
node06:18922:18978 [3] NCCL INFO Channel 01 : 3[b8000] -> 2[a8000] via direct shared memory
node06:18921:18976 [2] NCCL INFO Channel 00 : 2[a8000] -> 1[38000] via direct shared memory
node06:18921:18976 [2] NCCL INFO Channel 01 : 2[a8000] -> 1[38000] via direct shared memory
node06:18920:18977 [1] NCCL INFO Channel 00 : 1[38000] -> 0[27000] via direct shared memory
node06:18920:18977 [1] NCCL INFO Channel 01 : 1[38000] -> 0[27000] via direct shared memory
node06:18922:18978 [3] NCCL INFO Connected all trees
node06:18922:18978 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node06:18922:18978 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node06:18919:18975 [0] NCCL INFO Connected all trees
node06:18919:18975 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node06:18919:18975 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node06:18921:18976 [2] NCCL INFO Connected all trees
node06:18921:18976 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node06:18921:18976 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node06:18920:18977 [1] NCCL INFO Connected all trees
node06:18920:18977 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node06:18920:18977 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node06:18919:18975 [0] NCCL INFO comm 0x79c80c003070 rank 0 nranks 4 cudaDev 0 busId 27000 - Init COMPLETE
node06:18920:18977 [1] NCCL INFO comm 0x7004d8003070 rank 1 nranks 4 cudaDev 1 busId 38000 - Init COMPLETE
node06:18921:18976 [2] NCCL INFO comm 0x7ac3a4003070 rank 2 nranks 4 cudaDev 2 busId a8000 - Init COMPLETE
node06:18922:18978 [3] NCCL INFO comm 0x7f3814003070 rank 3 nranks 4 cudaDev 3 busId b8000 - Init COMPLETE
node06:18919:18919 [0] NCCL INFO Launch mode Parallel
Target compression ratio: 75.0%
Creating retrieval dataset
Using downloaded and verified file: annotation/coco_karpathy_train.json
Using downloaded and verified file: annotation/coco_karpathy_val.json
Using downloaded and verified file: annotation/coco_karpathy_test.json
Creating model for searching
VisionTransformerを作成
VisionTransformerを作成
teacher_model evaluation
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.374625521246344e-05
max_val 5.06649594171904e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.521767575875856e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.579863187042065e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
do itm_eval
test_result_teacher {'txt_r1': 71.48, 'txt_r5': 90.82, 'txt_r10': 95.42, 'txt_r_mean': 85.90666666666668, 'img_r1': 56.80127948820472, 'img_r5': 80.57976809276289, 'img_r10': 87.64894042383047, 'img_r_mean': 75.00999600159936, 'r_mean': 80.45833133413302}
KD False
Start searching
KD:False
Current compression ratio of attn:  tensor(0., device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0., device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  5.543308009082199e-06
Search Epoch: [0]  [    0/23614]  eta: 9:22:07  lr: 0.00001000  loss: 17.4508  loss_ita: 3.9340  loss_sp_attn: 6.7584  loss_sp_mlp: 6.7584  time: 1.4283  data: 0.4604  max mem: 21650
KD is False
Current compression ratio of attn:  tensor(2.5630e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(6.5565e-07, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0011142046580675021
Current compression ratio of attn:  tensor(8.8811e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(4.8280e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0022228635726734133
Current compression ratio of attn:  tensor(1.9252e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(1.1504e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0033315176300535753
Current compression ratio of attn:  tensor(3.6001e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(1.9610e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.004440164407657824
Current compression ratio of attn:  tensor(5.1379e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(3.4630e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.005548801482967812
Current compression ratio of attn:  tensor(7.7128e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(4.6551e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0066574264334748005
Current compression ratio of attn:  tensor(9.8884e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(6.9082e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.007766036836697048
Current compression ratio of attn:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(8.2016e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.008874630270188132
Current compression ratio of attn:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.00998320431153695
Current compression ratio of attn:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01109175653837371
Current compression ratio of attn:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01220028452837808
Current compression ratio of attn:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.013308785859282368
Current compression ratio of attn:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.014417258108876754
Current compression ratio of attn:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.015525698855014536
Current compression ratio of attn:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01663410567561832
Current compression ratio of attn:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.017742476148685883
Current compression ratio of attn:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.018850807852292463
Current compression ratio of attn:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.019959098364599588
Current compression ratio of attn:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.021067345263857545
Current compression ratio of attn:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.022175546128412927
Current compression ratio of attn:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0008, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.023283698536712187
Current compression ratio of attn:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.024391800067308865
Current compression ratio of attn:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.02549984829886539
Current compression ratio of attn:  tensor(0.0008, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.026607840810163978
Current compression ratio of attn:  tensor(0.0009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.027715775180104932
Search Epoch: [0]  [ 5000/23614]  eta: 3:33:54  lr: 0.00001000  loss: 16.6640  loss_ita: 3.1596  loss_sp_attn: 6.7529  loss_sp_mlp: 6.7515  time: 0.6898  data: 0.0001  max mem: 26576
Current compression ratio of attn:  tensor(0.0010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.028823648987717908
Current compression ratio of attn:  tensor(0.0010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.029931459812165072
Current compression ratio of attn:  tensor(0.0011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.031039205232744744
Current compression ratio of attn:  tensor(0.0012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0015, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.032146882828899215
Current compression ratio of attn:  tensor(0.0012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.033254490180218844
Current compression ratio of attn:  tensor(0.0013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03436202486644678
Current compression ratio of attn:  tensor(0.0014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03546948446748646
Current compression ratio of attn:  tensor(0.0015, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.036576866563403185
Current compression ratio of attn:  tensor(0.0016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0021, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.037684168734433754
Current compression ratio of attn:  tensor(0.0017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03879138856098856
Current compression ratio of attn:  tensor(0.0019, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.039898523623658144
Current compression ratio of attn:  tensor(0.0020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04100557150321799
Current compression ratio of attn:  tensor(0.0021, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.042112529780634525
Current compression ratio of attn:  tensor(0.0023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0026, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04321939603706959
Current compression ratio of attn:  tensor(0.0024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0027, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0443261678538861
Current compression ratio of attn:  tensor(0.0025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04543284281265395
Current compression ratio of attn:  tensor(0.0027, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04653941849515391
Current compression ratio of attn:  tensor(0.0029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0031, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04764589248338426
Current compression ratio of attn:  tensor(0.0030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04875226235956505
Current compression ratio of attn:  tensor(0.0032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0498585257061438
Current compression ratio of attn:  tensor(0.0032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05096468010580133
Current compression ratio of attn:  tensor(0.0034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0037, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05207072314145622
Current compression ratio of attn:  tensor(0.0035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.053176652396270396
Current compression ratio of attn:  tensor(0.0038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0040, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.054282465453654435
Current compression ratio of attn:  tensor(0.0040, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05538815989727243
Search Epoch: [0]  [10000/23614]  eta: 2:36:28  lr: 0.00001000  loss: 15.7080  loss_ita: 2.2439  loss_sp_attn: 6.7329  loss_sp_mlp: 6.7312  time: 0.6951  data: 0.0001  max mem: 26577
Current compression ratio of attn:  tensor(0.0041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0564937333110484
Current compression ratio of attn:  tensor(0.0042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0045, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05759918327917027
Current compression ratio of attn:  tensor(0.0044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05870450738609585
Current compression ratio of attn:  tensor(0.0048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05980970321655843
Current compression ratio of attn:  tensor(0.0049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06091476835557037
Current compression ratio of attn:  tensor(0.0052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0051, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06201970038843113
Current compression ratio of attn:  tensor(0.0054, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0631244969007301
Current compression ratio of attn:  tensor(0.0057, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0054, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06422915547835281
Current compression ratio of attn:  tensor(0.0059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0056, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06533367370748645
Current compression ratio of attn:  tensor(0.0061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0057, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06643804917462523
Current compression ratio of attn:  tensor(0.0064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06754227946657426
Current compression ratio of attn:  tensor(0.0066, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06864636217045694
Current compression ratio of attn:  tensor(0.0070, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06975029487371878
Current compression ratio of attn:  tensor(0.0072, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0708540751641328
Current compression ratio of attn:  tensor(0.0077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07195770062980542
Current compression ratio of attn:  tensor(0.0078, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07306116885918139
Current compression ratio of attn:  tensor(0.0082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07416447744104854
Current compression ratio of attn:  tensor(0.0085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07526762396454417
Current compression ratio of attn:  tensor(0.0089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07637060601915938
Current compression ratio of attn:  tensor(0.0091, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07747342119474471
Current compression ratio of attn:  tensor(0.0093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07857606708151532
Current compression ratio of attn:  tensor(0.0095, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0078, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07967854127005616
Current compression ratio of attn:  tensor(0.0097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0080, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08078084135132789
Current compression ratio of attn:  tensor(0.0101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08188296491667083
Current compression ratio of attn:  tensor(0.0105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08298490955781171
Search Epoch: [0]  [15000/23614]  eta: 1:39:11  lr: 0.00001000  loss: 16.8962  loss_ita: 3.5033  loss_sp_attn: 6.6899  loss_sp_mlp: 6.7031  time: 0.6987  data: 0.0001  max mem: 26578
Current compression ratio of attn:  tensor(0.0108, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0086, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08408667286686772
Current compression ratio of attn:  tensor(0.0113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08518825243635278
Current compression ratio of attn:  tensor(0.0117, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08628964585918168
Current compression ratio of attn:  tensor(0.0121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0090, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08739085072867661
Current compression ratio of attn:  tensor(0.0125, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08849186463857123
Current compression ratio of attn:  tensor(0.0129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08959268518301684
Current compression ratio of attn:  tensor(0.0133, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0095, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09069330995658728
Current compression ratio of attn:  tensor(0.0137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09179373655428373
Current compression ratio of attn:  tensor(0.0139, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0928939625715408
Current compression ratio of attn:  tensor(0.0144, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0939939856042315
Current compression ratio of attn:  tensor(0.0148, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0104, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09509380324867195
Current compression ratio of attn:  tensor(0.0152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09619341310162738
Current compression ratio of attn:  tensor(0.0157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0107, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0972928127603169
Current compression ratio of attn:  tensor(0.0161, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09839199982241917
Current compression ratio of attn:  tensor(0.0166, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0111, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09949097188607729
Current compression ratio of attn:  tensor(0.0170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1005897265499039
Current compression ratio of attn:  tensor(0.0174, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0116, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10168826141298701
Current compression ratio of attn:  tensor(0.0177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0118, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10278657407489494
Current compression ratio of attn:  tensor(0.0183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0119, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10388466213568115
Current compression ratio of attn:  tensor(0.0189, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10498252319589027
Current compression ratio of attn:  tensor(0.0193, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10608015485656286
Current compression ratio of attn:  tensor(0.0199, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0125, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10717755471924056
Current compression ratio of attn:  tensor(0.0203, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0128, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10827472038597193
Current compression ratio of attn:  tensor(0.0210, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10937164945931675
Current compression ratio of attn:  tensor(0.0215, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0130, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11046833954235236
Search Epoch: [0]  [20000/23614]  eta: 0:41:37  lr: 0.00001000  loss: 16.8233  loss_ita: 3.5350  loss_sp_attn: 6.6168  loss_sp_mlp: 6.6715  time: 0.6854  data: 0.0001  max mem: 26578
Current compression ratio of attn:  tensor(0.0217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11156478823867766
Current compression ratio of attn:  tensor(0.0224, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11266099315241962
Current compression ratio of attn:  tensor(0.0230, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11375695188823756
Current compression ratio of attn:  tensor(0.0236, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0139, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11485266205132884
Current compression ratio of attn:  tensor(0.0243, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11594812124743392
Current compression ratio of attn:  tensor(0.0249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1170433270828416
Current compression ratio of attn:  tensor(0.0253, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0145, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11813827716439465
Current compression ratio of attn:  tensor(0.0260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0146, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11923296909949424
Current compression ratio of attn:  tensor(0.0265, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0149, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12032740049610599
Current compression ratio of attn:  tensor(0.0270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1214215689627645
Current compression ratio of attn:  tensor(0.0276, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0154, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12251547210857903
Current compression ratio of attn:  tensor(0.0284, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0154, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12360910754323876
Current compression ratio of attn:  tensor(0.0290, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0156, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12470247287701762
Current compression ratio of attn:  tensor(0.0297, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0158, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12579556572078
Current compression ratio of attn:  tensor(0.0303, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0161, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1268883836859854
Current compression ratio of attn:  tensor(0.0310, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0162, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1279809243846942
Current compression ratio of attn:  tensor(0.0315, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1290731854295725
Current compression ratio of attn:  tensor(0.0323, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0166, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1301651644338976
Search Epoch: [0]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 16.1729  loss_ita: 2.9869  loss_sp_attn: 6.5400  loss_sp_mlp: 6.6461  time: 0.7046  data: 0.0003  max mem: 26578
Search Epoch: [0] Total time: 4:32:03 (0.6913 s / it)
Averaged stats: lr: 0.0000  loss: 16.2015  loss_ita: 2.7903  loss_sp_attn: 6.6959  loss_sp_mlp: 6.7153
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
do itm_eval
search_result {'txt_r1': 68.02, 'txt_r5': 87.7, 'txt_r10': 92.78, 'txt_r_mean': 82.83333333333333, 'img_r1': 50.699720111955216, 'img_r5': 76.17752898840463, 'img_r10': 84.03838464614154, 'img_r_mean': 70.3052112488338, 'r_mean': 76.56927229108356}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0912
Text_CKA_Similarity: 0.4107
Image_Cosine_Similarity: 0.1849
Image_CKA_Similarity: 0.6474
sim_matrix_pearson_correlation: 0.3728
model_search_0.pth saved
KD:False
Search Epoch: [1]  [    0/23614]  eta: 6:12:29  lr: 0.00001000  loss: 16.1201  loss_ita: 2.9340  loss_sp_attn: 6.5400  loss_sp_mlp: 6.6461  time: 0.9465  data: 0.1952  max mem: 28191
KD is False
Current compression ratio of attn:  tensor(0.0327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13125685901156298
Current compression ratio of attn:  tensor(0.0332, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13234826677708367
Current compression ratio of attn:  tensor(0.0340, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0174, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1334393853456016
Current compression ratio of attn:  tensor(0.0345, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13453021233289025
Current compression ratio of attn:  tensor(0.0352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0180, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13562074535536062
Current compression ratio of attn:  tensor(0.0359, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1367109820300657
Current compression ratio of attn:  tensor(0.0364, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0185, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1378009199747064
Current compression ratio of attn:  tensor(0.0369, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0188, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13889055680763615
Current compression ratio of attn:  tensor(0.0377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13997989014786633
Current compression ratio of attn:  tensor(0.0382, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0193, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1410689176150716
Current compression ratio of attn:  tensor(0.0388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0196, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14215763682959515
Current compression ratio of attn:  tensor(0.0398, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14324604541245328
Current compression ratio of attn:  tensor(0.0403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0201, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14433414098534142
Current compression ratio of attn:  tensor(0.0412, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0202, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14542192117063896
Current compression ratio of attn:  tensor(0.0416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1465093835914143
Current compression ratio of attn:  tensor(0.0425, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0208, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14759652587143018
Current compression ratio of attn:  tensor(0.0431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14868334563514912
Current compression ratio of attn:  tensor(0.0437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0214, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14976984050773812
Current compression ratio of attn:  tensor(0.0443, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1508560081150742
Current compression ratio of attn:  tensor(0.0453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15194184608374958
Current compression ratio of attn:  tensor(0.0462, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0220, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1530273520410766
Current compression ratio of attn:  tensor(0.0466, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0225, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15411252361509317
Current compression ratio of attn:  tensor(0.0474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0227, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15519735843456794
Current compression ratio of attn:  tensor(0.0484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0229, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15628185412900542
Current compression ratio of attn:  tensor(0.0489, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0233, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1573660083286509
Search Epoch: [1]  [ 5000/23614]  eta: 3:34:42  lr: 0.00001000  loss: 15.4157  loss_ita: 2.3866  loss_sp_attn: 6.4279  loss_sp_mlp: 6.6012  time: 0.7014  data: 0.0001  max mem: 28227
Current compression ratio of attn:  tensor(0.0499, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15844981866449628
Current compression ratio of attn:  tensor(0.0505, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0237, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1595332827682845
Current compression ratio of attn:  tensor(0.0512, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0241, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16061639827251514
Current compression ratio of attn:  tensor(0.0521, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0242, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1616991628104497
Current compression ratio of attn:  tensor(0.0528, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0246, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16278157401611626
Current compression ratio of attn:  tensor(0.0535, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16386362952431527
Current compression ratio of attn:  tensor(0.0543, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16494532697062428
Current compression ratio of attn:  tensor(0.0550, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1660266639914033
Current compression ratio of attn:  tensor(0.0560, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16710763822379987
Current compression ratio of attn:  tensor(0.0567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16818824730575416
Current compression ratio of attn:  tensor(0.0578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0261, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16926848887600462
Current compression ratio of attn:  tensor(0.0586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0264, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17034836057409225
Current compression ratio of attn:  tensor(0.0593, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0268, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17142786004036664
Current compression ratio of attn:  tensor(0.0606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0268, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17250698491599056
Current compression ratio of attn:  tensor(0.0614, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0271, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17358573284294548
Current compression ratio of attn:  tensor(0.0623, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0274, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17466410146403633
Current compression ratio of attn:  tensor(0.0629, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0278, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1757420884228971
Current compression ratio of attn:  tensor(0.0634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0283, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17681969136399545
Current compression ratio of attn:  tensor(0.0645, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0284, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1778969079326385
Current compression ratio of attn:  tensor(0.0651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0289, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17897373577497744
Current compression ratio of attn:  tensor(0.0663, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0291, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1800501725380131
Current compression ratio of attn:  tensor(0.0672, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0293, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18112621586960037
Current compression ratio of attn:  tensor(0.0677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0298, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1822018634184544
Current compression ratio of attn:  tensor(0.0689, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0299, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18327711283415482
Current compression ratio of attn:  tensor(0.0700, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18435196176715132
Search Epoch: [1]  [10000/23614]  eta: 2:37:14  lr: 0.00001000  loss: 14.7111  loss_ita: 1.8710  loss_sp_attn: 6.2854  loss_sp_mlp: 6.5547  time: 0.7033  data: 0.0001  max mem: 28227
Current compression ratio of attn:  tensor(0.0708, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0305, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1854264078687689
Current compression ratio of attn:  tensor(0.0716, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0309, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18650044879121244
Current compression ratio of attn:  tensor(0.0725, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18757408218757243
Current compression ratio of attn:  tensor(0.0738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0313, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18864730571182972
Current compression ratio of attn:  tensor(0.0744, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0317, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18972011701886093
Current compression ratio of attn:  tensor(0.0753, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0321, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19079251376444326
Current compression ratio of attn:  tensor(0.0762, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1918644936052598
Current compression ratio of attn:  tensor(0.0778, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0323, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19293605419890486
Current compression ratio of attn:  tensor(0.0789, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19400719320388848
Current compression ratio of attn:  tensor(0.0795, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0331, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19507790827964222
Current compression ratio of attn:  tensor(0.0806, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0333, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19614819708652392
Current compression ratio of attn:  tensor(0.0818, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19721805728582262
Current compression ratio of attn:  tensor(0.0824, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0340, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19828748653976436
Current compression ratio of attn:  tensor(0.0831, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0345, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1993564825115165
Current compression ratio of attn:  tensor(0.0840, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0349, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20042504286519325
Current compression ratio of attn:  tensor(0.0852, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0350, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2014931652658608
Current compression ratio of attn:  tensor(0.0857, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0357, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20256084737954222
Current compression ratio of attn:  tensor(0.0867, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0359, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20362808687322276
Current compression ratio of attn:  tensor(0.0877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0363, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2046948814148547
Current compression ratio of attn:  tensor(0.0887, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0366, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20576122867336266
Current compression ratio of attn:  tensor(0.0898, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0369, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20682712631864875
Current compression ratio of attn:  tensor(0.0907, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0372, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2078925720215974
Current compression ratio of attn:  tensor(0.0917, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0376, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2089575634540805
Current compression ratio of attn:  tensor(0.0936, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0374, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21002209828896282
Current compression ratio of attn:  tensor(0.0947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21108617420010667
Search Epoch: [1]  [15000/23614]  eta: 1:39:30  lr: 0.00001000  loss: 14.1330  loss_ita: 1.5109  loss_sp_attn: 6.1186  loss_sp_mlp: 6.5035  time: 0.6881  data: 0.0001  max mem: 28227
Current compression ratio of attn:  tensor(0.0948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21214978886237731
Current compression ratio of attn:  tensor(0.0960, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21321293995164778
Current compression ratio of attn:  tensor(0.0965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0396, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21427562514480392
Current compression ratio of attn:  tensor(0.0979, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0396, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21533784211975
Current compression ratio of attn:  tensor(0.0987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0402, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21639958855541316
Current compression ratio of attn:  tensor(0.1002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0402, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2174608621317487
Current compression ratio of attn:  tensor(0.1009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0408, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21852166052974534
Current compression ratio of attn:  tensor(0.1023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0409, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21958198143142985
Current compression ratio of attn:  tensor(0.1027, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0417, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22064182251987263
Current compression ratio of attn:  tensor(0.1042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0418, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2217011814791925
Current compression ratio of attn:  tensor(0.1047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0425, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22276005599456172
Current compression ratio of attn:  tensor(0.1069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0421, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22381844375221108
Current compression ratio of attn:  tensor(0.1075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0428, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2248763424394351
Current compression ratio of attn:  tensor(0.1087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.225933749744597
Current compression ratio of attn:  tensor(0.1098, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0434, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22699066335713364
Current compression ratio of attn:  tensor(0.1107, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22804708096756066
Current compression ratio of attn:  tensor(0.1115, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0445, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22910300026747746
Current compression ratio of attn:  tensor(0.1124, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23015841894957256
Current compression ratio of attn:  tensor(0.1136, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23121333470762812
Current compression ratio of attn:  tensor(0.1144, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0459, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23226774523652535
Current compression ratio of attn:  tensor(0.1152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0464, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2333216482322495
Current compression ratio of attn:  tensor(0.1157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0472, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23437504139189486
Current compression ratio of attn:  tensor(0.1169, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23542792241366955
Current compression ratio of attn:  tensor(0.1181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0477, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2364802889969011
Current compression ratio of attn:  tensor(0.1186, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0485, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23753213884204089
Search Epoch: [1]  [20000/23614]  eta: 0:41:45  lr: 0.00001000  loss: 14.7120  loss_ita: 2.3250  loss_sp_attn: 5.9567  loss_sp_mlp: 6.4303  time: 0.6947  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.1201, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0487, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23858346965066946
Current compression ratio of attn:  tensor(0.1194, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0502, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23963427912550184
Current compression ratio of attn:  tensor(0.1215, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24068456497039162
Current compression ratio of attn:  tensor(0.1221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0508, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24173432489033714
Current compression ratio of attn:  tensor(0.1241, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0507, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24278355659148582
Current compression ratio of attn:  tensor(0.1232, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2438322577811391
Current compression ratio of attn:  tensor(0.1239, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0530, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2448804261677578
Current compression ratio of attn:  tensor(0.1245, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0537, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2459280594609669
Current compression ratio of attn:  tensor(0.1269, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0534, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24697515537156084
Current compression ratio of attn:  tensor(0.1270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0544, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2480217116115081
Current compression ratio of attn:  tensor(0.1286, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24906772589395645
Current compression ratio of attn:  tensor(0.1301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0547, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25011319593323783
Current compression ratio of attn:  tensor(0.1310, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0553, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25115811944487365
Current compression ratio of attn:  tensor(0.1303, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0569, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25220249414557927
Current compression ratio of attn:  tensor(0.1316, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0572, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25324631775326945
Current compression ratio of attn:  tensor(0.1305, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0590, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25428958798706314
Current compression ratio of attn:  tensor(0.1339, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25533230256728834
Current compression ratio of attn:  tensor(0.1343, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0590, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2563744592154873
Search Epoch: [1]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 14.4358  loss_ita: 2.2253  loss_sp_attn: 5.8509  loss_sp_mlp: 6.3596  time: 0.6849  data: 0.0003  max mem: 28228
Search Epoch: [1] Total time: 4:32:59 (0.6936 s / it)
Averaged stats: lr: 0.0000  loss: 15.0914  loss_ita: 2.3458  loss_sp_attn: 6.2184  loss_sp_mlp: 6.5271
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
do itm_eval
search_result {'txt_r1': 58.64, 'txt_r5': 83.38, 'txt_r10': 89.9, 'txt_r_mean': 77.30666666666666, 'img_r1': 45.91763294682127, 'img_r5': 72.62295081967213, 'img_r10': 82.01119552179128, 'img_r_mean': 66.8505930960949, 'r_mean': 72.07862988138078}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0977
Text_CKA_Similarity: 0.4990
Image_Cosine_Similarity: 0.1153
Image_CKA_Similarity: 0.6455
sim_matrix_pearson_correlation: 0.2417
model_search_1.pth saved
KD:False
Search Epoch: [2]  [    0/23614]  eta: 6:11:04  lr: 0.00001000  loss: 15.8818  loss_ita: 3.6713  loss_sp_attn: 5.8509  loss_sp_mlp: 6.3596  time: 0.9428  data: 0.1946  max mem: 28228
KD is False
Current compression ratio of attn:  tensor(0.1330, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0609, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2574160556544216
Current compression ratio of attn:  tensor(0.1354, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2584570896080767
Current compression ratio of attn:  tensor(0.1379, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0602, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25949755880166714
Current compression ratio of attn:  tensor(0.1360, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0625, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2605374609616418
Current compression ratio of attn:  tensor(0.1387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0620, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2615767938156883
Current compression ratio of attn:  tensor(0.1388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0632, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2626155550927386
Current compression ratio of attn:  tensor(0.1387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0644, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2636537425229732
Current compression ratio of attn:  tensor(0.1418, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0637, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2646913538378267
Current compression ratio of attn:  tensor(0.1424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0645, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26572838676999283
Current compression ratio of attn:  tensor(0.1431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0653, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26676483905342885
Current compression ratio of attn:  tensor(0.1423, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0669, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2678007084233609
Current compression ratio of attn:  tensor(0.1433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0676, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2688359926162889
Current compression ratio of attn:  tensor(0.1432, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26987068936999126
Current compression ratio of attn:  tensor(0.1463, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0681, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2709047964235304
Current compression ratio of attn:  tensor(0.1440, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0707, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.271938311517257
Current compression ratio of attn:  tensor(0.1475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0697, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2729712323928153
Current compression ratio of attn:  tensor(0.1495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0697, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2740035567931479
Current compression ratio of attn:  tensor(0.1490, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0713, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27503528246250114
Current compression ratio of attn:  tensor(0.1500, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0719, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2760664071464292
Current compression ratio of attn:  tensor(0.1503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0730, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27709692859179963
Current compression ratio of attn:  tensor(0.1532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0722, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2781268445467983
Current compression ratio of attn:  tensor(0.1522, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0742, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27915615276093403
Current compression ratio of attn:  tensor(0.1521, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28018485098504353
Current compression ratio of attn:  tensor(0.1575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28121293697129657
Current compression ratio of attn:  tensor(0.1544, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28224040847320064
Search Epoch: [2]  [ 5000/23614]  eta: 3:34:57  lr: 0.00001000  loss: 14.5579  loss_ita: 2.6024  loss_sp_attn: 5.7152  loss_sp_mlp: 6.2402  time: 0.6817  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.1564, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28326726324560597
Current compression ratio of attn:  tensor(0.1560, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0782, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2842934990447105
Current compression ratio of attn:  tensor(0.1569, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0789, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2853191136280646
Current compression ratio of attn:  tensor(0.1604, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0779, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2863441047545761
Current compression ratio of attn:  tensor(0.1590, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0800, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28736847018451517
Current compression ratio of attn:  tensor(0.1601, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0807, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28839220767951923
Current compression ratio of attn:  tensor(0.1625, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0804, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28941531500259776
Current compression ratio of attn:  tensor(0.1651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0802, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2904377899181372
Current compression ratio of attn:  tensor(0.1648, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0816, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29145963019190596
Current compression ratio of attn:  tensor(0.1662, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0820, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29248083359105925
Current compression ratio of attn:  tensor(0.1637, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0849, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.293501397884144
Current compression ratio of attn:  tensor(0.1698, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0824, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2945213208411032
Current compression ratio of attn:  tensor(0.1662, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0859, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2955406002332819
Current compression ratio of attn:  tensor(0.1711, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0842, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29655923383343086
Current compression ratio of attn:  tensor(0.1705, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0859, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29757721941571247
Current compression ratio of attn:  tensor(0.1707, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2985945547557046
Current compression ratio of attn:  tensor(0.1710, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0882, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29961123763040637
Current compression ratio of attn:  tensor(0.1735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0880, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30062726581824245
Current compression ratio of attn:  tensor(0.1723, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0899, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3016426370990682
Current compression ratio of attn:  tensor(0.1739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0903, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3026573492541742
Current compression ratio of attn:  tensor(0.1745, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30367140006629145
Current compression ratio of attn:  tensor(0.1767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0912, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.304684787319596
Current compression ratio of attn:  tensor(0.1766, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0927, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30569750879971386
Current compression ratio of attn:  tensor(0.1791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0925, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3067095622937261
Current compression ratio of attn:  tensor(0.1797, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0935, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3077209455901728
Search Epoch: [2]  [10000/23614]  eta: 2:37:16  lr: 0.00001000  loss: 13.4891  loss_ita: 1.8183  loss_sp_attn: 5.5440  loss_sp_mlp: 6.1268  time: 0.6986  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.1799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3087316564790591
Current compression ratio of attn:  tensor(0.1805, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0956, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30974169275185925
Current compression ratio of attn:  tensor(0.1827, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0956, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31075105220152144
Current compression ratio of attn:  tensor(0.1838, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0963, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3117597326224731
Current compression ratio of attn:  tensor(0.1817, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0989, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31276773181062517
Current compression ratio of attn:  tensor(0.1839, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0989, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31377504756337726
Current compression ratio of attn:  tensor(0.1845, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0999, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31478167767962234
Current compression ratio of attn:  tensor(0.1866, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1000, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31578761995975174
Current compression ratio of attn:  tensor(0.1844, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1027, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3167928722056595
Current compression ratio of attn:  tensor(0.1878, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3177974322207477
Current compression ratio of attn:  tensor(0.1869, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1040, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.318801297809931
Current compression ratio of attn:  tensor(0.1884, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31980446677964136
Current compression ratio of attn:  tensor(0.1903, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.320806936937833
Current compression ratio of attn:  tensor(0.1926, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3218087060939872
Current compression ratio of attn:  tensor(0.1920, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3228097720591169
Current compression ratio of attn:  tensor(0.1947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32381013264577163
Current compression ratio of attn:  tensor(0.1932, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3248097856680423
Current compression ratio of attn:  tensor(0.1955, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3258087289415659
Current compression ratio of attn:  tensor(0.1984, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1080, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32680696028353023
Current compression ratio of attn:  tensor(0.1965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32780447751267894
Current compression ratio of attn:  tensor(0.1990, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1104, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32880127844931595
Current compression ratio of attn:  tensor(0.1985, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3297973609153103
Current compression ratio of attn:  tensor(0.1964, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1149, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33079272273410126
Current compression ratio of attn:  tensor(0.2010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33178736173070256
Current compression ratio of attn:  tensor(0.1993, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3327812757317074
Search Epoch: [2]  [15000/23614]  eta: 1:39:29  lr: 0.00001000  loss: 14.5254  loss_ita: 3.1393  loss_sp_attn: 5.4113  loss_sp_mlp: 5.9747  time: 0.6951  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.2018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1158, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33377446256529325
Current compression ratio of attn:  tensor(0.2017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1172, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33476692006122655
Current compression ratio of attn:  tensor(0.2046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1169, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33575864605086736
Current compression ratio of attn:  tensor(0.2035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33674963836717414
Current compression ratio of attn:  tensor(0.2044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1198, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3377398948447087
Current compression ratio of attn:  tensor(0.2052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1209, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3387294133196405
Current compression ratio of attn:  tensor(0.2084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1204, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33971819162975186
Current compression ratio of attn:  tensor(0.2084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34070622761444225
Current compression ratio of attn:  tensor(0.2092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34169351911473334
Current compression ratio of attn:  tensor(0.2094, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34268006397327355
Current compression ratio of attn:  tensor(0.2102, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34366586003434274
Current compression ratio of attn:  tensor(0.2124, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1251, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3446509051438571
Current compression ratio of attn:  tensor(0.2138, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34563519714937374
Current compression ratio of attn:  tensor(0.2128, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1277, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3466187339000951
Current compression ratio of attn:  tensor(0.2142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1283, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3476015132468745
Current compression ratio of attn:  tensor(0.2138, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3485835330422198
Current compression ratio of attn:  tensor(0.2187, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1286, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34956479114029865
Current compression ratio of attn:  tensor(0.2187, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35054528539694335
Current compression ratio of attn:  tensor(0.2177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1322, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35152501366965494
Current compression ratio of attn:  tensor(0.2197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1324, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3525039738176086
Current compression ratio of attn:  tensor(0.2172, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1354, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35348216370165764
Current compression ratio of attn:  tensor(0.2211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1345, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3544595811843386
Current compression ratio of attn:  tensor(0.2221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1354, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3554362241298759
Current compression ratio of attn:  tensor(0.2234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1360, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3564120904041863
Current compression ratio of attn:  tensor(0.2254, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1363, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3573871778748837
Search Epoch: [2]  [20000/23614]  eta: 0:41:44  lr: 0.00001000  loss: 14.6339  loss_ita: 3.5621  loss_sp_attn: 5.2348  loss_sp_mlp: 5.8370  time: 0.6972  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.2240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35836148441128385
Current compression ratio of attn:  tensor(0.2273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1381, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3593350078844088
Current compression ratio of attn:  tensor(0.2256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1407, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36030774616699185
Current compression ratio of attn:  tensor(0.2283, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1406, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3612796971334819
Current compression ratio of attn:  tensor(0.2277, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36225085866004836
Current compression ratio of attn:  tensor(0.2300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1426, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3632212286245856
Current compression ratio of attn:  tensor(0.2304, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3641908049067176
Current compression ratio of attn:  tensor(0.2318, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1443, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36515958538780263
Current compression ratio of attn:  tensor(0.2350, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36612756795093804
Current compression ratio of attn:  tensor(0.2360, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1448, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3670947504809646
Current compression ratio of attn:  tensor(0.2337, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1478, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3680611308644712
Current compression ratio of attn:  tensor(0.2356, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36902670698979956
Current compression ratio of attn:  tensor(0.2379, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3699914767470489
Current compression ratio of attn:  tensor(0.2370, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3709554380280803
Current compression ratio of attn:  tensor(0.2389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1505, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37191858872652156
Current compression ratio of attn:  tensor(0.2406, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1512, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37288092673777173
Current compression ratio of attn:  tensor(0.2419, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37384244995900556
Current compression ratio of attn:  tensor(0.2403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1544, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3748031562891783
Search Epoch: [2]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 14.2363  loss_ita: 3.3876  loss_sp_attn: 5.1342  loss_sp_mlp: 5.7146  time: 0.6958  data: 0.0005  max mem: 28228
Search Epoch: [2] Total time: 4:32:47 (0.6931 s / it)
Averaged stats: lr: 0.0000  loss: 14.5880  loss_ita: 3.0272  loss_sp_attn: 5.4979  loss_sp_mlp: 6.0629
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
do itm_eval
search_result {'txt_r1': 46.88, 'txt_r5': 72.76, 'txt_r10': 82.24, 'txt_r_mean': 67.29333333333334, 'img_r1': 27.53298680527789, 'img_r5': 52.29908036785286, 'img_r10': 63.79048380647741, 'img_r_mean': 47.87418365986938, 'r_mean': 57.58375849660136}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0538
Text_CKA_Similarity: 0.4053
Image_Cosine_Similarity: 0.0799
Image_CKA_Similarity: 0.6428
sim_matrix_pearson_correlation: 0.3139
model_search_2.pth saved
KD:False
Search Epoch: [3]  [    0/23614]  eta: 5:55:20  lr: 0.00001000  loss: 14.5637  loss_ita: 3.7150  loss_sp_attn: 5.1342  loss_sp_mlp: 5.7146  time: 0.9029  data: 0.1954  max mem: 28228
KD is False
Current compression ratio of attn:  tensor(0.2431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3757630436290303
Current compression ratio of attn:  tensor(0.2444, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1551, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3767221098810912
Current compression ratio of attn:  tensor(0.2450, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1563, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37768035294968505
Current compression ratio of attn:  tensor(0.2450, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3786377707409347
Current compression ratio of attn:  tensor(0.2465, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1584, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3795943611627661
Current compression ratio of attn:  tensor(0.2467, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1599, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3805501221249134
Current compression ratio of attn:  tensor(0.2475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38150505153892295
Current compression ratio of attn:  tensor(0.2517, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1599, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3824591473181583
Current compression ratio of attn:  tensor(0.2501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1625, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38341240737780447
Current compression ratio of attn:  tensor(0.2511, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38436482963487295
Current compression ratio of attn:  tensor(0.2513, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1648, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38531641200820543
Current compression ratio of attn:  tensor(0.2521, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1660, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3862671524184791
Current compression ratio of attn:  tensor(0.2534, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1667, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38721704878821095
Current compression ratio of attn:  tensor(0.2529, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38816609904176236
Current compression ratio of attn:  tensor(0.2545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1693, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3891143011053435
Current compression ratio of attn:  tensor(0.2548, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1707, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39006165290701783
Current compression ratio of attn:  tensor(0.2559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1715, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3910081523767071
Current compression ratio of attn:  tensor(0.2572, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1724, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3919537974461951
Current compression ratio of attn:  tensor(0.2574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39289858604913264
Current compression ratio of attn:  tensor(0.2580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1751, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39384251612104226
Current compression ratio of attn:  tensor(0.2584, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1764, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3947855855993223
Current compression ratio of attn:  tensor(0.2588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1777, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3957277924232517
Current compression ratio of attn:  tensor(0.2608, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1782, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3966691345339943
Current compression ratio of attn:  tensor(0.2579, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3976096098746036
Current compression ratio of attn:  tensor(0.2636, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1797, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39854921639002683
Search Epoch: [3]  [ 5000/23614]  eta: 3:34:16  lr: 0.00001000  loss: 14.9847  loss_ita: 4.4637  loss_sp_attn: 4.9767  loss_sp_mlp: 5.5442  time: 0.6869  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.2626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1819, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39948795202710996
Current compression ratio of attn:  tensor(0.2639, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1826, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40042581473460204
Current compression ratio of attn:  tensor(0.2657, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1832, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40136280246315903
Current compression ratio of attn:  tensor(0.2694, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1826, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4022989131653495
Current compression ratio of attn:  tensor(0.2667, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1858, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40323414479565794
Current compression ratio of attn:  tensor(0.2706, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1851, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40416849531049004
Current compression ratio of attn:  tensor(0.2680, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1883, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4051019626681765
Current compression ratio of attn:  tensor(0.2721, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1874, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4060345448289781
Current compression ratio of attn:  tensor(0.2725, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4069662397550897
Current compression ratio of attn:  tensor(0.2703, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1918, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4078970454106452
Current compression ratio of attn:  tensor(0.2726, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1920, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40882695976172123
Current compression ratio of attn:  tensor(0.2729, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1934, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40975598077634234
Current compression ratio of attn:  tensor(0.2733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41068410642448505
Current compression ratio of attn:  tensor(0.2749, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1954, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4116113346780821
Current compression ratio of attn:  tensor(0.2769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1958, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4125376635110277
Current compression ratio of attn:  tensor(0.2785, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1966, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4134630908991809
Current compression ratio of attn:  tensor(0.2767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1992, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4143876148203706
Current compression ratio of attn:  tensor(0.2783, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2000, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4153112332544002
Current compression ratio of attn:  tensor(0.2809, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2000, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4162339441830514
Current compression ratio of attn:  tensor(0.2800, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41715574559008894
Current compression ratio of attn:  tensor(0.2831, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2019, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41807663546126506
Current compression ratio of attn:  tensor(0.2827, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4189966117843239
Current compression ratio of attn:  tensor(0.2867, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2031, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41991567254900547
Current compression ratio of attn:  tensor(0.2830, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4208338157470509
Current compression ratio of attn:  tensor(0.2902, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4217510393722057
Search Epoch: [3]  [10000/23614]  eta: 2:36:50  lr: 0.00001000  loss: 15.4755  loss_ita: 5.3000  loss_sp_attn: 4.7971  loss_sp_mlp: 5.3784  time: 0.6884  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.2874, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4226673414202254
Current compression ratio of attn:  tensor(0.2885, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42358271988887874
Current compression ratio of attn:  tensor(0.2899, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2095, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4244971727779529
Current compression ratio of attn:  tensor(0.2907, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42541069808925747
Current compression ratio of attn:  tensor(0.2919, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2115, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42632329382662904
Current compression ratio of attn:  tensor(0.2952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42723495799593525
Current compression ratio of attn:  tensor(0.2948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2131, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4281456886050793
Current compression ratio of attn:  tensor(0.2967, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2136, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4290554836640047
Current compression ratio of attn:  tensor(0.2958, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2158, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4299643411846986
Current compression ratio of attn:  tensor(0.2995, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43087225918119754
Current compression ratio of attn:  tensor(0.2976, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2182, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4317792356695905
Current compression ratio of attn:  tensor(0.3002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4326852686680238
Current compression ratio of attn:  tensor(0.2991, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2205, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4335903561967058
Current compression ratio of attn:  tensor(0.3060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43449449627791026
Current compression ratio of attn:  tensor(0.3021, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2220, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43539768693598185
Current compression ratio of attn:  tensor(0.3042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2225, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43629992619733926
Current compression ratio of attn:  tensor(0.3034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4372012120904806
Current compression ratio of attn:  tensor(0.3060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2248, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43810154264598666
Current compression ratio of attn:  tensor(0.3064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43900091589652634
Current compression ratio of attn:  tensor(0.3101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43989932987685976
Current compression ratio of attn:  tensor(0.3061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2299, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4407967826238438
Current compression ratio of attn:  tensor(0.3129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4416932721764354
Current compression ratio of attn:  tensor(0.3094, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2313, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44258879657569616
Current compression ratio of attn:  tensor(0.3139, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2302, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44348335386479665
Current compression ratio of attn:  tensor(0.3114, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2334, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.444376942089021
Search Epoch: [3]  [15000/23614]  eta: 1:39:17  lr: 0.00001000  loss: 14.7223  loss_ita: 4.8879  loss_sp_attn: 4.6537  loss_sp_mlp: 5.1807  time: 0.6657  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.3169, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2317, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4452695592957704
Current compression ratio of attn:  tensor(0.3158, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44616120353456834
Current compression ratio of attn:  tensor(0.3185, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4470518728570637
Current compression ratio of attn:  tensor(0.3147, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2382, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44794156531703655
Current compression ratio of attn:  tensor(0.3197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4488302789704007
Current compression ratio of attn:  tensor(0.3183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2395, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4497180118752092
Current compression ratio of attn:  tensor(0.3213, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2394, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.450604762091658
Current compression ratio of attn:  tensor(0.3227, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45149052768209064
Current compression ratio of attn:  tensor(0.3225, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2420, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45237530671100157
Current compression ratio of attn:  tensor(0.3263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2414, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4532590972450418
Current compression ratio of attn:  tensor(0.3240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2446, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4541418973530217
Current compression ratio of attn:  tensor(0.3244, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2461, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45502370510591583
Current compression ratio of attn:  tensor(0.3298, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2445, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45590451857686787
Current compression ratio of attn:  tensor(0.3273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2477, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4567843358411931
Current compression ratio of attn:  tensor(0.3311, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45766315497638466
Current compression ratio of attn:  tensor(0.3288, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4585409740621159
Current compression ratio of attn:  tensor(0.3297, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2515, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45941779118024584
Current compression ratio of attn:  tensor(0.3319, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2518, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4602936044148228
Current compression ratio of attn:  tensor(0.3304, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4611684118520886
Current compression ratio of attn:  tensor(0.3374, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2519, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46204221158048325
Current compression ratio of attn:  tensor(0.3362, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2544, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46291500169064825
Current compression ratio of attn:  tensor(0.3344, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2572, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46378678027543135
Current compression ratio of attn:  tensor(0.3394, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4646575454298909
Current compression ratio of attn:  tensor(0.3403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2571, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46552729525129954
Current compression ratio of attn:  tensor(0.3395, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2592, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46639602783914813
Search Epoch: [3]  [20000/23614]  eta: 0:41:40  lr: 0.00001000  loss: 14.1357  loss_ita: 4.6654  loss_sp_attn: 4.4636  loss_sp_mlp: 5.0066  time: 0.6774  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.3413, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2599, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.467263741295151
Current compression ratio of attn:  tensor(0.3427, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2608, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46813043372324903
Current compression ratio of attn:  tensor(0.3450, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4689961032296141
Current compression ratio of attn:  tensor(0.3453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4698607479226536
Current compression ratio of attn:  tensor(0.3460, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2641, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47072436591301386
Current compression ratio of attn:  tensor(0.3493, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2637, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4715869553135853
Current compression ratio of attn:  tensor(0.3461, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2675, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47244851423950507
Current compression ratio of attn:  tensor(0.3501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2668, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4733090408081628
Current compression ratio of attn:  tensor(0.3493, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47416853313920354
Current compression ratio of attn:  tensor(0.3524, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2689, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4750269893545324
Current compression ratio of attn:  tensor(0.3539, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2697, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47588440757831857
Current compression ratio of attn:  tensor(0.3537, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2715, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4767407859369992
Current compression ratio of attn:  tensor(0.3552, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2725, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47759612255928374
Current compression ratio of attn:  tensor(0.3558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4784504155761583
Current compression ratio of attn:  tensor(0.3578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2744, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4793036631208888
Current compression ratio of attn:  tensor(0.3618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2737, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48015586332902616
Current compression ratio of attn:  tensor(0.3596, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4810070143384094
Current compression ratio of attn:  tensor(0.3578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2795, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48185711428917066
Search Epoch: [3]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 12.9778  loss_ita: 3.7680  loss_sp_attn: 4.3405  loss_sp_mlp: 4.8694  time: 0.6932  data: 0.0003  max mem: 28228
Search Epoch: [3] Total time: 4:32:21 (0.6920 s / it)
Averaged stats: lr: 0.0000  loss: 14.2550  loss_ita: 4.2053  loss_sp_attn: 4.7466  loss_sp_mlp: 5.3030
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
do itm_eval
search_result {'txt_r1': 29.12, 'txt_r5': 54.46, 'txt_r10': 66.82, 'txt_r_mean': 50.133333333333326, 'img_r1': 21.699320271891242, 'img_r5': 46.02159136345462, 'img_r10': 57.712914834066375, 'img_r_mean': 41.811275489804075, 'r_mean': 45.9723044115687}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0013
Text_CKA_Similarity: 0.2950
Image_Cosine_Similarity: 0.0814
Image_CKA_Similarity: 0.6461
sim_matrix_pearson_correlation: 0.3800
model_search_3.pth saved
KD:False
Search Epoch: [4]  [    0/23614]  eta: 5:43:50  lr: 0.00001000  loss: 14.6625  loss_ita: 5.4526  loss_sp_attn: 4.3405  loss_sp_mlp: 4.8694  time: 0.8737  data: 0.1490  max mem: 28228
KD is False
Current compression ratio of attn:  tensor(0.3643, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48270616132373834
Current compression ratio of attn:  tensor(0.3604, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48355415358684184
Current compression ratio of attn:  tensor(0.3675, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2787, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4844010892255153
Current compression ratio of attn:  tensor(0.3614, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2844, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4852469663891018
Current compression ratio of attn:  tensor(0.3685, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2818, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48609178322925695
Current compression ratio of attn:  tensor(0.3677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2841, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4869355378999539
Current compression ratio of attn:  tensor(0.3704, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2843, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4877782285574861
Current compression ratio of attn:  tensor(0.3679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2874, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4886198533604726
Current compression ratio of attn:  tensor(0.3733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2859, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4894604104698611
Current compression ratio of attn:  tensor(0.3725, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2882, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49029989804893237
Current compression ratio of attn:  tensor(0.3735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49113831426330445
Current compression ratio of attn:  tensor(0.3701, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2932, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4919756572809364
Current compression ratio of attn:  tensor(0.3756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2917, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4928119252721318
Current compression ratio of attn:  tensor(0.3739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2943, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4936471164095442
Current compression ratio of attn:  tensor(0.3786, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2932, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4944812288681794
Current compression ratio of attn:  tensor(0.3769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2960, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.495314260825401
Current compression ratio of attn:  tensor(0.3793, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49614621046093277
Current compression ratio of attn:  tensor(0.3805, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49697707595686413
Current compression ratio of attn:  tensor(0.3820, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2982, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49780685549765336
Current compression ratio of attn:  tensor(0.3812, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4986355472701315
Current compression ratio of attn:  tensor(0.3821, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4994631494635065
Current compression ratio of attn:  tensor(0.3859, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5002896602693674
Current compression ratio of attn:  tensor(0.3869, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5011150778816879
Current compression ratio of attn:  tensor(0.3887, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5019394004968305
Current compression ratio of attn:  tensor(0.3861, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5027626263135503
Search Epoch: [4]  [ 5000/23614]  eta: 3:35:23  lr: 0.00001000  loss: 13.3551  loss_ita: 4.5183  loss_sp_attn: 4.1490  loss_sp_mlp: 4.6878  time: 0.6965  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.3899, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3057, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5035847535329991
Current compression ratio of attn:  tensor(0.3894, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3078, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5044057803587295
Current compression ratio of attn:  tensor(0.3906, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5052257049966982
Current compression ratio of attn:  tensor(0.3889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3118, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5060445256552706
Current compression ratio of attn:  tensor(0.3913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3118, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5068622405452241
Current compression ratio of attn:  tensor(0.3931, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5076788478797527
Current compression ratio of attn:  tensor(0.3923, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5084943458744706
Current compression ratio of attn:  tensor(0.3970, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5093087327474155
Current compression ratio of attn:  tensor(0.3962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5101220067190536
Current compression ratio of attn:  tensor(0.3959, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3180, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5109341660122827
Current compression ratio of attn:  tensor(0.4016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3163, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5117452088524362
Current compression ratio of attn:  tensor(0.4004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3188, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5125551334672874
Current compression ratio of attn:  tensor(0.4020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3196, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5133639380870527
Current compression ratio of attn:  tensor(0.4023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.514171620944396
Current compression ratio of attn:  tensor(0.4056, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3209, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5149781802744323
Current compression ratio of attn:  tensor(0.4006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3258, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5157836143147317
Current compression ratio of attn:  tensor(0.4042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5165879213053235
Current compression ratio of attn:  tensor(0.4039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5173910994886993
Current compression ratio of attn:  tensor(0.4084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5181931471098172
Current compression ratio of attn:  tensor(0.4079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3285, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5189940624161062
Current compression ratio of attn:  tensor(0.4088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3297, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5197938436574694
Current compression ratio of attn:  tensor(0.4139, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3283, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5205924890862873
Current compression ratio of attn:  tensor(0.4116, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3315, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5213899969574234
Current compression ratio of attn:  tensor(0.4134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3322, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5221863655282262
Current compression ratio of attn:  tensor(0.4131, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5229815930585338
Search Epoch: [4]  [10000/23614]  eta: 2:37:19  lr: 0.00001000  loss: 14.4357  loss_ita: 5.9695  loss_sp_attn: 3.9664  loss_sp_mlp: 4.4998  time: 0.6854  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.4153, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3347, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5237756778106776
Current compression ratio of attn:  tensor(0.4159, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3360, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5245686180494863
Current compression ratio of attn:  tensor(0.4190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3360, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5253604120422894
Current compression ratio of attn:  tensor(0.4147, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3404, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5261510580589209
Current compression ratio of attn:  tensor(0.4223, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3373, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5269405543717236
Current compression ratio of attn:  tensor(0.4211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3400, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5277288992555523
Current compression ratio of attn:  tensor(0.4257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.528516090987778
Current compression ratio of attn:  tensor(0.4196, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3445, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5293021278482911
Current compression ratio of attn:  tensor(0.4267, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.530087008119506
Current compression ratio of attn:  tensor(0.4215, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3469, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5308707300863642
Current compression ratio of attn:  tensor(0.4267, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3454, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5316532920363382
Current compression ratio of attn:  tensor(0.4274, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3469, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.532434692259435
Current compression ratio of attn:  tensor(0.4295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5332149290482009
Current compression ratio of attn:  tensor(0.4333, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3467, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5339940006977237
Current compression ratio of attn:  tensor(0.4320, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3494, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5347719055056372
Current compression ratio of attn:  tensor(0.4333, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5355486417721256
Current compression ratio of attn:  tensor(0.4323, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3526, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5363242077999257
Current compression ratio of attn:  tensor(0.4351, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5370986018943319
Current compression ratio of attn:  tensor(0.4327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3561, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5378718223631992
Current compression ratio of attn:  tensor(0.4383, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3544, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5386438675169469
Current compression ratio of attn:  tensor(0.4352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5394147356685632
Current compression ratio of attn:  tensor(0.4389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5401844251336075
Current compression ratio of attn:  tensor(0.4411, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5409529342302151
Current compression ratio of attn:  tensor(0.4405, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5417202612791004
Current compression ratio of attn:  tensor(0.4383, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3633, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5424864046035611
Search Epoch: [4]  [15000/23614]  eta: 1:39:31  lr: 0.00001000  loss: 12.6069  loss_ita: 4.5076  loss_sp_attn: 3.7965  loss_sp_mlp: 4.3029  time: 0.6929  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.4474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5432513625294808
Current compression ratio of attn:  tensor(0.4401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3659, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.544015133385334
Current compression ratio of attn:  tensor(0.4470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5447777155021886
Current compression ratio of attn:  tensor(0.4433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3675, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5455391072137104
Current compression ratio of attn:  tensor(0.4454, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3680, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5462993068561661
Current compression ratio of attn:  tensor(0.4464, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3692, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5470583127684276
Current compression ratio of attn:  tensor(0.4495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5478161232919748
Current compression ratio of attn:  tensor(0.4495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3708, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5485727367708998
Current compression ratio of attn:  tensor(0.4530, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3705, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5493281515519106
Current compression ratio of attn:  tensor(0.4517, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3730, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5500823659843345
Current compression ratio of attn:  tensor(0.4504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5508353784201211
Current compression ratio of attn:  tensor(0.4539, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3753, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5515871872138474
Current compression ratio of attn:  tensor(0.4558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3759, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5523377907227197
Current compression ratio of attn:  tensor(0.4526, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3796, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5530871873065787
Current compression ratio of attn:  tensor(0.4551, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5538353753279018
Current compression ratio of attn:  tensor(0.4570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3805, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5545823531518077
Current compression ratio of attn:  tensor(0.4602, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3803, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5553281191460593
Current compression ratio of attn:  tensor(0.4599, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3823, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5560726716810672
Current compression ratio of attn:  tensor(0.4608, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3835, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5568160091298943
Current compression ratio of attn:  tensor(0.4614, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3849, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5575581298682579
Current compression ratio of attn:  tensor(0.4633, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3855, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5582990322745344
Current compression ratio of attn:  tensor(0.4626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5590387147297622
Current compression ratio of attn:  tensor(0.4655, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5597771756176453
Current compression ratio of attn:  tensor(0.4697, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3869, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5605144133245576
Current compression ratio of attn:  tensor(0.4690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3890, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.561250426239545
Search Epoch: [4]  [20000/23614]  eta: 0:41:47  lr: 0.00001000  loss: 11.9780  loss_ita: 4.2600  loss_sp_attn: 3.5887  loss_sp_mlp: 4.1293  time: 0.6825  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.4690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3909, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5619852127543302
Current compression ratio of attn:  tensor(0.4686, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3928, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5627187712633156
Current compression ratio of attn:  tensor(0.4728, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3921, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.563451100163587
Current compression ratio of attn:  tensor(0.4731, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3936, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5641821978549169
Current compression ratio of attn:  tensor(0.4744, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5649120627397684
Current compression ratio of attn:  tensor(0.4737, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3969, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5656406932232978
Current compression ratio of attn:  tensor(0.4762, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5663680877133599
Current compression ratio of attn:  tensor(0.4765, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5670942446205091
Current compression ratio of attn:  tensor(0.4784, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3993, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5678191623580047
Current compression ratio of attn:  tensor(0.4761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5685428393418136
Current compression ratio of attn:  tensor(0.4790, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5692652739906137
Current compression ratio of attn:  tensor(0.4806, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5699864647257982
Current compression ratio of attn:  tensor(0.4815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5707064099714774
Current compression ratio of attn:  tensor(0.4795, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5714251081544839
Current compression ratio of attn:  tensor(0.4847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.572142557704375
Current compression ratio of attn:  tensor(0.4817, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5728587570534368
Current compression ratio of attn:  tensor(0.4863, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4086, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5735737046366866
Current compression ratio of attn:  tensor(0.4849, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5742873988918773
Search Epoch: [4]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 13.6544  loss_ita: 6.1937  loss_sp_attn: 3.4813  loss_sp_mlp: 3.9794  time: 0.6956  data: 0.0002  max mem: 28228
Search Epoch: [4] Total time: 4:33:02 (0.6937 s / it)
Averaged stats: lr: 0.0000  loss: 13.4080  loss_ita: 5.0761  loss_sp_attn: 3.8950  loss_sp_mlp: 4.4369
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
do itm_eval
search_result {'txt_r1': 19.04, 'txt_r5': 42.16, 'txt_r10': 54.44, 'txt_r_mean': 38.54666666666666, 'img_r1': 11.519392243102759, 'img_r5': 29.056377449020392, 'img_r10': 39.75209916033587, 'img_r_mean': 26.775956284153008, 'r_mean': 32.66131147540983}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0576
Text_CKA_Similarity: 0.3139
Image_Cosine_Similarity: 0.0450
Image_CKA_Similarity: 0.5833
sim_matrix_pearson_correlation: 0.4169
model_search_4.pth saved
KD:False
Search Epoch: [5]  [    0/23614]  eta: 6:27:23  lr: 0.00001000  loss: 12.3096  loss_ita: 4.8488  loss_sp_attn: 3.4813  loss_sp_mlp: 3.9794  time: 0.9843  data: 0.2011  max mem: 28228
KD is False
Current compression ratio of attn:  tensor(0.4915, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5749998382595005
Current compression ratio of attn:  tensor(0.4898, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4117, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5757110211827899
Current compression ratio of attn:  tensor(0.4877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4148, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5764209461077247
Current compression ratio of attn:  tensor(0.4890, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4158, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5771296114830327
Current compression ratio of attn:  tensor(0.4926, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5778370157601942
Current compression ratio of attn:  tensor(0.4935, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5785431573934451
Current compression ratio of attn:  tensor(0.4918, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4193, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5792480348397804
Current compression ratio of attn:  tensor(0.4957, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4186, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5799516465589577
Current compression ratio of attn:  tensor(0.4933, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5806539910134997
Current compression ratio of attn:  tensor(0.4983, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.581355066668699
Current compression ratio of attn:  tensor(0.4985, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4220, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.58205487199262
Current compression ratio of attn:  tensor(0.5011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4223, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5827534054561034
Current compression ratio of attn:  tensor(0.5017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4236, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5834506655327691
Current compression ratio of attn:  tensor(0.5017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4255, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5841466506990189
Current compression ratio of attn:  tensor(0.5043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4258, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5848413594340415
Current compression ratio of attn:  tensor(0.5032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4282, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5855347902198135
Current compression ratio of attn:  tensor(0.5065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5862269415411049
Current compression ratio of attn:  tensor(0.5044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4310, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5869178118854811
Current compression ratio of attn:  tensor(0.5087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4299, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5876073997433067
Current compression ratio of attn:  tensor(0.5083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4321, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5882957036077486
Current compression ratio of attn:  tensor(0.5120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4316, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5889827219747794
Current compression ratio of attn:  tensor(0.5122, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4332, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.589668453343181
Current compression ratio of attn:  tensor(0.5121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4348, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5903528962145469
Current compression ratio of attn:  tensor(0.5137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4357, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5910360490932867
Current compression ratio of attn:  tensor(0.5140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4370, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5917179104866284
Search Epoch: [5]  [ 5000/23614]  eta: 3:35:06  lr: 0.00001000  loss: 12.5069  loss_ita: 5.4176  loss_sp_attn: 3.2847  loss_sp_mlp: 3.8047  time: 0.6918  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.5118, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5923984789046223
Current compression ratio of attn:  tensor(0.5165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4390, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5930777528601439
Current compression ratio of attn:  tensor(0.5171, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5937557308688972
Current compression ratio of attn:  tensor(0.5157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4430, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5944324114494184
Current compression ratio of attn:  tensor(0.5187, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4430, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.595107793123078
Current compression ratio of attn:  tensor(0.5179, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4451, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5957818744140855
Current compression ratio of attn:  tensor(0.5174, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4473, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5964546538494915
Current compression ratio of attn:  tensor(0.5159, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4497, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5971261299591913
Current compression ratio of attn:  tensor(0.5189, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4496, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5977963012759284
Current compression ratio of attn:  tensor(0.5216, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4497, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.598465166335297
Current compression ratio of attn:  tensor(0.5229, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4506, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5991327236757462
Current compression ratio of attn:  tensor(0.5217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4530, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.599798971838582
Current compression ratio of attn:  tensor(0.5216, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4548, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6004639093679717
Current compression ratio of attn:  tensor(0.5211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4568, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6011275348109458
Current compression ratio of attn:  tensor(0.5220, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6017898467174027
Current compression ratio of attn:  tensor(0.5251, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6024508436401105
Current compression ratio of attn:  tensor(0.5260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4590, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6031105241347108
Current compression ratio of attn:  tensor(0.5290, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6037688867597215
Current compression ratio of attn:  tensor(0.5285, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4608, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.604425930076541
Current compression ratio of attn:  tensor(0.5294, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4620, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6050816526494495
Current compression ratio of attn:  tensor(0.5300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4633, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6057360530456141
Current compression ratio of attn:  tensor(0.5359, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4613, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6063891298350905
Current compression ratio of attn:  tensor(0.5301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4666, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6070408815908266
Current compression ratio of attn:  tensor(0.5349, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4654, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.607691306888666
Current compression ratio of attn:  tensor(0.5316, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6083404043073506
Search Epoch: [5]  [10000/23614]  eta: 2:37:05  lr: 0.00001000  loss: 13.3529  loss_ita: 6.5987  loss_sp_attn: 3.1657  loss_sp_mlp: 3.5885  time: 0.6939  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.5371, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4675, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6089881724285237
Current compression ratio of attn:  tensor(0.5384, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4684, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6096346098367337
Current compression ratio of attn:  tensor(0.5379, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4704, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6102797151194364
Current compression ratio of attn:  tensor(0.5395, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4711, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6109234868669984
Current compression ratio of attn:  tensor(0.5429, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4706, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6115659236727008
Current compression ratio of attn:  tensor(0.5403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6122070241327409
Current compression ratio of attn:  tensor(0.5437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6128467868462368
Current compression ratio of attn:  tensor(0.5407, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4771, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6134852104152293
Current compression ratio of attn:  tensor(0.5441, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4765, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6141222934446856
Current compression ratio of attn:  tensor(0.5425, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4792, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.614758034542502
Current compression ratio of attn:  tensor(0.5492, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6153924323195071
Current compression ratio of attn:  tensor(0.5440, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4817, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6160254853894651
Current compression ratio of attn:  tensor(0.5489, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4806, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6166571923690781
Current compression ratio of attn:  tensor(0.5523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4800, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6172875518779898
Current compression ratio of attn:  tensor(0.5471, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4848, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6179165625387883
Current compression ratio of attn:  tensor(0.5516, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4838, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6185442229770092
Current compression ratio of attn:  tensor(0.5522, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4850, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6191705318211382
Current compression ratio of attn:  tensor(0.5556, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4849, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6197954877026148
Current compression ratio of attn:  tensor(0.5522, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4884, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6204190892558344
Current compression ratio of attn:  tensor(0.5560, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4880, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6210413351181521
Current compression ratio of attn:  tensor(0.5558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4895, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6216622239298853
Current compression ratio of attn:  tensor(0.5582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4898, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6222817543343169
Current compression ratio of attn:  tensor(0.5595, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4907, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6228999249776975
Current compression ratio of attn:  tensor(0.5607, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4917, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6235167345092496
Current compression ratio of attn:  tensor(0.5606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4934, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6241321815811696
Search Epoch: [5]  [15000/23614]  eta: 1:39:24  lr: 0.00001000  loss: 12.1760  loss_ita: 5.7826  loss_sp_attn: 2.9699  loss_sp_mlp: 3.4235  time: 0.7037  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.5608, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6247462648486308
Current compression ratio of attn:  tensor(0.5606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4967, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6253589829697872
Current compression ratio of attn:  tensor(0.5662, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6259703346057751
Current compression ratio of attn:  tensor(0.5660, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4967, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6265803184207175
Current compression ratio of attn:  tensor(0.5662, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4981, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6271889330817254
Current compression ratio of attn:  tensor(0.5635, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6277961772589022
Current compression ratio of attn:  tensor(0.5691, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4997, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6284020496253458
Current compression ratio of attn:  tensor(0.5646, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6290065488571518
Current compression ratio of attn:  tensor(0.5688, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6296096736334158
Current compression ratio of attn:  tensor(0.5719, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6302114226362372
Current compression ratio of attn:  tensor(0.5728, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5040, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6308117945507217
Current compression ratio of attn:  tensor(0.5773, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6314107880649835
Current compression ratio of attn:  tensor(0.5739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5066, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6320084018701495
Current compression ratio of attn:  tensor(0.5733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6326046346603609
Current compression ratio of attn:  tensor(0.5779, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6331994851327769
Current compression ratio of attn:  tensor(0.5773, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6337929519875773
Current compression ratio of attn:  tensor(0.5801, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6343850339279647
Current compression ratio of attn:  tensor(0.5799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5110, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6349757296601687
Current compression ratio of attn:  tensor(0.5808, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5119, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6355650378934473
Current compression ratio of attn:  tensor(0.5828, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5122, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6361529573400906
Current compression ratio of attn:  tensor(0.5796, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5159, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6367394867154235
Current compression ratio of attn:  tensor(0.5850, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6373246247378079
Current compression ratio of attn:  tensor(0.5877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6379083701286468
Current compression ratio of attn:  tensor(0.5868, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6384907216123854
Current compression ratio of attn:  tensor(0.5847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5192, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6390716779165152
Search Epoch: [5]  [20000/23614]  eta: 0:41:43  lr: 0.00001000  loss: 12.2075  loss_ita: 6.1514  loss_sp_attn: 2.8067  loss_sp_mlp: 3.2494  time: 0.6920  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.5886, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5184, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6396512377715764
Current compression ratio of attn:  tensor(0.5906, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5188, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6402293999111601
Current compression ratio of attn:  tensor(0.5896, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5210, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6408061630719126
Current compression ratio of attn:  tensor(0.5913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5214, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.641381525993536
Current compression ratio of attn:  tensor(0.5929, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6419554874187927
Current compression ratio of attn:  tensor(0.5931, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6425280460935076
Current compression ratio of attn:  tensor(0.5962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5232, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6430992007665701
Current compression ratio of attn:  tensor(0.5964, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5248, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6436689501899386
Current compression ratio of attn:  tensor(0.5965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5262, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6442372931186413
Current compression ratio of attn:  tensor(0.5989, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.64480422831078
Current compression ratio of attn:  tensor(0.5979, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5285, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6453697545275326
Current compression ratio of attn:  tensor(0.6022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5274, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.645933870533156
Current compression ratio of attn:  tensor(0.6020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5291, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6464965750949879
Current compression ratio of attn:  tensor(0.6032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5299, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6470578669834512
Current compression ratio of attn:  tensor(0.6038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6476177449720546
Current compression ratio of attn:  tensor(0.6032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5331, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6481762078373969
Current compression ratio of attn:  tensor(0.6041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5339, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6487332543591696
Current compression ratio of attn:  tensor(0.6076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6492888833201579
Search Epoch: [5]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 12.3454  loss_ita: 6.5404  loss_sp_attn: 2.6521  loss_sp_mlp: 3.1529  time: 0.7060  data: 0.0004  max mem: 28228
Search Epoch: [5] Total time: 4:32:48 (0.6932 s / it)
Averaged stats: lr: 0.0000  loss: 12.4735  loss_ita: 5.8510  loss_sp_attn: 3.0724  loss_sp_mlp: 3.5501
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
do itm_eval
search_result {'txt_r1': 13.58, 'txt_r5': 35.46, 'txt_r10': 47.9, 'txt_r_mean': 32.31333333333333, 'img_r1': 8.932427029188325, 'img_r5': 24.53418632546981, 'img_r10': 35.15393842463015, 'img_r_mean': 22.873517259762764, 'r_mean': 27.593425296548048}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: -0.0473
Text_CKA_Similarity: 0.2484
Image_Cosine_Similarity: 0.0228
Image_CKA_Similarity: 0.6190
sim_matrix_pearson_correlation: 0.2129
model_search_5.pth saved
KD:False
Search Epoch: [6]  [    0/23614]  eta: 6:01:45  lr: 0.00001000  loss: 11.8440  loss_ita: 6.0390  loss_sp_attn: 2.6521  loss_sp_mlp: 3.1529  time: 0.9192  data: 0.1824  max mem: 28228
KD is False
Current compression ratio of attn:  tensor(0.6092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5339, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6498430935062455
Current compression ratio of attn:  tensor(0.6101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5349, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6503958837064159
Current compression ratio of attn:  tensor(0.6076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5381, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6509472527127554
Current compression ratio of attn:  tensor(0.6100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5381, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6514971993204561
Current compression ratio of attn:  tensor(0.6143, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5371, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.652045722327818
Current compression ratio of attn:  tensor(0.6141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6525928205362517
Current compression ratio of attn:  tensor(0.6142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6531384927502814
Current compression ratio of attn:  tensor(0.6159, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5407, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.653682737777547
Current compression ratio of attn:  tensor(0.6149, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5429, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6542255544288075
Current compression ratio of attn:  tensor(0.6157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5438, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6547669415179425
Current compression ratio of attn:  tensor(0.6170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5446, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6553068978619556
Current compression ratio of attn:  tensor(0.6190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.655845422280977
Current compression ratio of attn:  tensor(0.6218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5447, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6563825135982652
Current compression ratio of attn:  tensor(0.6200, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5473, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6569181706402106
Current compression ratio of attn:  tensor(0.6228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5471, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6574523922363381
Current compression ratio of attn:  tensor(0.6222, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5487, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6579851772193083
Current compression ratio of attn:  tensor(0.6223, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6585165244249216
Current compression ratio of attn:  tensor(0.6266, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5492, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.65904643269212
Current compression ratio of attn:  tensor(0.6245, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5521, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6595749008629896
Current compression ratio of attn:  tensor(0.6265, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6601019277827637
Current compression ratio of attn:  tensor(0.6270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5535, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6606275122998242
Current compression ratio of attn:  tensor(0.6260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5556, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6611516532657054
Current compression ratio of attn:  tensor(0.6303, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6616743495350959
Current compression ratio of attn:  tensor(0.6308, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5557, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6621955999658408
Current compression ratio of attn:  tensor(0.6355, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5543, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6627154034189447
Search Epoch: [6]  [ 5000/23614]  eta: 3:34:46  lr: 0.00001000  loss: 11.3441  loss_ita: 5.8681  loss_sp_attn: 2.4635  loss_sp_mlp: 3.0125  time: 0.6991  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.6256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6632337587585744
Current compression ratio of attn:  tensor(0.6392, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5549, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6637506648520602
Current compression ratio of attn:  tensor(0.6339, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5596, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6642661205699
Current compression ratio of attn:  tensor(0.6352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5604, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6647801247857605
Current compression ratio of attn:  tensor(0.6356, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5614, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6652926763764802
Current compression ratio of attn:  tensor(0.6365, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5624, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6658037742220716
Current compression ratio of attn:  tensor(0.6382, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5629, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6663134172057241
Current compression ratio of attn:  tensor(0.6379, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5645, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.666821604213806
Current compression ratio of attn:  tensor(0.6380, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5659, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.667328334135867
Current compression ratio of attn:  tensor(0.6400, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5661, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6678336058646411
Current compression ratio of attn:  tensor(0.6417, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5666, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6683374182960479
Current compression ratio of attn:  tensor(0.6433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5670, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6688397703291966
Current compression ratio of attn:  tensor(0.6407, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5699, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6693406608663869
Current compression ratio of attn:  tensor(0.6446, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6698400888131122
Current compression ratio of attn:  tensor(0.6459, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5696, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.670338053078062
Current compression ratio of attn:  tensor(0.6479, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5699, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6708345525731242
Current compression ratio of attn:  tensor(0.6453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5726, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.671329586213387
Current compression ratio of attn:  tensor(0.6489, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5720, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6718231529171419
Current compression ratio of attn:  tensor(0.6513, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5721, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6723152516058859
Current compression ratio of attn:  tensor(0.6491, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5749, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6728058812043238
Current compression ratio of attn:  tensor(0.6538, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5734, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6732950406403704
Current compression ratio of attn:  tensor(0.6543, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5745, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.673782728845153
Current compression ratio of attn:  tensor(0.6516, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5776, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6742689447530139
Current compression ratio of attn:  tensor(0.6544, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5772, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6747536873015123
Current compression ratio of attn:  tensor(0.6557, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5779, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6752369554314269
Search Epoch: [6]  [10000/23614]  eta: 2:37:04  lr: 0.00001000  loss: 11.7703  loss_ita: 6.5906  loss_sp_attn: 2.3269  loss_sp_mlp: 2.8528  time: 0.6866  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.6546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6757187480867586
Current compression ratio of attn:  tensor(0.6566, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5800, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6761990642147316
Current compression ratio of attn:  tensor(0.6591, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5800, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6766779027657973
Current compression ratio of attn:  tensor(0.6595, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5809, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6771552626936354
Current compression ratio of attn:  tensor(0.6612, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6776311429551564
Current compression ratio of attn:  tensor(0.6597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5838, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6781055425105043
Current compression ratio of attn:  tensor(0.6582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5861, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6785784603230587
Current compression ratio of attn:  tensor(0.6625, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5848, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6790498953594368
Current compression ratio of attn:  tensor(0.6610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5870, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.679519846589496
Current compression ratio of attn:  tensor(0.6635, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5870, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6799883129863358
Current compression ratio of attn:  tensor(0.6627, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6804552935263004
Current compression ratio of attn:  tensor(0.6632, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5899, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6809207871889806
Current compression ratio of attn:  tensor(0.6644, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5904, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6813847929572165
Current compression ratio of attn:  tensor(0.6637, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5923, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6818473098170992
Current compression ratio of attn:  tensor(0.6653, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5924, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6823083367579733
Current compression ratio of attn:  tensor(0.6693, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5915, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6827678727724391
Current compression ratio of attn:  tensor(0.6686, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5932, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6832259168563547
Current compression ratio of attn:  tensor(0.6722, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5923, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.683682468008838
Current compression ratio of attn:  tensor(0.6703, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5950, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6841375252322699
Current compression ratio of attn:  tensor(0.6739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5940, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6845910875322949
Current compression ratio of attn:  tensor(0.6728, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5961, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6850431539178244
Current compression ratio of attn:  tensor(0.6728, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5976, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6854937234010388
Current compression ratio of attn:  tensor(0.6760, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5969, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6859427949973886
Current compression ratio of attn:  tensor(0.6733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6000, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6863903677255987
Current compression ratio of attn:  tensor(0.6765, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5992, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6868364406076679
Search Epoch: [6]  [15000/23614]  eta: 1:39:19  lr: 0.00001000  loss: 10.4331  loss_ita: 5.5384  loss_sp_attn: 2.1863  loss_sp_mlp: 2.7084  time: 0.6787  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.6738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6872810126688731
Current compression ratio of attn:  tensor(0.6774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6877240829377704
Current compression ratio of attn:  tensor(0.6754, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6881656504461977
Current compression ratio of attn:  tensor(0.6759, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6886057142292763
Current compression ratio of attn:  tensor(0.6775, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6890442733254135
Current compression ratio of attn:  tensor(0.6807, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6894813267763047
Current compression ratio of attn:  tensor(0.6791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.689916873626935
Current compression ratio of attn:  tensor(0.6832, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6057, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6903509129255818
Current compression ratio of attn:  tensor(0.6820, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6907834437238166
Current compression ratio of attn:  tensor(0.6840, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6912144650765072
Current compression ratio of attn:  tensor(0.6844, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6086, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6916439760418197
Current compression ratio of attn:  tensor(0.6869, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6920719756812206
Current compression ratio of attn:  tensor(0.6845, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6924984630594787
Current compression ratio of attn:  tensor(0.6857, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6118, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6929234372446677
Current compression ratio of attn:  tensor(0.6893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6108, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6933468973081672
Current compression ratio of attn:  tensor(0.6890, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6119, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6937688423246656
Current compression ratio of attn:  tensor(0.6890, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6133, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6941892713721622
Current compression ratio of attn:  tensor(0.6910, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6133, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6946081835319684
Current compression ratio of attn:  tensor(0.6910, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6145, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6950255778887103
Current compression ratio of attn:  tensor(0.6938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6954414535303308
Current compression ratio of attn:  tensor(0.6942, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6150, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6958558095480912
Current compression ratio of attn:  tensor(0.6951, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6158, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6962686450365732
Current compression ratio of attn:  tensor(0.6955, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6167, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6966799590936814
Current compression ratio of attn:  tensor(0.6979, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6970897508206447
Current compression ratio of attn:  tensor(0.6995, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6167, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6974980193220184
Search Epoch: [6]  [20000/23614]  eta: 0:41:41  lr: 0.00001000  loss: 11.2007  loss_ita: 6.5795  loss_sp_attn: 2.0308  loss_sp_mlp: 2.5903  time: 0.6965  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.7007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6172, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6979047637056865
Current compression ratio of attn:  tensor(0.7011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6983099830828632
Current compression ratio of attn:  tensor(0.7007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6196, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.698713676568095
Current compression ratio of attn:  tensor(0.7019, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6201, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6991158432792627
Current compression ratio of attn:  tensor(0.7032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6995164823375833
Current compression ratio of attn:  tensor(0.7023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6222, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6999155928676121
Current compression ratio of attn:  tensor(0.7032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7003131739972438
Current compression ratio of attn:  tensor(0.7035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6239, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7007092248577158
Current compression ratio of attn:  tensor(0.7048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6243, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7011037445836089
Current compression ratio of attn:  tensor(0.7080, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6236, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7014967323128496
Current compression ratio of attn:  tensor(0.7060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7018881871867122
Current compression ratio of attn:  tensor(0.7076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6261, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7022781083498202
Current compression ratio of attn:  tensor(0.7112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6251, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7026664949501487
Current compression ratio of attn:  tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6268, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7030533461390258
Current compression ratio of attn:  tensor(0.7104, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6278, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7034386610711351
Current compression ratio of attn:  tensor(0.7124, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7038224389045165
Current compression ratio of attn:  tensor(0.7132, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6284, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7042046788005688
Current compression ratio of attn:  tensor(0.7140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6292, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7045853799240517
Search Epoch: [6]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 10.3721  loss_ita: 5.9331  loss_sp_attn: 1.9331  loss_sp_mlp: 2.5059  time: 0.6957  data: 0.0004  max mem: 28228
Search Epoch: [6] Total time: 4:32:15 (0.6918 s / it)
Averaged stats: lr: 0.0000  loss: 11.1710  loss_ita: 6.0766  loss_sp_attn: 2.2888  loss_sp_mlp: 2.8057
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
do itm_eval
search_result {'txt_r1': 10.46, 'txt_r5': 27.58, 'txt_r10': 38.54, 'txt_r_mean': 25.526666666666667, 'img_r1': 9.636145541783288, 'img_r5': 25.941623350659736, 'img_r10': 36.565373850459814, 'img_r_mean': 24.04771424763428, 'r_mean': 24.787190457150473}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: -0.0384
Text_CKA_Similarity: 0.1126
Image_Cosine_Similarity: 0.0455
Image_CKA_Similarity: 0.5793
sim_matrix_pearson_correlation: 0.2932
model_search_6.pth saved
KD:False
Search Epoch: [7]  [    0/23614]  eta: 6:27:56  lr: 0.00001000  loss: 10.3622  loss_ita: 5.9232  loss_sp_attn: 1.9331  loss_sp_mlp: 2.5059  time: 0.9857  data: 0.2036  max mem: 28228
KD is False
Current compression ratio of attn:  tensor(0.7143, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7049645414430872
Current compression ratio of attn:  tensor(0.7127, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6323, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7053421625291612
Current compression ratio of attn:  tensor(0.7151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6320, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.705718242357126
Current compression ratio of attn:  tensor(0.7155, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7060927801052015
Current compression ratio of attn:  tensor(0.7175, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7064657749549773
Current compression ratio of attn:  tensor(0.7154, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7068372260914147
Current compression ratio of attn:  tensor(0.7187, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6343, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7072071327028477
Current compression ratio of attn:  tensor(0.7178, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6359, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7075754939809857
Current compression ratio of attn:  tensor(0.7198, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6358, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7079423091209145
Current compression ratio of attn:  tensor(0.7181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6380, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7083075773210986
Current compression ratio of attn:  tensor(0.7202, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6378, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7086712977833829
Current compression ratio of attn:  tensor(0.7205, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6385, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7090334697129939
Current compression ratio of attn:  tensor(0.7229, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6382, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7093940923185419
Current compression ratio of attn:  tensor(0.7258, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.709753164812023
Current compression ratio of attn:  tensor(0.7245, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6394, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7101106864088205
Current compression ratio of attn:  tensor(0.7261, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6396, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.710466656327706
Current compression ratio of attn:  tensor(0.7252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6412, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7108210737908424
Current compression ratio of attn:  tensor(0.7256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6421, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7111739380237843
Current compression ratio of attn:  tensor(0.7268, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6422, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7115252482554808
Current compression ratio of attn:  tensor(0.7271, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7118750037182764
Current compression ratio of attn:  tensor(0.7271, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6442, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7122232036479129
Current compression ratio of attn:  tensor(0.7287, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6441, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7125698472835315
Current compression ratio of attn:  tensor(0.7311, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6434, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7129149338676737
Current compression ratio of attn:  tensor(0.7310, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7132584626462832
Current compression ratio of attn:  tensor(0.7314, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6458, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7136004328687087
Search Epoch: [7]  [ 5000/23614]  eta: 3:35:19  lr: 0.00001000  loss: 10.6213  loss_ita: 6.4116  loss_sp_attn: 1.8156  loss_sp_mlp: 2.3941  time: 0.6983  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.7321, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6462, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7139408437877031
Current compression ratio of attn:  tensor(0.7337, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6464, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7142796946594279
Current compression ratio of attn:  tensor(0.7328, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6480, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7146169847434525
Current compression ratio of attn:  tensor(0.7344, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6481, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.714952713302757
Current compression ratio of attn:  tensor(0.7356, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7152868796037342
Current compression ratio of attn:  tensor(0.7359, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6492, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7156194829161902
Current compression ratio of attn:  tensor(0.7358, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7159505225133462
Current compression ratio of attn:  tensor(0.7362, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6510, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7162799976718408
Current compression ratio of attn:  tensor(0.7382, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6506, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7166079076717307
Current compression ratio of attn:  tensor(0.7381, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6519, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.716934251796493
Current compression ratio of attn:  tensor(0.7401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6517, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7172590293330259
Current compression ratio of attn:  tensor(0.7379, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6540, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7175822395716515
Current compression ratio of attn:  tensor(0.7391, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6543, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.717903881806116
Current compression ratio of attn:  tensor(0.7390, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6553, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7182239553335922
Current compression ratio of attn:  tensor(0.7418, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7185424594546808
Current compression ratio of attn:  tensor(0.7438, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6543, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7188593934734113
Current compression ratio of attn:  tensor(0.7416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7191747566972451
Current compression ratio of attn:  tensor(0.7432, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7194885484370747
Current compression ratio of attn:  tensor(0.7435, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7198007680072274
Current compression ratio of attn:  tensor(0.7430, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6587, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7201114147254656
Current compression ratio of attn:  tensor(0.7463, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6577, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7204204879129885
Current compression ratio of attn:  tensor(0.7458, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.720727986894434
Current compression ratio of attn:  tensor(0.7486, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7210339109978792
Current compression ratio of attn:  tensor(0.7510, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7213382595548428
Current compression ratio of attn:  tensor(0.7467, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6612, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7216410319002867
Search Epoch: [7]  [10000/23614]  eta: 2:37:14  lr: 0.00001000  loss: 10.0534  loss_ita: 6.0517  loss_sp_attn: 1.7119  loss_sp_mlp: 2.2898  time: 0.6941  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.7508, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6596, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7219422273726164
Current compression ratio of attn:  tensor(0.7511, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6604, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7222418453136834
Current compression ratio of attn:  tensor(0.7543, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6593, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.722539885068786
Current compression ratio of attn:  tensor(0.7525, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6613, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7228363459866712
Current compression ratio of attn:  tensor(0.7524, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6623, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7231312274195363
Current compression ratio of attn:  tensor(0.7511, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6640, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7234245287230294
Current compression ratio of attn:  tensor(0.7547, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6627, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7237162492562517
Current compression ratio of attn:  tensor(0.7529, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6645, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7240063883817582
Current compression ratio of attn:  tensor(0.7562, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6636, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7242949454655603
Current compression ratio of attn:  tensor(0.7560, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6646, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7245819198771251
Current compression ratio of attn:  tensor(0.7555, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6656, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7248673109893793
Current compression ratio of attn:  tensor(0.7558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6660, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7251511181787085
Current compression ratio of attn:  tensor(0.7573, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6662, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7254333408249595
Current compression ratio of attn:  tensor(0.7564, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7257139783114418
Current compression ratio of attn:  tensor(0.7596, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6666, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7259930300249284
Current compression ratio of attn:  tensor(0.7582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6683, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7262704953556575
Current compression ratio of attn:  tensor(0.7585, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7265463736973337
Current compression ratio of attn:  tensor(0.7617, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6676, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7268206644471294
Current compression ratio of attn:  tensor(0.7616, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6688, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7270933670056862
Current compression ratio of attn:  tensor(0.7606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6702, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7273644807771156
Current compression ratio of attn:  tensor(0.7613, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6706, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7276340051690016
Current compression ratio of attn:  tensor(0.7620, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6711, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7279019395924003
Current compression ratio of attn:  tensor(0.7610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6723, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.728168283461843
Current compression ratio of attn:  tensor(0.7617, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6729, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7284330361953356
Current compression ratio of attn:  tensor(0.7637, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6725, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7286961972143616
Search Epoch: [7]  [15000/23614]  eta: 1:39:30  lr: 0.00001000  loss: 10.5788  loss_ita: 6.7685  loss_sp_attn: 1.5970  loss_sp_mlp: 2.2133  time: 0.6962  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.7627, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7289577659438822
Current compression ratio of attn:  tensor(0.7638, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.729217741812338
Current compression ratio of attn:  tensor(0.7645, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6744, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7294761242516501
Current compression ratio of attn:  tensor(0.7652, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6748, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7297329126972218
Current compression ratio of attn:  tensor(0.7651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6757, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7299881065879391
Current compression ratio of attn:  tensor(0.7679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6747, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7302417053661724
Current compression ratio of attn:  tensor(0.7647, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6775, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7304937084777775
Current compression ratio of attn:  tensor(0.7671, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7307441153720974
Current compression ratio of attn:  tensor(0.7674, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6772, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7309929255019625
Current compression ratio of attn:  tensor(0.7702, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6765, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7312401383236924
Current compression ratio of attn:  tensor(0.7666, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6795, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7314857532970973
Current compression ratio of attn:  tensor(0.7673, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6798, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7317297698854787
Current compression ratio of attn:  tensor(0.7663, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6811, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7319721875556306
Current compression ratio of attn:  tensor(0.7687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6805, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7322130057778413
Current compression ratio of attn:  tensor(0.7693, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6809, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7324522240258935
Current compression ratio of attn:  tensor(0.7696, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6813, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7326898417770666
Current compression ratio of attn:  tensor(0.7736, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6797, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7329258585121369
Current compression ratio of attn:  tensor(0.7730, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6807, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7331602737153791
Current compression ratio of attn:  tensor(0.7682, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6845, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7333930868745678
Current compression ratio of attn:  tensor(0.7701, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6841, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7336242974809779
Current compression ratio of attn:  tensor(0.7721, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6836, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7338539050293862
Current compression ratio of attn:  tensor(0.7719, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6844, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7340819090180724
Current compression ratio of attn:  tensor(0.7734, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6842, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7343083089488203
Current compression ratio of attn:  tensor(0.7741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6843, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7345331043269183
Current compression ratio of attn:  tensor(0.7735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6854, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7347562946611614
Search Epoch: [7]  [20000/23614]  eta: 0:41:44  lr: 0.00001000  loss: 9.7414  loss_ita: 6.0839  loss_sp_attn: 1.5311  loss_sp_mlp: 2.1263  time: 0.6938  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.7750, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6854, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.734977879463852
Current compression ratio of attn:  tensor(0.7756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6857, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7351978582507999
Current compression ratio of attn:  tensor(0.7771, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6854, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.735416230541325
Current compression ratio of attn:  tensor(0.7769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6862, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7356329958582575
Current compression ratio of attn:  tensor(0.7763, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6873, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7358481537279389
Current compression ratio of attn:  tensor(0.7761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6881, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7360617036802231
Current compression ratio of attn:  tensor(0.7789, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7362736452484774
Current compression ratio of attn:  tensor(0.7787, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6879, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7364839779695841
Current compression ratio of attn:  tensor(0.7798, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6879, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7366927013839406
Current compression ratio of attn:  tensor(0.7813, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6876, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7368998150354609
Current compression ratio of attn:  tensor(0.7789, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6897, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7371053184715766
Current compression ratio of attn:  tensor(0.7813, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7373092112432378
Current compression ratio of attn:  tensor(0.7798, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6904, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.737511492904914
Current compression ratio of attn:  tensor(0.7821, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6896, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7377121630145954
Current compression ratio of attn:  tensor(0.7840, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6891, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7379112211337933
Current compression ratio of attn:  tensor(0.7851, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6891, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7381086668275418
Current compression ratio of attn:  tensor(0.7862, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.738304499664398
Current compression ratio of attn:  tensor(0.7872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6890, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7384987192164434
Search Epoch: [7]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 10.3653  loss_ita: 6.8254  loss_sp_attn: 1.4381  loss_sp_mlp: 2.1019  time: 0.6995  data: 0.0003  max mem: 28228
Search Epoch: [7] Total time: 4:32:49 (0.6932 s / it)
Averaged stats: lr: 0.0000  loss: 10.3190  loss_ita: 6.3677  loss_sp_attn: 1.6775  loss_sp_mlp: 2.2738
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
do itm_eval
search_result {'txt_r1': 12.96, 'txt_r5': 33.14, 'txt_r10': 44.66, 'txt_r_mean': 30.25333333333333, 'img_r1': 9.176329468212716, 'img_r5': 25.801679328268694, 'img_r10': 36.805277888844465, 'img_r_mean': 23.92776222844196, 'r_mean': 27.090547780887647}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: -0.1188
Text_CKA_Similarity: 0.1338
Image_Cosine_Similarity: 0.0582
Image_CKA_Similarity: 0.4871
sim_matrix_pearson_correlation: 0.2127
model_search_7.pth saved
KD:False
Search Epoch: [8]  [    0/23614]  eta: 6:23:07  lr: 0.00001000  loss: 10.3375  loss_ita: 6.7976  loss_sp_attn: 1.4381  loss_sp_mlp: 2.1019  time: 0.9735  data: 0.2061  max mem: 28228
KD is False
Current compression ratio of attn:  tensor(0.7883, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6890, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7386913250592848
Current compression ratio of attn:  tensor(0.7846, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6918, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7388823167720551
Current compression ratio of attn:  tensor(0.7836, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6931, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7390716939374142
Current compression ratio of attn:  tensor(0.7876, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6912, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7392594561415502
Current compression ratio of attn:  tensor(0.7852, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6932, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7394456029741796
Current compression ratio of attn:  tensor(0.7854, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6936, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7396301340285494
Current compression ratio of attn:  tensor(0.7882, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6926, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7398130489014366
Current compression ratio of attn:  tensor(0.7888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6926, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.73999434719315
Current compression ratio of attn:  tensor(0.7877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6940, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7401740285075312
Current compression ratio of attn:  tensor(0.7883, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6942, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7403520924519544
Current compression ratio of attn:  tensor(0.7907, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6931, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7405285386373286
Current compression ratio of attn:  tensor(0.7909, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6937, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7407033666780972
Current compression ratio of attn:  tensor(0.7889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6953, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7408765761922399
Current compression ratio of attn:  tensor(0.7887, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.741048166801273
Current compression ratio of attn:  tensor(0.7875, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6975, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7412181381302501
Current compression ratio of attn:  tensor(0.7886, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7413864898077631
Current compression ratio of attn:  tensor(0.7888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6978, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7415532214659435
Current compression ratio of attn:  tensor(0.7907, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7417183327404624
Current compression ratio of attn:  tensor(0.7921, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6968, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7418818232705313
Current compression ratio of attn:  tensor(0.7919, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6975, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7420436926989039
Current compression ratio of attn:  tensor(0.7899, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6990, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7422039406718758
Current compression ratio of attn:  tensor(0.7918, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6985, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7423625668392857
Current compression ratio of attn:  tensor(0.7902, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6999, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7425195708545163
Current compression ratio of attn:  tensor(0.7930, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6988, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7426749523744948
Current compression ratio of attn:  tensor(0.7957, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6976, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7428287110596935
Search Epoch: [8]  [ 5000/23614]  eta: 3:34:35  lr: 0.00001000  loss: 9.5000  loss_ita: 6.0755  loss_sp_attn: 1.3807  loss_sp_mlp: 2.0438  time: 0.6967  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.7950, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6984, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7429808465741313
Current compression ratio of attn:  tensor(0.7990, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7431313585853736
Current compression ratio of attn:  tensor(0.7932, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7432802467645336
Current compression ratio of attn:  tensor(0.7951, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6999, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7434275107862722
Current compression ratio of attn:  tensor(0.7965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6995, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7435731503287999
Current compression ratio of attn:  tensor(0.7967, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6996, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7437171650738765
Current compression ratio of attn:  tensor(0.7959, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7438595547068125
Current compression ratio of attn:  tensor(0.7970, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7440003189164693
Current compression ratio of attn:  tensor(0.7962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.74413945739526
Current compression ratio of attn:  tensor(0.7981, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.74427696983915
Current compression ratio of attn:  tensor(0.7974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7444128559476582
Current compression ratio of attn:  tensor(0.7975, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7445471154238567
Current compression ratio of attn:  tensor(0.7990, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7015, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7446797479743725
Current compression ratio of attn:  tensor(0.7974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7448107533093873
Current compression ratio of attn:  tensor(0.7975, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7449401311426387
Current compression ratio of attn:  tensor(0.7994, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7450678811914202
Current compression ratio of attn:  tensor(0.8008, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7451940031765829
Current compression ratio of attn:  tensor(0.8018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7453184968225344
Current compression ratio of attn:  tensor(0.8007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7454413618572414
Current compression ratio of attn:  tensor(0.7999, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7037, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7455625980122287
Current compression ratio of attn:  tensor(0.7996, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7456822050225809
Current compression ratio of attn:  tensor(0.7997, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7458001826269418
Current compression ratio of attn:  tensor(0.8025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7459165305675164
Current compression ratio of attn:  tensor(0.8022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7460312485900701
Current compression ratio of attn:  tensor(0.8006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7461443364439302
Search Epoch: [8]  [10000/23614]  eta: 2:36:53  lr: 0.00001000  loss: 9.6534  loss_ita: 6.3131  loss_sp_attn: 1.3480  loss_sp_mlp: 1.9923  time: 0.6976  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.8041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7462557938819859
Current compression ratio of attn:  tensor(0.8047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7463656206606895
Current compression ratio of attn:  tensor(0.8052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7464738165400558
Current compression ratio of attn:  tensor(0.8045, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.746580381283664
Current compression ratio of attn:  tensor(0.8063, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7466853146586572
Current compression ratio of attn:  tensor(0.8060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7040, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.746788616435743
Current compression ratio of attn:  tensor(0.8074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7468902863891947
Current compression ratio of attn:  tensor(0.8058, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7469903242968512
Current compression ratio of attn:  tensor(0.8042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7470887299401174
Current compression ratio of attn:  tensor(0.8077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7040, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7471855031039649
Current compression ratio of attn:  tensor(0.8065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.747280643576933
Current compression ratio of attn:  tensor(0.8058, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.747374151151128
Current compression ratio of attn:  tensor(0.8080, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7474660256222244
Current compression ratio of attn:  tensor(0.8081, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7475562667894657
Current compression ratio of attn:  tensor(0.8091, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7476448744556636
Current compression ratio of attn:  tensor(0.8105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7477318484272
Current compression ratio of attn:  tensor(0.8093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7050, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7478171885140259
Current compression ratio of attn:  tensor(0.8063, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.747900894529663
Current compression ratio of attn:  tensor(0.8056, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7080, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7479829662912036
Current compression ratio of attn:  tensor(0.8078, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7480634036193109
Current compression ratio of attn:  tensor(0.8075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7481422063382196
Current compression ratio of attn:  tensor(0.8119, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7482193742757361
Current compression ratio of attn:  tensor(0.8115, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7054, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7482949072632391
Current compression ratio of attn:  tensor(0.8129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.74836880513568
Current compression ratio of attn:  tensor(0.8099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7484410677315831
Search Epoch: [8]  [15000/23614]  eta: 1:39:12  lr: 0.00001000  loss: 8.9798  loss_ita: 5.7140  loss_sp_attn: 1.2845  loss_sp_mlp: 1.9813  time: 0.7057  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.8135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7485116948930456
Current compression ratio of attn:  tensor(0.8131, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7485806864657386
Current compression ratio of attn:  tensor(0.8123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7486480422989074
Current compression ratio of attn:  tensor(0.8120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7487137622453711
Current compression ratio of attn:  tensor(0.8094, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7487778461615238
Current compression ratio of attn:  tensor(0.8099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7488402939073343
Current compression ratio of attn:  tensor(0.8130, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7489011053463468
Current compression ratio of attn:  tensor(0.8122, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7489602803456807
Current compression ratio of attn:  tensor(0.8140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7490178187760318
Current compression ratio of attn:  tensor(0.8132, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7490737205116714
Current compression ratio of attn:  tensor(0.8129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7491279854304475
Current compression ratio of attn:  tensor(0.8129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7491806134137846
Current compression ratio of attn:  tensor(0.8112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7086, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7492316043466845
Current compression ratio of attn:  tensor(0.8109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7090, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7492809581177254
Current compression ratio of attn:  tensor(0.8087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7102, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7493286746190636
Current compression ratio of attn:  tensor(0.8140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7493747537464328
Current compression ratio of attn:  tensor(0.8145, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7494191953991441
Current compression ratio of attn:  tensor(0.8154, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7494619994800877
Current compression ratio of attn:  tensor(0.8150, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7495031658957312
Current compression ratio of attn:  tensor(0.8150, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7495426945561209
Current compression ratio of attn:  tensor(0.8129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.749580585374882
Current compression ratio of attn:  tensor(0.8121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496168382692184
Current compression ratio of attn:  tensor(0.8130, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496514531599132
Current compression ratio of attn:  tensor(0.8152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496844299713288
Current compression ratio of attn:  tensor(0.8109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7104, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497157686314065
Search Epoch: [8]  [20000/23614]  eta: 0:41:38  lr: 0.00001000  loss: 9.7866  loss_ita: 6.5512  loss_sp_attn: 1.2781  loss_sp_mlp: 1.9574  time: 0.7008  data: 0.0001  max mem: 28228
Current compression ratio of attn:  tensor(0.8135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497454690716681
Current compression ratio of attn:  tensor(0.8136, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497735312272139
Current compression ratio of attn:  tensor(0.8162, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.749799955036725
Current compression ratio of attn:  tensor(0.8136, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498247404424623
Current compression ratio of attn:  tensor(0.8106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498478873902663
Current compression ratio of attn:  tensor(0.8115, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498693958295586
Current compression ratio of attn:  tensor(0.8128, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7096, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498892657133402
Current compression ratio of attn:  tensor(0.8120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7098, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499074969981934
Current compression ratio of attn:  tensor(0.8168, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7072, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499240896442805
Current compression ratio of attn:  tensor(0.8150, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499390436153444
Current compression ratio of attn:  tensor(0.8120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499523588787088
Current compression ratio of attn:  tensor(0.8138, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7094, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499640354052786
Current compression ratio of attn:  tensor(0.8142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499740731695388
Current compression ratio of attn:  tensor(0.8120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499824721495559
Current compression ratio of attn:  tensor(0.8129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499892323269771
Current compression ratio of attn:  tensor(0.8134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7098, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499943536870305
Current compression ratio of attn:  tensor(0.8147, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499978362185253
Current compression ratio of attn:  tensor(0.8112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7111, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.749999679913852
Current compression ratio of attn:  tensor(0.8116, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7108, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.75
Search Epoch: [8]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 10.7927  loss_ita: 7.5642  loss_sp_attn: 1.2760  loss_sp_mlp: 1.9525  time: 0.6898  data: 0.0005  max mem: 28228
Search Epoch: [8] Total time: 4:31:58 (0.6910 s / it)
Averaged stats: lr: 0.0000  loss: 9.8690  loss_ita: 6.5364  loss_sp_attn: 1.3277  loss_sp_mlp: 2.0049
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
do itm_eval
search_result {'txt_r1': 16.7, 'txt_r5': 38.06, 'txt_r10': 50.36, 'txt_r_mean': 35.04, 'img_r1': 13.550579768092764, 'img_r5': 35.0499800079968, 'img_r10': 48.02878848460616, 'img_r_mean': 32.20978275356524, 'r_mean': 33.62489137678262}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: -0.0558
Text_CKA_Similarity: 0.2036
Image_Cosine_Similarity: 0.0351
Image_CKA_Similarity: 0.5475
sim_matrix_pearson_correlation: 0.2187
model_search_8.pth saved
mask_attn_vision:   [1.56, 1.56, 6.25, 1.56, 1.56, 1.56, 46.88, 21.88, 39.06, 37.5, 45.31, 39.06, 23.44, 39.06, 40.62, 21.88, 20.31, 15.62, 14.06, 9.38, 12.5, 7.81, 7.81, 9.38]
mask_attn_language:  [87.5, 48.44, 15.62, 7.81, 1.56, 6.25, 3.12, 6.25, 6.25, 9.38, 9.38, 10.94]
mask_mlp_vision:  [27.51, 17.6, 21.8, 21.61, 28.96, 23.8, 33.3, 33.54, 43.63, 52.59, 49.44, 49.51, 59.11, 51.61, 46.85, 41.8, 24.95, 15.72, 12.55, 11.69, 15.75, 17.85, 18.12, 13.31]
mask_mlp_language:  [76.33, 22.66, 21.32, 19.17, 23.63, 23.54, 23.21, 17.55, 15.33, 15.43, 16.08, 21.45]
mask_vision:  0.30353567004203796
mask_language:  0.24500425159931183
mask_attn:  0.1883680522441864
mask_mlp:  0.28920307755470276
Creating model for training
VisionTransformerを作成
Start training
KD:False
Train Epoch: [0]  [    0/23614]  eta: 4:22:28  lr: 0.00001000  loss: 8.1916  time: 0.6669  data: 0.1760  max mem: 28228
KD is False
Train Epoch: [0]  [ 5000/23614]  eta: 2:04:33  lr: 0.00001000  loss: 3.8474  time: 0.3984  data: 0.0001  max mem: 28228
Train Epoch: [0]  [10000/23614]  eta: 1:31:07  lr: 0.00001000  loss: 4.9292  time: 0.3990  data: 0.0001  max mem: 28228
Train Epoch: [0]  [15000/23614]  eta: 0:57:39  lr: 0.00001000  loss: 4.1546  time: 0.3998  data: 0.0001  max mem: 28228
Train Epoch: [0]  [20000/23614]  eta: 0:24:09  lr: 0.00001000  loss: 4.6292  time: 0.4002  data: 0.0001  max mem: 28228
Train Epoch: [0]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 2.8432  time: 0.4006  data: 0.0005  max mem: 28228
Train Epoch: [0] Total time: 2:37:49 (0.4010 s / it)
Averaged stats: lr: 0.0000  loss: 4.0550
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0336
Text_CKA_Similarity: 0.4811
Image_Cosine_Similarity: 0.0866
Image_CKA_Similarity: 0.6974
sim_matrix_pearson_correlation: 0.5644
{'txt_r1': 48.66, 'txt_r5': 76.7, 'txt_r10': 86.24, 'txt_r_mean': 70.53333333333333, 'img_r1': 35.80167932826869, 'img_r5': 65.56177528988404, 'img_r10': 76.71731307477009, 'img_r_mean': 59.36025589764094, 'r_mean': 64.94679461548714}
{'txt_r1': 48.4, 'txt_r5': 75.76, 'txt_r10': 85.66, 'txt_r_mean': 69.94, 'img_r1': 35.373850459816076, 'img_r5': 65.11395441823271, 'img_r10': 76.24550179928029, 'img_r_mean': 58.91110222577637, 'r_mean': 64.42555111288819}
LOG:  {'train_lr': '0.000', 'train_loss': '4.055', 'val_txt_r1': 48.66, 'val_txt_r5': 76.7, 'val_txt_r10': 86.24, 'val_txt_r_mean': 70.53333333333333, 'val_img_r1': 35.80167932826869, 'val_img_r5': 65.56177528988404, 'val_img_r10': 76.71731307477009, 'val_img_r_mean': 59.36025589764094, 'val_r_mean': 64.94679461548714, 'test_txt_r1': 48.4, 'test_txt_r5': 75.76, 'test_txt_r10': 85.66, 'test_txt_r_mean': 69.94, 'test_img_r1': 35.373850459816076, 'test_img_r5': 65.11395441823271, 'test_img_r10': 76.24550179928029, 'test_img_r_mean': 58.91110222577637, 'test_r_mean': 64.42555111288819, 'epoch': 0, 'best_epoch': 0}
KD:False
Train Epoch: [1]  [    0/23614]  eta: 4:16:29  lr: 0.00000970  loss: 4.8254  time: 0.6517  data: 0.1639  max mem: 28228
KD is False
Train Epoch: [1]  [ 5000/23614]  eta: 2:04:29  lr: 0.00000970  loss: 3.4927  time: 0.4031  data: 0.0001  max mem: 28228
Train Epoch: [1]  [10000/23614]  eta: 1:30:53  lr: 0.00000970  loss: 2.8221  time: 0.4062  data: 0.0001  max mem: 28228
Train Epoch: [1]  [15000/23614]  eta: 0:57:31  lr: 0.00000970  loss: 3.0504  time: 0.4025  data: 0.0001  max mem: 28228
Train Epoch: [1]  [20000/23614]  eta: 0:24:10  lr: 0.00000970  loss: 4.2399  time: 0.4048  data: 0.0001  max mem: 28228
Train Epoch: [1]  [23613/23614]  eta: 0:00:00  lr: 0.00000970  loss: 3.3514  time: 0.3907  data: 0.0005  max mem: 28228
Train Epoch: [1] Total time: 2:37:56 (0.4013 s / it)
Averaged stats: lr: 0.0000  loss: 3.7161
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0098
Text_CKA_Similarity: 0.4838
Image_Cosine_Similarity: 0.0519
Image_CKA_Similarity: 0.6976
sim_matrix_pearson_correlation: 0.5592
{'txt_r1': 52.26, 'txt_r5': 79.94, 'txt_r10': 88.56, 'txt_r_mean': 73.58666666666666, 'img_r1': 38.79248300679728, 'img_r5': 68.75649740103958, 'img_r10': 79.50019992003199, 'img_r_mean': 62.34972677595628, 'r_mean': 67.96819672131147}
{'txt_r1': 51.32, 'txt_r5': 79.64, 'txt_r10': 88.26, 'txt_r_mean': 73.07333333333334, 'img_r1': 38.68052778888445, 'img_r5': 68.14474210315873, 'img_r10': 78.86045581767293, 'img_r_mean': 61.895241903238706, 'r_mean': 67.48428761828602}
LOG:  {'train_lr': '0.000', 'train_loss': '3.716', 'val_txt_r1': 52.26, 'val_txt_r5': 79.94, 'val_txt_r10': 88.56, 'val_txt_r_mean': 73.58666666666666, 'val_img_r1': 38.79248300679728, 'val_img_r5': 68.75649740103958, 'val_img_r10': 79.50019992003199, 'val_img_r_mean': 62.34972677595628, 'val_r_mean': 67.96819672131147, 'test_txt_r1': 51.32, 'test_txt_r5': 79.64, 'test_txt_r10': 88.26, 'test_txt_r_mean': 73.07333333333334, 'test_img_r1': 38.68052778888445, 'test_img_r5': 68.14474210315873, 'test_img_r10': 78.86045581767293, 'test_img_r_mean': 61.895241903238706, 'test_r_mean': 67.48428761828602, 'epoch': 1, 'best_epoch': 1}
KD:False
Train Epoch: [2]  [    0/23614]  eta: 4:04:00  lr: 0.00000883  loss: 4.4097  time: 0.6200  data: 0.1380  max mem: 28228
KD is False
Train Epoch: [2]  [ 5000/23614]  eta: 2:04:27  lr: 0.00000883  loss: 3.7951  time: 0.4006  data: 0.0001  max mem: 28228
Train Epoch: [2]  [10000/23614]  eta: 1:30:58  lr: 0.00000883  loss: 2.7840  time: 0.3947  data: 0.0001  max mem: 28228
Train Epoch: [2]  [15000/23614]  eta: 0:57:31  lr: 0.00000883  loss: 4.5630  time: 0.3966  data: 0.0001  max mem: 28228
Train Epoch: [2]  [20000/23614]  eta: 0:24:08  lr: 0.00000883  loss: 3.3177  time: 0.4065  data: 0.0001  max mem: 28228
Train Epoch: [2]  [23613/23614]  eta: 0:00:00  lr: 0.00000883  loss: 1.9363  time: 0.3931  data: 0.0006  max mem: 28228
Train Epoch: [2] Total time: 2:37:51 (0.4011 s / it)
Averaged stats: lr: 0.0000  loss: 3.4775
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: -0.0039
Text_CKA_Similarity: 0.4795
Image_Cosine_Similarity: 0.0641
Image_CKA_Similarity: 0.6817
sim_matrix_pearson_correlation: 0.5435
{'txt_r1': 55.64, 'txt_r5': 82.4, 'txt_r10': 90.0, 'txt_r_mean': 76.01333333333334, 'img_r1': 40.831667333066775, 'img_r5': 69.66013594562175, 'img_r10': 79.99200319872051, 'img_r_mean': 63.49460215913634, 'r_mean': 69.75396774623484}
{'txt_r1': 53.72, 'txt_r5': 81.5, 'txt_r10': 89.68, 'txt_r_mean': 74.96666666666667, 'img_r1': 39.45221911235506, 'img_r5': 68.72850859656137, 'img_r10': 79.36425429828068, 'img_r_mean': 62.51499400239904, 'r_mean': 68.74083033453286}
LOG:  {'train_lr': '0.000', 'train_loss': '3.477', 'val_txt_r1': 55.64, 'val_txt_r5': 82.4, 'val_txt_r10': 90.0, 'val_txt_r_mean': 76.01333333333334, 'val_img_r1': 40.831667333066775, 'val_img_r5': 69.66013594562175, 'val_img_r10': 79.99200319872051, 'val_img_r_mean': 63.49460215913634, 'val_r_mean': 69.75396774623484, 'test_txt_r1': 53.72, 'test_txt_r5': 81.5, 'test_txt_r10': 89.68, 'test_txt_r_mean': 74.96666666666667, 'test_img_r1': 39.45221911235506, 'test_img_r5': 68.72850859656137, 'test_img_r10': 79.36425429828068, 'test_img_r_mean': 62.51499400239904, 'test_r_mean': 68.74083033453286, 'epoch': 2, 'best_epoch': 2}
KD:False
Train Epoch: [3]  [    0/23614]  eta: 4:11:27  lr: 0.00000750  loss: 4.3732  time: 0.6389  data: 0.1600  max mem: 28228
KD is False
Train Epoch: [3]  [ 5000/23614]  eta: 2:04:43  lr: 0.00000750  loss: 3.9760  time: 0.3998  data: 0.0001  max mem: 28228
Train Epoch: [3]  [10000/23614]  eta: 1:31:12  lr: 0.00000750  loss: 2.9017  time: 0.3975  data: 0.0001  max mem: 28228
Train Epoch: [3]  [15000/23614]  eta: 0:57:45  lr: 0.00000750  loss: 2.6774  time: 0.4045  data: 0.0001  max mem: 28228
Train Epoch: [3]  [20000/23614]  eta: 0:24:14  lr: 0.00000750  loss: 2.5331  time: 0.4028  data: 0.0001  max mem: 28228
Train Epoch: [3]  [23613/23614]  eta: 0:00:00  lr: 0.00000750  loss: 2.6678  time: 0.3954  data: 0.0006  max mem: 28228
Train Epoch: [3] Total time: 2:38:14 (0.4021 s / it)
Averaged stats: lr: 0.0000  loss: 3.2839
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0153
Text_CKA_Similarity: 0.4716
Image_Cosine_Similarity: 0.0356
Image_CKA_Similarity: 0.6769
sim_matrix_pearson_correlation: 0.5411
{'txt_r1': 56.32, 'txt_r5': 83.48, 'txt_r10': 90.9, 'txt_r_mean': 76.9, 'img_r1': 42.07117153138744, 'img_r5': 71.28348660535785, 'img_r10': 81.2235105957617, 'img_r_mean': 64.85938957750233, 'r_mean': 70.87969478875117}
{'txt_r1': 55.44, 'txt_r5': 82.48, 'txt_r10': 90.08, 'txt_r_mean': 76.0, 'img_r1': 41.5953618552579, 'img_r5': 70.84366253498601, 'img_r10': 80.73170731707317, 'img_r_mean': 64.39024390243902, 'r_mean': 70.1951219512195}
LOG:  {'train_lr': '0.000', 'train_loss': '3.284', 'val_txt_r1': 56.32, 'val_txt_r5': 83.48, 'val_txt_r10': 90.9, 'val_txt_r_mean': 76.9, 'val_img_r1': 42.07117153138744, 'val_img_r5': 71.28348660535785, 'val_img_r10': 81.2235105957617, 'val_img_r_mean': 64.85938957750233, 'val_r_mean': 70.87969478875117, 'test_txt_r1': 55.44, 'test_txt_r5': 82.48, 'test_txt_r10': 90.08, 'test_txt_r_mean': 76.0, 'test_img_r1': 41.5953618552579, 'test_img_r5': 70.84366253498601, 'test_img_r10': 80.73170731707317, 'test_img_r_mean': 64.39024390243902, 'test_r_mean': 70.1951219512195, 'epoch': 3, 'best_epoch': 3}
KD:False
Train Epoch: [4]  [    0/23614]  eta: 4:18:04  lr: 0.00000587  loss: 2.2465  time: 0.6558  data: 0.1624  max mem: 28228
KD is False
Train Epoch: [4]  [ 5000/23614]  eta: 2:04:31  lr: 0.00000587  loss: 2.9496  time: 0.4071  data: 0.0001  max mem: 28228
Train Epoch: [4]  [10000/23614]  eta: 1:30:57  lr: 0.00000587  loss: 3.6328  time: 0.4006  data: 0.0001  max mem: 28228
Train Epoch: [4]  [15000/23614]  eta: 0:57:36  lr: 0.00000587  loss: 3.4493  time: 0.4010  data: 0.0001  max mem: 28228
Train Epoch: [4]  [20000/23614]  eta: 0:24:09  lr: 0.00000587  loss: 3.1056  time: 0.4000  data: 0.0001  max mem: 28228
Train Epoch: [4]  [23613/23614]  eta: 0:00:00  lr: 0.00000587  loss: 2.1995  time: 0.3968  data: 0.0005  max mem: 28228
Train Epoch: [4] Total time: 2:37:54 (0.4012 s / it)
Averaged stats: lr: 0.0000  loss: 3.1042
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0201
Text_CKA_Similarity: 0.4656
Image_Cosine_Similarity: 0.0402
Image_CKA_Similarity: 0.6608
sim_matrix_pearson_correlation: 0.5378
{'txt_r1': 57.08, 'txt_r5': 83.84, 'txt_r10': 90.92, 'txt_r_mean': 77.28000000000002, 'img_r1': 42.566973210715716, 'img_r5': 71.95921631347461, 'img_r10': 81.46741303478609, 'img_r_mean': 65.33120085299214, 'r_mean': 71.30560042649608}
{'txt_r1': 56.98, 'txt_r5': 83.04, 'txt_r10': 90.22, 'txt_r_mean': 76.74666666666667, 'img_r1': 42.18712514994002, 'img_r5': 70.73570571771292, 'img_r10': 80.88764494202319, 'img_r_mean': 64.60349193655871, 'r_mean': 70.6750793016127}
LOG:  {'train_lr': '0.000', 'train_loss': '3.104', 'val_txt_r1': 57.08, 'val_txt_r5': 83.84, 'val_txt_r10': 90.92, 'val_txt_r_mean': 77.28000000000002, 'val_img_r1': 42.566973210715716, 'val_img_r5': 71.95921631347461, 'val_img_r10': 81.46741303478609, 'val_img_r_mean': 65.33120085299214, 'val_r_mean': 71.30560042649608, 'test_txt_r1': 56.98, 'test_txt_r5': 83.04, 'test_txt_r10': 90.22, 'test_txt_r_mean': 76.74666666666667, 'test_img_r1': 42.18712514994002, 'test_img_r5': 70.73570571771292, 'test_img_r10': 80.88764494202319, 'test_img_r_mean': 64.60349193655871, 'test_r_mean': 70.6750793016127, 'epoch': 4, 'best_epoch': 4}
KD:False
Train Epoch: [5]  [    0/23614]  eta: 4:19:20  lr: 0.00000413  loss: 3.1107  time: 0.6590  data: 0.1581  max mem: 28228
KD is False
Train Epoch: [5]  [ 5000/23614]  eta: 2:04:26  lr: 0.00000413  loss: 3.4386  time: 0.3996  data: 0.0001  max mem: 28228
Train Epoch: [5]  [10000/23614]  eta: 1:30:57  lr: 0.00000413  loss: 2.4945  time: 0.3973  data: 0.0001  max mem: 28228
Train Epoch: [5]  [15000/23614]  eta: 0:57:36  lr: 0.00000413  loss: 2.4433  time: 0.3994  data: 0.0001  max mem: 28228
Train Epoch: [5]  [20000/23614]  eta: 0:24:11  lr: 0.00000413  loss: 3.0660  time: 0.3988  data: 0.0001  max mem: 28228
Train Epoch: [5]  [23613/23614]  eta: 0:00:00  lr: 0.00000413  loss: 2.6956  time: 0.3926  data: 0.0005  max mem: 28228
Train Epoch: [5] Total time: 2:38:07 (0.4018 s / it)
Averaged stats: lr: 0.0000  loss: 2.9322
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0575
Text_CKA_Similarity: 0.4388
Image_Cosine_Similarity: 0.0555
Image_CKA_Similarity: 0.6455
sim_matrix_pearson_correlation: 0.5161
{'txt_r1': 58.78, 'txt_r5': 85.12, 'txt_r10': 92.06, 'txt_r_mean': 78.65333333333334, 'img_r1': 43.154738104758096, 'img_r5': 72.35105957616953, 'img_r10': 81.9672131147541, 'img_r_mean': 65.82433693189391, 'r_mean': 72.23883513261362}
{'txt_r1': 58.36, 'txt_r5': 84.64, 'txt_r10': 91.06, 'txt_r_mean': 78.02, 'img_r1': 42.82686925229908, 'img_r5': 71.71131547381047, 'img_r10': 81.7872850859656, 'img_r_mean': 65.44182327069173, 'r_mean': 71.73091163534586}
LOG:  {'train_lr': '0.000', 'train_loss': '2.932', 'val_txt_r1': 58.78, 'val_txt_r5': 85.12, 'val_txt_r10': 92.06, 'val_txt_r_mean': 78.65333333333334, 'val_img_r1': 43.154738104758096, 'val_img_r5': 72.35105957616953, 'val_img_r10': 81.9672131147541, 'val_img_r_mean': 65.82433693189391, 'val_r_mean': 72.23883513261362, 'test_txt_r1': 58.36, 'test_txt_r5': 84.64, 'test_txt_r10': 91.06, 'test_txt_r_mean': 78.02, 'test_img_r1': 42.82686925229908, 'test_img_r5': 71.71131547381047, 'test_img_r10': 81.7872850859656, 'test_img_r_mean': 65.44182327069173, 'test_r_mean': 71.73091163534586, 'epoch': 5, 'best_epoch': 5}
KD:False
Train Epoch: [6]  [    0/23614]  eta: 4:10:22  lr: 0.00000250  loss: 3.9636  time: 0.6362  data: 0.1792  max mem: 28228
KD is False
Train Epoch: [6]  [ 5000/23614]  eta: 2:04:32  lr: 0.00000250  loss: 1.7824  time: 0.4003  data: 0.0001  max mem: 28228
Train Epoch: [6]  [10000/23614]  eta: 1:31:13  lr: 0.00000250  loss: 4.0226  time: 0.4017  data: 0.0001  max mem: 28228
Train Epoch: [6]  [15000/23614]  eta: 0:57:40  lr: 0.00000250  loss: 2.2626  time: 0.4004  data: 0.0001  max mem: 28228
Train Epoch: [6]  [20000/23614]  eta: 0:24:11  lr: 0.00000250  loss: 2.7422  time: 0.4040  data: 0.0001  max mem: 28228
Train Epoch: [6]  [23613/23614]  eta: 0:00:00  lr: 0.00000250  loss: 2.4988  time: 0.3925  data: 0.0006  max mem: 28228
Train Epoch: [6] Total time: 2:38:07 (0.4018 s / it)
Averaged stats: lr: 0.0000  loss: 2.7758
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0375
Text_CKA_Similarity: 0.4158
Image_Cosine_Similarity: 0.0204
Image_CKA_Similarity: 0.6216
sim_matrix_pearson_correlation: 0.5045
{'txt_r1': 59.12, 'txt_r5': 85.4, 'txt_r10': 92.28, 'txt_r_mean': 78.93333333333334, 'img_r1': 44.062375049980005, 'img_r5': 72.88684526189525, 'img_r10': 82.32307077169132, 'img_r_mean': 66.42409702785552, 'r_mean': 72.67871518059442}
{'txt_r1': 59.98, 'txt_r5': 84.66, 'txt_r10': 91.1, 'txt_r_mean': 78.58, 'img_r1': 43.514594162335065, 'img_r5': 72.24310275889644, 'img_r10': 81.75929628148741, 'img_r_mean': 65.83899773423964, 'r_mean': 72.20949886711982}
LOG:  {'train_lr': '0.000', 'train_loss': '2.776', 'val_txt_r1': 59.12, 'val_txt_r5': 85.4, 'val_txt_r10': 92.28, 'val_txt_r_mean': 78.93333333333334, 'val_img_r1': 44.062375049980005, 'val_img_r5': 72.88684526189525, 'val_img_r10': 82.32307077169132, 'val_img_r_mean': 66.42409702785552, 'val_r_mean': 72.67871518059442, 'test_txt_r1': 59.98, 'test_txt_r5': 84.66, 'test_txt_r10': 91.1, 'test_txt_r_mean': 78.58, 'test_img_r1': 43.514594162335065, 'test_img_r5': 72.24310275889644, 'test_img_r10': 81.75929628148741, 'test_img_r_mean': 65.83899773423964, 'test_r_mean': 72.20949886711982, 'epoch': 6, 'best_epoch': 6}
KD:False
Train Epoch: [7]  [    0/23614]  eta: 4:24:38  lr: 0.00000117  loss: 2.5800  time: 0.6724  data: 0.1737  max mem: 28228
KD is False
Train Epoch: [7]  [ 5000/23614]  eta: 2:04:38  lr: 0.00000117  loss: 3.1048  time: 0.3977  data: 0.0001  max mem: 28228
Train Epoch: [7]  [10000/23614]  eta: 1:31:08  lr: 0.00000117  loss: 2.5735  time: 0.3969  data: 0.0001  max mem: 28228
Train Epoch: [7]  [15000/23614]  eta: 0:57:33  lr: 0.00000117  loss: 2.1462  time: 0.4030  data: 0.0001  max mem: 28228
Train Epoch: [7]  [20000/23614]  eta: 0:24:09  lr: 0.00000117  loss: 3.8087  time: 0.4008  data: 0.0001  max mem: 28228
Train Epoch: [7]  [23613/23614]  eta: 0:00:00  lr: 0.00000117  loss: 2.2910  time: 0.3978  data: 0.0006  max mem: 28228
Train Epoch: [7] Total time: 2:37:55 (0.4013 s / it)
Averaged stats: lr: 0.0000  loss: 2.6665
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0574
Text_CKA_Similarity: 0.4042
Image_Cosine_Similarity: 0.0216
Image_CKA_Similarity: 0.6073
sim_matrix_pearson_correlation: 0.4844
{'txt_r1': 60.18, 'txt_r5': 85.66, 'txt_r10': 92.44, 'txt_r_mean': 79.42666666666666, 'img_r1': 44.33426629348261, 'img_r5': 72.93882447021191, 'img_r10': 82.53498600559776, 'img_r_mean': 66.60269225643076, 'r_mean': 73.01467946154871}
{'txt_r1': 60.02, 'txt_r5': 85.14, 'txt_r10': 91.48, 'txt_r_mean': 78.88, 'img_r1': 43.638544582167135, 'img_r5': 71.97520991603359, 'img_r10': 81.66333466613355, 'img_r_mean': 65.75902972144476, 'r_mean': 72.31951486072238}
LOG:  {'train_lr': '0.000', 'train_loss': '2.666', 'val_txt_r1': 60.18, 'val_txt_r5': 85.66, 'val_txt_r10': 92.44, 'val_txt_r_mean': 79.42666666666666, 'val_img_r1': 44.33426629348261, 'val_img_r5': 72.93882447021191, 'val_img_r10': 82.53498600559776, 'val_img_r_mean': 66.60269225643076, 'val_r_mean': 73.01467946154871, 'test_txt_r1': 60.02, 'test_txt_r5': 85.14, 'test_txt_r10': 91.48, 'test_txt_r_mean': 78.88, 'test_img_r1': 43.638544582167135, 'test_img_r5': 71.97520991603359, 'test_img_r10': 81.66333466613355, 'test_img_r_mean': 65.75902972144476, 'test_r_mean': 72.31951486072238, 'epoch': 7, 'best_epoch': 7}
KD:False
Train Epoch: [8]  [    0/23614]  eta: 4:21:49  lr: 0.00000030  loss: 1.5074  time: 0.6652  data: 0.1722  max mem: 28228
KD is False
Train Epoch: [8]  [ 5000/23614]  eta: 2:04:30  lr: 0.00000030  loss: 2.1026  time: 0.4027  data: 0.0001  max mem: 28228
Train Epoch: [8]  [10000/23614]  eta: 1:31:07  lr: 0.00000030  loss: 2.1932  time: 0.3979  data: 0.0001  max mem: 28228
Train Epoch: [8]  [15000/23614]  eta: 0:57:38  lr: 0.00000030  loss: 2.7069  time: 0.3996  data: 0.0001  max mem: 28228
Train Epoch: [8]  [20000/23614]  eta: 0:24:10  lr: 0.00000030  loss: 2.4902  time: 0.4047  data: 0.0001  max mem: 28228
Train Epoch: [8]  [23613/23614]  eta: 0:00:00  lr: 0.00000030  loss: 3.8261  time: 0.3968  data: 0.0005  max mem: 28228
Train Epoch: [8] Total time: 2:38:01 (0.4015 s / it)
Averaged stats: lr: 0.0000  loss: 2.6308
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.669995203381404e-05
max_val 4.954875839757733e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0164
Text_CKA_Similarity: 0.3953
Image_Cosine_Similarity: 0.0397
Image_CKA_Similarity: 0.6010
sim_matrix_pearson_correlation: 0.4958
{'txt_r1': 59.3, 'txt_r5': 85.32, 'txt_r10': 92.28, 'txt_r_mean': 78.96666666666667, 'img_r1': 44.32626949220312, 'img_r5': 73.05077968812475, 'img_r10': 82.6109556177529, 'img_r_mean': 66.66266826602693, 'r_mean': 72.8146674663468}
LOG:  {'train_lr': '0.000', 'train_loss': '2.631', 'val_txt_r1': 59.3, 'val_txt_r5': 85.32, 'val_txt_r10': 92.28, 'val_txt_r_mean': 78.96666666666667, 'val_img_r1': 44.32626949220312, 'val_img_r5': 73.05077968812475, 'val_img_r10': 82.6109556177529, 'val_img_r_mean': 66.66266826602693, 'val_r_mean': 72.8146674663468, 'test_txt_r1': 60.02, 'test_txt_r5': 85.14, 'test_txt_r10': 91.48, 'test_txt_r_mean': 78.88, 'test_img_r1': 43.638544582167135, 'test_img_r5': 71.97520991603359, 'test_img_r10': 81.66333466613355, 'test_img_r_mean': 65.75902972144476, 'test_r_mean': 72.31951486072238, 'epoch': 8, 'best_epoch': 7}
