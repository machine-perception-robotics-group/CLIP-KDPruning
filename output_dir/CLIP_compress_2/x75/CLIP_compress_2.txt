| distributed init (rank 2, word 4): env://
| distributed init (rank 1, word 4): env://
| distributed init (rank 3, word 4): env://
| distributed init (rank 0, word 4): env://
node02:1494859:1494859 [0] NCCL INFO Bootstrap : Using eno1:192.168.170.52<0>
node02:1494859:1494859 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node02:1494859:1494859 [0] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.52<0> [1]eno2:10.0.0.2<0>
node02:1494859:1494859 [0] NCCL INFO Using network Socket
NCCL version 2.10.3+cuda11.3
node02:1494861:1494861 [2] NCCL INFO Bootstrap : Using eno1:192.168.170.52<0>
node02:1494861:1494861 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node02:1494861:1494861 [2] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.52<0> [1]eno2:10.0.0.2<0>
node02:1494861:1494861 [2] NCCL INFO Using network Socket
node02:1494860:1494860 [1] NCCL INFO Bootstrap : Using eno1:192.168.170.52<0>
node02:1494860:1494860 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node02:1494860:1494860 [1] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.52<0> [1]eno2:10.0.0.2<0>
node02:1494860:1494860 [1] NCCL INFO Using network Socket
node02:1494862:1494862 [3] NCCL INFO Bootstrap : Using eno1:192.168.170.52<0>
node02:1494862:1494862 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node02:1494862:1494862 [3] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.52<0> [1]eno2:10.0.0.2<0>
node02:1494862:1494862 [3] NCCL INFO Using network Socket
node02:1494861:1494913 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
node02:1494861:1494913 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,ffff0000
node02:1494862:1494915 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
node02:1494862:1494915 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,ffff0000
node02:1494859:1494912 [0] NCCL INFO Channel 00/02 :    0   1   2   3
node02:1494859:1494912 [0] NCCL INFO Channel 01/02 :    0   1   2   3
node02:1494859:1494912 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
node02:1494859:1494912 [0] NCCL INFO Setting affinity for GPU 0 to ffff,0000ffff
node02:1494860:1494914 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
node02:1494860:1494914 [1] NCCL INFO Setting affinity for GPU 1 to ffff,0000ffff
node02:1494859:1494912 [0] NCCL INFO Channel 00 : 0[2a000] -> 1[3d000] via direct shared memory
node02:1494862:1494915 [3] NCCL INFO Channel 00 : 3[bd000] -> 0[2a000] via direct shared memory
node02:1494861:1494913 [2] NCCL INFO Channel 00 : 2[ab000] -> 3[bd000] via direct shared memory
node02:1494860:1494914 [1] NCCL INFO Channel 00 : 1[3d000] -> 2[ab000] via direct shared memory
node02:1494859:1494912 [0] NCCL INFO Channel 01 : 0[2a000] -> 1[3d000] via direct shared memory
node02:1494862:1494915 [3] NCCL INFO Channel 01 : 3[bd000] -> 0[2a000] via direct shared memory
node02:1494861:1494913 [2] NCCL INFO Channel 01 : 2[ab000] -> 3[bd000] via direct shared memory
node02:1494860:1494914 [1] NCCL INFO Channel 01 : 1[3d000] -> 2[ab000] via direct shared memory
node02:1494859:1494912 [0] NCCL INFO Connected all rings
node02:1494861:1494913 [2] NCCL INFO Connected all rings
node02:1494862:1494915 [3] NCCL INFO Connected all rings
node02:1494860:1494914 [1] NCCL INFO Connected all rings
node02:1494862:1494915 [3] NCCL INFO Channel 00 : 3[bd000] -> 2[ab000] via direct shared memory
node02:1494862:1494915 [3] NCCL INFO Channel 01 : 3[bd000] -> 2[ab000] via direct shared memory
node02:1494861:1494913 [2] NCCL INFO Channel 00 : 2[ab000] -> 1[3d000] via direct shared memory
node02:1494861:1494913 [2] NCCL INFO Channel 01 : 2[ab000] -> 1[3d000] via direct shared memory
node02:1494860:1494914 [1] NCCL INFO Channel 00 : 1[3d000] -> 0[2a000] via direct shared memory
node02:1494860:1494914 [1] NCCL INFO Channel 01 : 1[3d000] -> 0[2a000] via direct shared memory
node02:1494859:1494912 [0] NCCL INFO Connected all trees
node02:1494859:1494912 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node02:1494859:1494912 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node02:1494862:1494915 [3] NCCL INFO Connected all trees
node02:1494862:1494915 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node02:1494862:1494915 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node02:1494860:1494914 [1] NCCL INFO Connected all trees
node02:1494860:1494914 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node02:1494860:1494914 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node02:1494861:1494913 [2] NCCL INFO Connected all trees
node02:1494861:1494913 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node02:1494861:1494913 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node02:1494862:1494915 [3] NCCL INFO comm 0x7c7c9c003070 rank 3 nranks 4 cudaDev 3 busId bd000 - Init COMPLETE
node02:1494860:1494914 [1] NCCL INFO comm 0x7e3f8c003070 rank 1 nranks 4 cudaDev 1 busId 3d000 - Init COMPLETE
node02:1494861:1494913 [2] NCCL INFO comm 0x79f7d8003070 rank 2 nranks 4 cudaDev 2 busId ab000 - Init COMPLETE
node02:1494859:1494912 [0] NCCL INFO comm 0x7055dc003070 rank 0 nranks 4 cudaDev 0 busId 2a000 - Init COMPLETE
node02:1494859:1494859 [0] NCCL INFO Launch mode Parallel
Target compression ratio: 75.0%
Creating retrieval dataset
Using downloaded and verified file: annotation/coco_karpathy_train.json
Using downloaded and verified file: annotation/coco_karpathy_val.json
Using downloaded and verified file: annotation/coco_karpathy_test.json
Creating model for searching
VisionTransformerを作成
VisionTransformerを作成
teacher_model evaluation
Computing features for evaluation...
do itm_eval
test_result_teacher {'txt_r1': 71.48, 'txt_r5': 90.82, 'txt_r10': 95.42, 'txt_r_mean': 85.90666666666668, 'img_r1': 56.80127948820472, 'img_r5': 80.57976809276289, 'img_r10': 87.64894042383047, 'img_r_mean': 75.00999600159936, 'r_mean': 80.45833133413302}
KD False
Start searching
KD:False
Current compression ratio of attn:  tensor(0., device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0., device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  7.3912862300216045e-06
Search Epoch: [0]  [    0/17710]  eta: 16:03:37  lr: 0.00001000  loss: 17.0912  loss_ita: 3.5744  loss_sp_attn: 6.7584  loss_sp_mlp: 6.7584  time: 3.2647  data: 1.9513  max mem: 25624
KD is False
Current compression ratio of attn:  tensor(4.2319e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(1.9073e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0014856477282517901
Current compression ratio of attn:  tensor(1.3769e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(1.0371e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.002963898397875447
Current compression ratio of attn:  tensor(3.0816e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(2.3544e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.004442137553113352
Current compression ratio of attn:  tensor(5.1260e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(4.3809e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.005920359451184036
Current compression ratio of attn:  tensor(8.1360e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(6.7711e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0073985583493792785
Current compression ratio of attn:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(9.1851e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.008876728505071634
Current compression ratio of attn:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01035486417575154
Current compression ratio of attn:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01183295961903906
Current compression ratio of attn:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.013311009092714682
Current compression ratio of attn:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.014789006854734655
Current compression ratio of attn:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01626694716325612
Current compression ratio of attn:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.017744824276661013
Current compression ratio of attn:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.019222632453576173
Current compression ratio of attn:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.020700365952895317
Current compression ratio of attn:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.022178019033804126
Current compression ratio of attn:  tensor(0.0008, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.023655585955799172
Current compression ratio of attn:  tensor(0.0009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0008, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.02513306097871193
Current compression ratio of attn:  tensor(0.0011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.026610438362731758
Current compression ratio of attn:  tensor(0.0012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.02808771236842607
Current compression ratio of attn:  tensor(0.0013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.02956487725676441
Current compression ratio of attn:  tensor(0.0014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.031041927289140698
Current compression ratio of attn:  tensor(0.0016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.032518856727395136
Current compression ratio of attn:  tensor(0.0018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.033995659833835394
Current compression ratio of attn:  tensor(0.0019, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0015, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03547233087126095
Current compression ratio of attn:  tensor(0.0021, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03694886410298356
Search Epoch: [0]  [ 5000/17710]  eta: 2:44:06  lr: 0.00001000  loss: 17.0202  loss_ita: 3.5266  loss_sp_attn: 6.7456  loss_sp_mlp: 6.7480  time: 0.7647  data: 0.0003  max mem: 30585
Current compression ratio of attn:  tensor(0.0022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.038425253792850854
Current compression ratio of attn:  tensor(0.0025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0019, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.039901494205268125
Current compression ratio of attn:  tensor(0.0027, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04137757960522
Current compression ratio of attn:  tensor(0.0028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04285350425829422
Current compression ratio of attn:  tensor(0.0030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04432926243070241
Current compression ratio of attn:  tensor(0.0032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0026, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04580484838930303
Current compression ratio of attn:  tensor(0.0033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04728025640162357
Current compression ratio of attn:  tensor(0.0036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.048755480735883025
Current compression ratio of attn:  tensor(0.0037, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0031, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05023051566101345
Current compression ratio of attn:  tensor(0.0040, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05170535544668334
Current compression ratio of attn:  tensor(0.0042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.053179994363319154
Current compression ratio of attn:  tensor(0.0043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05465442668212743
Current compression ratio of attn:  tensor(0.0046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.056128646675117286
Current compression ratio of attn:  tensor(0.0049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.057602648615122855
Current compression ratio of attn:  tensor(0.0053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05907642677582574
Current compression ratio of attn:  tensor(0.0056, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0605499754317763
Current compression ratio of attn:  tensor(0.0060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06202328885841684
Current compression ratio of attn:  tensor(0.0062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06349636133210318
Current compression ratio of attn:  tensor(0.0068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06496918713012782
Current compression ratio of attn:  tensor(0.0073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0050, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06644176053074069
Current compression ratio of attn:  tensor(0.0075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06791407581317324
Current compression ratio of attn:  tensor(0.0081, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0054, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06938612725765893
Current compression ratio of attn:  tensor(0.0085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0056, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07085790914545662
Current compression ratio of attn:  tensor(0.0090, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0057, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07232941575887186
Current compression ratio of attn:  tensor(0.0094, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07380064138128026
Search Epoch: [0]  [10000/17710]  eta: 1:39:36  lr: 0.00001000  loss: 17.1952  loss_ita: 3.7779  loss_sp_attn: 6.6973  loss_sp_mlp: 6.7200  time: 0.7755  data: 0.0003  max mem: 30585
Current compression ratio of attn:  tensor(0.0097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07527158029714863
Current compression ratio of attn:  tensor(0.0101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0767422267920575
Current compression ratio of attn:  tensor(0.0105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07821257515272403
Current compression ratio of attn:  tensor(0.0110, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07968261966702295
Current compression ratio of attn:  tensor(0.0112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08115235462400965
Current compression ratio of attn:  tensor(0.0120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08262177431394206
Current compression ratio of attn:  tensor(0.0123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08409087302830308
Current compression ratio of attn:  tensor(0.0128, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08555964505982216
Current compression ratio of attn:  tensor(0.0134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0080, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08702808470249841
Current compression ratio of attn:  tensor(0.0141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08849618625162162
Current compression ratio of attn:  tensor(0.0143, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0086, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08996394400379538
Current compression ratio of attn:  tensor(0.0150, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09143135225695911
Current compression ratio of attn:  tensor(0.0158, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09289840531040969
Current compression ratio of attn:  tensor(0.0163, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09436509746482372
Current compression ratio of attn:  tensor(0.0168, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0094, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09583142302228018
Current compression ratio of attn:  tensor(0.0173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09729737628628227
Current compression ratio of attn:  tensor(0.0180, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09876295156177933
Current compression ratio of attn:  tensor(0.0184, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10022814315518895
Current compression ratio of attn:  tensor(0.0190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10169294537441986
Current compression ratio of attn:  tensor(0.0197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0108, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10315735252889298
Current compression ratio of attn:  tensor(0.0205, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0110, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.104621358929564
Current compression ratio of attn:  tensor(0.0212, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10608495888894581
Current compression ratio of attn:  tensor(0.0219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0114, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10754814672113003
Current compression ratio of attn:  tensor(0.0225, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0118, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10901091674180938
Current compression ratio of attn:  tensor(0.0234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0119, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1104732632682997
Search Epoch: [0]  [15000/17710]  eta: 0:34:59  lr: 0.00001000  loss: 16.4197  loss_ita: 3.1344  loss_sp_attn: 6.6066  loss_sp_mlp: 6.6787  time: 0.7593  data: 0.0003  max mem: 30585
Current compression ratio of attn:  tensor(0.0240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0122, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1119351806195624
Current compression ratio of attn:  tensor(0.0247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0124, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11339666311622557
Current compression ratio of attn:  tensor(0.0257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11485770508060716
Current compression ratio of attn:  tensor(0.0266, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0128, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11631830083673636
Current compression ratio of attn:  tensor(0.0271, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0132, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1177784447103756
Current compression ratio of attn:  tensor(0.0277, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11923813102904338
Current compression ratio of attn:  tensor(0.0288, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12069735412203514
Current compression ratio of attn:  tensor(0.0295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12215610832044638
Current compression ratio of attn:  tensor(0.0304, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12361438795719379
Current compression ratio of attn:  tensor(0.0312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0145, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12507218736703787
Current compression ratio of attn:  tensor(0.0321, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0147, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12652950088660495
Current compression ratio of attn:  tensor(0.0328, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12798632285440845
Current compression ratio of attn:  tensor(0.0335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0155, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.129442647610872
Search Epoch: [0]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 15.3922  loss_ita: 2.2064  loss_sp_attn: 6.5321  loss_sp_mlp: 6.6536  time: 0.7809  data: 0.0006  max mem: 30585
Search Epoch: [0] Total time: 3:48:37 (0.7746 s / it)
Averaged stats: lr: 0.0000  loss: 16.1783  loss_ita: 2.7692  loss_sp_attn: 6.6895  loss_sp_mlp: 6.7196
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 66.54, 'txt_r5': 86.96, 'txt_r10': 92.94, 'txt_r_mean': 82.14666666666666, 'img_r1': 51.46341463414634, 'img_r5': 76.4094362255098, 'img_r10': 84.34626149540183, 'img_r_mean': 70.73970411835266, 'r_mean': 76.44318539250966}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0968
Text_CKA_Similarity: 0.4487
Image_Cosine_Similarity: 0.1826
Image_CKA_Similarity: 0.6664
sim_matrix_pearson_correlation: 0.3170
KD:False
Search Epoch: [1]  [    0/17710]  eta: 3 days, 5:15:13  lr: 0.00001000  loss: 15.9653  loss_ita: 2.7796  loss_sp_attn: 6.5321  loss_sp_mlp: 6.6536  time: 15.7038  data: 0.3960  max mem: 30585
KD is False
Current compression ratio of attn:  tensor(0.0348, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0154, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13089846949835054
Current compression ratio of attn:  tensor(0.0353, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13235378286115237
Current compression ratio of attn:  tensor(0.0363, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0162, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13380858204556192
Current compression ratio of attn:  tensor(0.0369, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0167, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13526286139986077
Current compression ratio of attn:  tensor(0.0379, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13671661527434975
Current compression ratio of attn:  tensor(0.0384, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0175, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13816983802137175
Current compression ratio of attn:  tensor(0.0396, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0176, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13962252399533243
Current compression ratio of attn:  tensor(0.0407, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0178, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14107466755272308
Current compression ratio of attn:  tensor(0.0414, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1425262630521421
Current compression ratio of attn:  tensor(0.0428, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14397730485431703
Current compression ratio of attn:  tensor(0.0439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0185, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14542778732212655
Current compression ratio of attn:  tensor(0.0442, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0193, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14687770482062218
Current compression ratio of attn:  tensor(0.0458, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0192, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14832705171705013
Current compression ratio of attn:  tensor(0.0465, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14977582238087378
Current compression ratio of attn:  tensor(0.0477, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0199, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15122401118379467
Current compression ratio of attn:  tensor(0.0487, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0202, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15267161249977496
Current compression ratio of attn:  tensor(0.0493, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0208, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15411862070505927
Current compression ratio of attn:  tensor(0.0503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0212, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15556503017819603
Current compression ratio of attn:  tensor(0.0512, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0216, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15701083530006
Current compression ratio of attn:  tensor(0.0521, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1584560304538737
Current compression ratio of attn:  tensor(0.0532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0223, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1599006100252292
Current compression ratio of attn:  tensor(0.0539, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0229, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16134456840211003
Current compression ratio of attn:  tensor(0.0546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16278789997491308
Current compression ratio of attn:  tensor(0.0564, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1642305991364703
Current compression ratio of attn:  tensor(0.0574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0238, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16567266028207048
Search Epoch: [1]  [ 5000/17710]  eta: 2:52:36  lr: 0.00001000  loss: 14.6423  loss_ita: 1.6743  loss_sp_attn: 6.3703  loss_sp_mlp: 6.5977  time: 0.7967  data: 0.0002  max mem: 30589
Current compression ratio of attn:  tensor(0.0588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16711407780948084
Current compression ratio of attn:  tensor(0.0603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0241, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1685548461189692
Current compression ratio of attn:  tensor(0.0610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16999495961332545
Current compression ratio of attn:  tensor(0.0627, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17143441269788331
Current compression ratio of attn:  tensor(0.0637, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0251, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17287319978054227
Current compression ratio of attn:  tensor(0.0651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0254, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1743113152717889
Current compression ratio of attn:  tensor(0.0661, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0259, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17574875358471886
Current compression ratio of attn:  tensor(0.0678, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0259, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17718550913505893
Current compression ratio of attn:  tensor(0.0682, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0268, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17862157634118786
Current compression ratio of attn:  tensor(0.0699, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0268, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1800569496241589
Current compression ratio of attn:  tensor(0.0714, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1814916234077208
Current compression ratio of attn:  tensor(0.0723, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0276, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18292559211833997
Current compression ratio of attn:  tensor(0.0736, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1843588501852219
Current compression ratio of attn:  tensor(0.0750, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0282, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18579139204033307
Current compression ratio of attn:  tensor(0.0764, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0285, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18722321211842177
Current compression ratio of attn:  tensor(0.0778, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0287, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18865430485704082
Current compression ratio of attn:  tensor(0.0787, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0294, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1900846646965686
Current compression ratio of attn:  tensor(0.0799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0298, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19151428608023063
Current compression ratio of attn:  tensor(0.0811, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0303, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19294316345412116
Current compression ratio of attn:  tensor(0.0822, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0308, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1943712912672249
Current compression ratio of attn:  tensor(0.0840, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0310, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19579866397143852
Current compression ratio of attn:  tensor(0.0851, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0314, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19722527602159226
Current compression ratio of attn:  tensor(0.0859, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0322, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19865112187547138
Current compression ratio of attn:  tensor(0.0871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20007619599383758
Current compression ratio of attn:  tensor(0.0883, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0332, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20150049284045085
Search Epoch: [1]  [10000/17710]  eta: 1:41:33  lr: 0.00001000  loss: 14.2643  loss_ita: 1.5682  loss_sp_attn: 6.1618  loss_sp_mlp: 6.5343  time: 0.7547  data: 0.0002  max mem: 30589
Current compression ratio of attn:  tensor(0.0894, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0337, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2029240068820906
Current compression ratio of attn:  tensor(0.0906, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2043467325885776
Current compression ratio of attn:  tensor(0.0926, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2057686644327949
Current compression ratio of attn:  tensor(0.0934, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0350, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2071897968907098
Current compression ratio of attn:  tensor(0.0951, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20861012444139515
Current compression ratio of attn:  tensor(0.0960, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0360, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21002964156705062
Current compression ratio of attn:  tensor(0.0978, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0362, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21144834275302443
Current compression ratio of attn:  tensor(0.0988, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2128662224878345
Current compression ratio of attn:  tensor(0.0998, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0375, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21428327526319008
Current compression ratio of attn:  tensor(0.1012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0380, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21569949557401297
Current compression ratio of attn:  tensor(0.1020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21711487791845904
Current compression ratio of attn:  tensor(0.1028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0396, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21852941679793958
Current compression ratio of attn:  tensor(0.1049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0397, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21994310671714273
Current compression ratio of attn:  tensor(0.1058, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0404, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22135594218405447
Current compression ratio of attn:  tensor(0.1075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0408, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2227679177099805
Current compression ratio of attn:  tensor(0.1088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0413, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22417902780956706
Current compression ratio of attn:  tensor(0.1102, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0418, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22558926700082263
Current compression ratio of attn:  tensor(0.1122, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0420, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22699862980513913
Current compression ratio of attn:  tensor(0.1126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22840711074731274
Current compression ratio of attn:  tensor(0.1137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0438, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22981470435556609
Current compression ratio of attn:  tensor(0.1153, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0442, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23122140516156853
Current compression ratio of attn:  tensor(0.1166, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0448, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2326272077004584
Current compression ratio of attn:  tensor(0.1182, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0452, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23403210651086293
Current compression ratio of attn:  tensor(0.1194, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0460, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.235436096134921
Current compression ratio of attn:  tensor(0.1195, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0473, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23683917111830297
Search Epoch: [1]  [15000/17710]  eta: 0:35:14  lr: 0.00001000  loss: 14.8215  loss_ita: 2.4324  loss_sp_attn: 5.9507  loss_sp_mlp: 6.4384  time: 0.7318  data: 0.0002  max mem: 30589
Current compression ratio of attn:  tensor(0.1215, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2382413260102329
Current compression ratio of attn:  tensor(0.1227, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23964255536350898
Current compression ratio of attn:  tensor(0.1241, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0488, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24104285373452528
Current compression ratio of attn:  tensor(0.1254, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0494, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2424422156832923
Current compression ratio of attn:  tensor(0.1274, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0497, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24384063577345869
Current compression ratio of attn:  tensor(0.1287, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24523810857233214
Current compression ratio of attn:  tensor(0.1296, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0512, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24663462865090013
Current compression ratio of attn:  tensor(0.1310, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0519, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24803019058385162
Current compression ratio of attn:  tensor(0.1322, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2494247889495978
Current compression ratio of attn:  tensor(0.1322, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2508184183302933
Current compression ratio of attn:  tensor(0.1352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0539, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25221107331185677
Current compression ratio of attn:  tensor(0.1349, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0555, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25360274848399267
Current compression ratio of attn:  tensor(0.1365, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0561, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25499343844021183
Current compression ratio of attn:  tensor(0.1371, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0573, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2563831377778524
Search Epoch: [1]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 13.4925  loss_ita: 1.2894  loss_sp_attn: 5.8319  loss_sp_mlp: 6.3712  time: 0.7856  data: 0.0006  max mem: 30592
Search Epoch: [1] Total time: 3:49:07 (0.7763 s / it)
Averaged stats: lr: 0.0000  loss: 15.0041  loss_ita: 2.2646  loss_sp_attn: 6.2000  loss_sp_mlp: 6.5394
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 60.48, 'txt_r5': 83.42, 'txt_r10': 90.18, 'txt_r_mean': 78.02666666666667, 'img_r1': 46.853258696521394, 'img_r5': 73.6265493802479, 'img_r10': 82.24710115953619, 'img_r_mean': 67.57563641210182, 'r_mean': 72.80115153938425}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0543
Text_CKA_Similarity: 0.4799
Image_Cosine_Similarity: 0.0942
Image_CKA_Similarity: 0.6445
sim_matrix_pearson_correlation: 0.2161
KD:False
Search Epoch: [2]  [    0/17710]  eta: 7 days, 17:03:45  lr: 0.00001000  loss: 14.7823  loss_ita: 2.5793  loss_sp_attn: 5.8319  loss_sp_mlp: 6.3712  time: 37.6186  data: 0.4083  max mem: 30592
KD is False
Current compression ratio of attn:  tensor(0.1377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0584, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2577718410981008
Current compression ratio of attn:  tensor(0.1383, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0596, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2591595430060134
Current compression ratio of attn:  tensor(0.1392, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26054623811053645
Current compression ratio of attn:  tensor(0.1369, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0635, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2619319210245276
Current compression ratio of attn:  tensor(0.1416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0622, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.263316586364777
Current compression ratio of attn:  tensor(0.1394, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2647002287520276
Current compression ratio of attn:  tensor(0.1415, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0654, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2660828428109967
Current compression ratio of attn:  tensor(0.1438, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0655, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2674644231703963
Current compression ratio of attn:  tensor(0.1448, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0665, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26884496446295425
Current compression ratio of attn:  tensor(0.1484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0659, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27022446132543515
Current compression ratio of attn:  tensor(0.1437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0704, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27160290839866097
Current compression ratio of attn:  tensor(0.1504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.272980300327532
Current compression ratio of attn:  tensor(0.1467, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0717, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27435663176104774
Current compression ratio of attn:  tensor(0.1517, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0704, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2757318973523275
Current compression ratio of attn:  tensor(0.1483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27710609175863127
Current compression ratio of attn:  tensor(0.1504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0745, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27847920964138045
Current compression ratio of attn:  tensor(0.1506, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0759, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2798512456661786
Current compression ratio of attn:  tensor(0.1507, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0775, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28122219450283226
Current compression ratio of attn:  tensor(0.1541, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0771, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2825920508253715
Current compression ratio of attn:  tensor(0.1586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2839608093120706
Current compression ratio of attn:  tensor(0.1536, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0808, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28532846464546874
Current compression ratio of attn:  tensor(0.1589, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0792, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.286695011512391
Current compression ratio of attn:  tensor(0.1582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0813, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2880604446039686
Current compression ratio of attn:  tensor(0.1593, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0822, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2894247586156596
Current compression ratio of attn:  tensor(0.1577, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0850, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29078794824726933
Search Epoch: [2]  [ 5000/17710]  eta: 2:42:27  lr: 0.00001000  loss: 14.4860  loss_ita: 2.6091  loss_sp_attn: 5.6927  loss_sp_mlp: 6.1841  time: 0.7904  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.1603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0851, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29215000820297166
Current compression ratio of attn:  tensor(0.1603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0868, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29351093319132876
Current compression ratio of attn:  tensor(0.1633, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0867, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2948707179253122
Current compression ratio of attn:  tensor(0.1634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0884, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29622935712232323
Current compression ratio of attn:  tensor(0.1652, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0890, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2975868455042132
Current compression ratio of attn:  tensor(0.1659, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0904, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29894317779730456
Current compression ratio of attn:  tensor(0.1707, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0892, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30029834873241085
Current compression ratio of attn:  tensor(0.1700, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3016523530448573
Current compression ratio of attn:  tensor(0.1718, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0919, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30300518547450156
Current compression ratio of attn:  tensor(0.1694, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30435684076575353
Current compression ratio of attn:  tensor(0.1741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0941, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3057073136675964
Current compression ratio of attn:  tensor(0.1718, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3070565989336068
Current compression ratio of attn:  tensor(0.1762, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0964, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30840469132197523
Current compression ratio of attn:  tensor(0.1757, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0985, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30975158559552607
Current compression ratio of attn:  tensor(0.1770, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0994, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31109727652173863
Current compression ratio of attn:  tensor(0.1783, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3124417588727667
Current compression ratio of attn:  tensor(0.1794, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3137850274254596
Current compression ratio of attn:  tensor(0.1804, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31512707696138187
Current compression ratio of attn:  tensor(0.1798, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1050, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31646790226683386
Current compression ratio of attn:  tensor(0.1832, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31780749813287174
Current compression ratio of attn:  tensor(0.1827, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3191458593553283
Current compression ratio of attn:  tensor(0.1868, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3204829807348325
Current compression ratio of attn:  tensor(0.1846, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1094, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3218188570768298
Current compression ratio of attn:  tensor(0.1893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32315348319160275
Current compression ratio of attn:  tensor(0.1917, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32448685389429077
Search Epoch: [2]  [10000/17710]  eta: 1:38:12  lr: 0.00001000  loss: 14.0020  loss_ita: 2.5155  loss_sp_attn: 5.4626  loss_sp_mlp: 6.0239  time: 0.7593  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.1906, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3258189640049105
Current compression ratio of attn:  tensor(0.1899, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3271498083483756
Current compression ratio of attn:  tensor(0.1966, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32847938175451724
Current compression ratio of attn:  tensor(0.1953, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3298076790581041
Current compression ratio of attn:  tensor(0.1951, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3311346950988622
Current compression ratio of attn:  tensor(0.1968, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1169, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3324604247214952
Current compression ratio of attn:  tensor(0.1972, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1186, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3337848627757043
Current compression ratio of attn:  tensor(0.1968, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33510800411620834
Current compression ratio of attn:  tensor(0.2001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33642984360276373
Current compression ratio of attn:  tensor(0.2015, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1216, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3377503761001843
Current compression ratio of attn:  tensor(0.1992, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33906959647836166
Current compression ratio of attn:  tensor(0.2025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3403874996122844
Current compression ratio of attn:  tensor(0.2023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1269, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34170408038205896
Current compression ratio of attn:  tensor(0.2072, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1259, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3430193336729286
Current compression ratio of attn:  tensor(0.2076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1275, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3443332543752938
Current compression ratio of attn:  tensor(0.2102, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.345645837384732
Current compression ratio of attn:  tensor(0.2078, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1314, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34695707760201755
Current compression ratio of attn:  tensor(0.2132, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34826696993314116
Current compression ratio of attn:  tensor(0.2088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1347, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34957550928933
Current compression ratio of attn:  tensor(0.2173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1314, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3508826905870675
Current compression ratio of attn:  tensor(0.2126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1363, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3521885087481127
Current compression ratio of attn:  tensor(0.2181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1348, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35349295869952047
Current compression ratio of attn:  tensor(0.2142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1392, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35479603537366117
Current compression ratio of attn:  tensor(0.2186, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1385, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3560977337082397
Current compression ratio of attn:  tensor(0.2157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1422, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3573980486463161
Search Epoch: [2]  [15000/17710]  eta: 0:34:17  lr: 0.00001000  loss: 14.3983  loss_ita: 3.3008  loss_sp_attn: 5.3005  loss_sp_mlp: 5.7970  time: 0.7433  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.2236, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1395, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35869697513632454
Current compression ratio of attn:  tensor(0.2227, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1420, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3599945081320931
Current compression ratio of attn:  tensor(0.2231, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3612906425928636
Current compression ratio of attn:  tensor(0.2275, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3625853734833107
Current compression ratio of attn:  tensor(0.2251, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1466, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3638786957735621
Current compression ratio of attn:  tensor(0.2255, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3651706044392174
Current compression ratio of attn:  tensor(0.2303, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3664610944613683
Current compression ratio of attn:  tensor(0.2288, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3677501608266175
Current compression ratio of attn:  tensor(0.2334, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1496, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3690377985270986
Current compression ratio of attn:  tensor(0.2287, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3703240025604953
Current compression ratio of attn:  tensor(0.2333, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1538, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3716087679300609
Current compression ratio of attn:  tensor(0.2350, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1548, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37289208964463794
Current compression ratio of attn:  tensor(0.2369, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1557, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37417396271867687
Search Epoch: [2]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 14.3917  loss_ita: 3.5284  loss_sp_attn: 5.1574  loss_sp_mlp: 5.7060  time: 0.7791  data: 0.0007  max mem: 30592
Search Epoch: [2] Total time: 3:43:25 (0.7569 s / it)
Averaged stats: lr: 0.0000  loss: 14.3858  loss_ita: 2.8139  loss_sp_attn: 5.5216  loss_sp_mlp: 6.0503
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 51.32, 'txt_r5': 77.18, 'txt_r10': 85.5, 'txt_r_mean': 71.33333333333333, 'img_r1': 37.09716113554578, 'img_r5': 64.1343462614954, 'img_r10': 74.32626949220312, 'img_r_mean': 58.519258963081434, 'r_mean': 64.92629614820738}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0015
Text_CKA_Similarity: 0.4067
Image_Cosine_Similarity: 0.1542
Image_CKA_Similarity: 0.6796
sim_matrix_pearson_correlation: 0.3707
KD:False
Search Epoch: [3]  [    0/17710]  eta: 7 days, 17:46:17  lr: 0.00001000  loss: 14.5862  loss_ita: 3.7228  loss_sp_attn: 5.1574  loss_sp_mlp: 5.7060  time: 37.7627  data: 0.4105  max mem: 30592
KD is False
Current compression ratio of attn:  tensor(0.2353, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1587, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3754543821722566
Current compression ratio of attn:  tensor(0.2372, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1593, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3767333430311026
Current compression ratio of attn:  tensor(0.2378, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1612, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37801084032660753
Current compression ratio of attn:  tensor(0.2392, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1623, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37928686909584886
Current compression ratio of attn:  tensor(0.2394, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1642, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3805614243816098
Current compression ratio of attn:  tensor(0.2406, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1656, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3818345012323977
Current compression ratio of attn:  tensor(0.2445, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1653, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3831060947024633
Current compression ratio of attn:  tensor(0.2445, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1674, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38437619985182037
Current compression ratio of attn:  tensor(0.2450, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1691, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3856448117462642
Current compression ratio of attn:  tensor(0.2476, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1697, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3869119254573918
Current compression ratio of attn:  tensor(0.2502, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1702, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38817753606261984
Current compression ratio of attn:  tensor(0.2484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38944163864520476
Current compression ratio of attn:  tensor(0.2501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1747, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39070422829426116
Current compression ratio of attn:  tensor(0.2527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1751, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39196530010478176
Current compression ratio of attn:  tensor(0.2546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3932248491776553
Current compression ratio of attn:  tensor(0.2559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1775, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39448287061968634
Current compression ratio of attn:  tensor(0.2572, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1788, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3957393595436144
Current compression ratio of attn:  tensor(0.2575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1806, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3969943110681321
Current compression ratio of attn:  tensor(0.2614, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1802, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39824772031790534
Current compression ratio of attn:  tensor(0.2601, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1833, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.399499582423591
Current compression ratio of attn:  tensor(0.2621, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1842, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4007498925218568
Current compression ratio of attn:  tensor(0.2629, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1859, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4019986457553994
Current compression ratio of attn:  tensor(0.2665, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1858, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40324583727296426
Current compression ratio of attn:  tensor(0.2657, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1885, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40449146222936344
Current compression ratio of attn:  tensor(0.2658, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1906, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40573551578549516
Search Epoch: [3]  [ 5000/17710]  eta: 2:41:24  lr: 0.00001000  loss: 14.1083  loss_ita: 3.6763  loss_sp_attn: 4.9621  loss_sp_mlp: 5.4699  time: 0.7310  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.2701, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1899, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40697799310836213
Current compression ratio of attn:  tensor(0.2681, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1935, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40821888937109074
Current compression ratio of attn:  tensor(0.2692, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1951, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4094581997529496
Current compression ratio of attn:  tensor(0.2702, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1966, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.410695919439368
Current compression ratio of attn:  tensor(0.2751, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1958, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41193204362195535
Current compression ratio of attn:  tensor(0.2769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1969, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4131665674985189
Current compression ratio of attn:  tensor(0.2767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1992, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4143994862730832
Current compression ratio of attn:  tensor(0.2797, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1995, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4156307951559085
Current compression ratio of attn:  tensor(0.2789, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.416860489363509
Current compression ratio of attn:  tensor(0.2802, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2037, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41808856411867185
Current compression ratio of attn:  tensor(0.2808, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4193150146504756
Current compression ratio of attn:  tensor(0.2843, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2056, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4205398361943088
Current compression ratio of attn:  tensor(0.2853, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4217630239918883
Current compression ratio of attn:  tensor(0.2893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42298457329127775
Current compression ratio of attn:  tensor(0.2919, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4242044793469063
Current compression ratio of attn:  tensor(0.2871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2128, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.425422737419587
Current compression ratio of attn:  tensor(0.2896, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42663934277653504
Current compression ratio of attn:  tensor(0.2932, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2133, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42785429069138603
Current compression ratio of attn:  tensor(0.2950, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2146, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4290675764442148
Current compression ratio of attn:  tensor(0.2961, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2162, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43027919532155323
Current compression ratio of attn:  tensor(0.2969, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2179, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43148914261640914
Current compression ratio of attn:  tensor(0.2995, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2186, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43269741362828396
Current compression ratio of attn:  tensor(0.2978, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4339040036631913
Current compression ratio of attn:  tensor(0.3014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4351089080336753
Current compression ratio of attn:  tensor(0.2990, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43631212205882863
Search Epoch: [3]  [10000/17710]  eta: 1:37:54  lr: 0.00001000  loss: 14.6901  loss_ita: 4.7189  loss_sp_attn: 4.7379  loss_sp_mlp: 5.2333  time: 0.7844  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.3053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4375136410643108
Current compression ratio of attn:  tensor(0.3029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2277, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43871346038236614
Current compression ratio of attn:  tensor(0.3121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2242, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43991157535184205
Current compression ratio of attn:  tensor(0.3089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2284, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4411079813182074
Current compression ratio of attn:  tensor(0.3143, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2276, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44230267363357
Current compression ratio of attn:  tensor(0.3123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2308, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44349564765669514
Current compression ratio of attn:  tensor(0.3183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2296, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4446868987530235
Current compression ratio of attn:  tensor(0.3145, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4458764222946888
Current compression ratio of attn:  tensor(0.3206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2328, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44706421366053684
Current compression ratio of attn:  tensor(0.3157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2383, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4482502682361418
Current compression ratio of attn:  tensor(0.3217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4494345814138258
Current compression ratio of attn:  tensor(0.3200, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2402, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45061714859267554
Current compression ratio of attn:  tensor(0.3224, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2409, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4517979651785613
Current compression ratio of attn:  tensor(0.3256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2413, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45297702658415356
Current compression ratio of attn:  tensor(0.3251, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45415432822894203
Current compression ratio of attn:  tensor(0.3260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2457, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4553298655392525
Current compression ratio of attn:  tensor(0.3292, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2460, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4565036339482649
Current compression ratio of attn:  tensor(0.3300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2478, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4576756288960318
Current compression ratio of attn:  tensor(0.3317, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2491, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4588458458294946
Current compression ratio of attn:  tensor(0.3306, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2521, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4600142802025026
Current compression ratio of attn:  tensor(0.3323, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46118092747582995
Current compression ratio of attn:  tensor(0.3355, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2536, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4623457831171936
Current compression ratio of attn:  tensor(0.3385, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2541, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46350884260127045
Current compression ratio of attn:  tensor(0.3348, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46467010140971576
Current compression ratio of attn:  tensor(0.3397, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46582955503117984
Search Epoch: [3]  [15000/17710]  eta: 0:34:12  lr: 0.00001000  loss: 14.5582  loss_ita: 5.0814  loss_sp_attn: 4.4628  loss_sp_mlp: 5.0140  time: 0.7285  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.3386, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2609, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4669871989613258
Current compression ratio of attn:  tensor(0.3427, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2609, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4681430287028477
Current compression ratio of attn:  tensor(0.3433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2628, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46929703976548687
Current compression ratio of attn:  tensor(0.3414, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2663, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4704492276660506
Current compression ratio of attn:  tensor(0.3450, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2664, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4715995879284284
Current compression ratio of attn:  tensor(0.3464, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47274811608361045
Current compression ratio of attn:  tensor(0.3475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2695, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4738948076697039
Current compression ratio of attn:  tensor(0.3480, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2716, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47503965823195127
Current compression ratio of attn:  tensor(0.3516, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2715, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47618266332274684
Current compression ratio of attn:  tensor(0.3527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47732381850165456
Current compression ratio of attn:  tensor(0.3555, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47846311933542485
Current compression ratio of attn:  tensor(0.3580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2748, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4796005613980124
Current compression ratio of attn:  tensor(0.3600, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2760, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4807361402705925
Current compression ratio of attn:  tensor(0.3606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2780, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48186985154157913
Search Epoch: [3]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 13.8119  loss_ita: 4.6106  loss_sp_attn: 4.3216  loss_sp_mlp: 4.8797  time: 0.7483  data: 0.0007  max mem: 30592
Search Epoch: [3] Total time: 3:43:10 (0.7561 s / it)
Averaged stats: lr: 0.0000  loss: 14.0630  loss_ita: 4.0052  loss_sp_attn: 4.7612  loss_sp_mlp: 5.2965
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 35.36, 'txt_r5': 62.74, 'txt_r10': 74.96, 'txt_r_mean': 57.68666666666667, 'img_r1': 23.958416633346662, 'img_r5': 48.540583766493405, 'img_r10': 60.12794882047181, 'img_r_mean': 44.20898307343729, 'r_mean': 50.947824870051974}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: -0.0163
Text_CKA_Similarity: 0.2766
Image_Cosine_Similarity: 0.1281
Image_CKA_Similarity: 0.6699
sim_matrix_pearson_correlation: 0.4019
KD:False
Search Epoch: [4]  [    0/17710]  eta: 3 days, 21:04:47  lr: 0.00001000  loss: 14.0058  loss_ita: 4.8045  loss_sp_attn: 4.3216  loss_sp_mlp: 4.8797  time: 18.9208  data: 0.4177  max mem: 30592
KD is False
Current compression ratio of attn:  tensor(0.3606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2802, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48300169080664157
Current compression ratio of attn:  tensor(0.3611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2823, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48413165366872135
Current compression ratio of attn:  tensor(0.3623, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2838, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4852597357380499
Current compression ratio of attn:  tensor(0.3659, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2841, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48638593263216534
Current compression ratio of attn:  tensor(0.3673, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2854, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4875102399759293
Current compression ratio of attn:  tensor(0.3673, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2879, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48863265340154394
Current compression ratio of attn:  tensor(0.3693, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4897531685485694
Current compression ratio of attn:  tensor(0.3701, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2909, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4908717810639402
Current compression ratio of attn:  tensor(0.3716, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2924, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49198848660198236
Current compression ratio of attn:  tensor(0.3761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2920, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4931032808244306
Current compression ratio of attn:  tensor(0.3792, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2923, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49421615940044417
Current compression ratio of attn:  tensor(0.3767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4953271180066251
Current compression ratio of attn:  tensor(0.3795, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2968, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49643615232703375
Current compression ratio of attn:  tensor(0.3792, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2996, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4975432580532065
Current compression ratio of attn:  tensor(0.3824, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2999, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49864843088417166
Current compression ratio of attn:  tensor(0.3803, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4997516665264671
Current compression ratio of attn:  tensor(0.3869, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.500852960694156
Current compression ratio of attn:  tensor(0.3875, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5019523091088441
Current compression ratio of attn:  tensor(0.3872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5030497074996962
Current compression ratio of attn:  tensor(0.3904, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5041451516034526
Current compression ratio of attn:  tensor(0.3912, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.505238637164446
Current compression ratio of attn:  tensor(0.3915, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3108, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5063301599346175
Current compression ratio of attn:  tensor(0.3894, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3145, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5074197156735335
Current compression ratio of attn:  tensor(0.3940, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5085073001484022
Current compression ratio of attn:  tensor(0.3984, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3136, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5095929091340897
Search Epoch: [4]  [ 5000/17710]  eta: 2:41:49  lr: 0.00001000  loss: 14.3281  loss_ita: 5.6234  loss_sp_attn: 4.0658  loss_sp_mlp: 4.6390  time: 0.7296  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.3975, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3166, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.510676538413137
Current compression ratio of attn:  tensor(0.3992, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3180, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5117581837757756
Current compression ratio of attn:  tensor(0.4018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3187, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5128378410199446
Current compression ratio of attn:  tensor(0.4018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5139155059513064
Current compression ratio of attn:  tensor(0.4056, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3212, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5149911743832636
Current compression ratio of attn:  tensor(0.4038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5160648421369747
Current compression ratio of attn:  tensor(0.4079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3245, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5171365050413709
Current compression ratio of attn:  tensor(0.4120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3242, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5182061589331715
Current compression ratio of attn:  tensor(0.4075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3294, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5192737996569011
Current compression ratio of attn:  tensor(0.4134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3281, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.520339423064905
Current compression ratio of attn:  tensor(0.4067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3347, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5214030250173655
Current compression ratio of attn:  tensor(0.4172, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3307, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.522464601382318
Current compression ratio of attn:  tensor(0.4126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3359, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5235241480356669
Current compression ratio of attn:  tensor(0.4165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3358, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5245816608612023
Current compression ratio of attn:  tensor(0.4170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5256371357506149
Current compression ratio of attn:  tensor(0.4173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3402, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5266905686035129
Current compression ratio of attn:  tensor(0.4187, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3417, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5277419553274374
Current compression ratio of attn:  tensor(0.4226, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3417, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5287912918378785
Current compression ratio of attn:  tensor(0.4259, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3420, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5298385740582914
Current compression ratio of attn:  tensor(0.4255, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3446, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5308837979201112
Current compression ratio of attn:  tensor(0.4245, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3477, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5319269593627701
Current compression ratio of attn:  tensor(0.4296, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3469, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5329680543337129
Current compression ratio of attn:  tensor(0.4262, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3515, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5340070787884115
Current compression ratio of attn:  tensor(0.4329, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3497, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5350440286903819
Current compression ratio of attn:  tensor(0.4325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5360789000111996
Search Epoch: [4]  [10000/17710]  eta: 1:36:59  lr: 0.00001000  loss: 13.3901  loss_ita: 5.1767  loss_sp_attn: 3.8357  loss_sp_mlp: 4.3777  time: 0.7293  data: 0.0003  max mem: 30592
Current compression ratio of attn:  tensor(0.4380, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3513, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5371116887305152
Current compression ratio of attn:  tensor(0.4326, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3571, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5381423908360696
Current compression ratio of attn:  tensor(0.4387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3553, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5391710023237102
Current compression ratio of attn:  tensor(0.4417, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.540197519197406
Current compression ratio of attn:  tensor(0.4385, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3604, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5412219374692637
Current compression ratio of attn:  tensor(0.4403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5422442531595426
Current compression ratio of attn:  tensor(0.4423, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3630, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5432644622966699
Current compression ratio of attn:  tensor(0.4476, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3620, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5442825609172572
Current compression ratio of attn:  tensor(0.4443, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3664, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5452985450661147
Current compression ratio of attn:  tensor(0.4458, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3680, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5463124107962671
Current compression ratio of attn:  tensor(0.4460, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3702, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5473241541689694
Current compression ratio of attn:  tensor(0.4544, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3674, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5483337712537208
Current compression ratio of attn:  tensor(0.4527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3709, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5493412581282818
Current compression ratio of attn:  tensor(0.4513, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5503466108786879
Current compression ratio of attn:  tensor(0.4547, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3744, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5513498255992657
Current compression ratio of attn:  tensor(0.4545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5523508983926476
Current compression ratio of attn:  tensor(0.4576, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5533498253697874
Current compression ratio of attn:  tensor(0.4594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3787, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5543466026499748
Current compression ratio of attn:  tensor(0.4621, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3794, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5553412263608508
Current compression ratio of attn:  tensor(0.4617, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3820, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5563336926384235
Current compression ratio of attn:  tensor(0.4660, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5573239976270811
Current compression ratio of attn:  tensor(0.4666, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3837, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5583121374796094
Current compression ratio of attn:  tensor(0.4687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5592981083572045
Current compression ratio of attn:  tensor(0.4688, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5602819064294895
Current compression ratio of attn:  tensor(0.4732, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3867, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5612635278745279
Search Epoch: [4]  [15000/17710]  eta: 0:33:59  lr: 0.00001000  loss: 12.4030  loss_ita: 4.6977  loss_sp_attn: 3.5600  loss_sp_mlp: 4.1452  time: 0.7739  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.4754, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3878, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5622429688788397
Current compression ratio of attn:  tensor(0.4716, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3925, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5632202256374154
Current compression ratio of attn:  tensor(0.4705, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3955, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.564195294353731
Current compression ratio of attn:  tensor(0.4739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3958, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5651681712397625
Current compression ratio of attn:  tensor(0.4774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3960, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5661388525160016
Current compression ratio of attn:  tensor(0.4801, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3967, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5671073344114691
Current compression ratio of attn:  tensor(0.4800, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3992, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5680736131637303
Current compression ratio of attn:  tensor(0.4805, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5690376850189096
Current compression ratio of attn:  tensor(0.4839, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5699995462317045
Current compression ratio of attn:  tensor(0.4837, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5709591930654012
Current compression ratio of attn:  tensor(0.4842, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5719166217918881
Current compression ratio of attn:  tensor(0.4873, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5728718286916703
Current compression ratio of attn:  tensor(0.4878, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5738248100538854
Search Epoch: [4]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 12.7602  loss_ita: 5.3008  loss_sp_attn: 3.4615  loss_sp_mlp: 3.9978  time: 0.7503  data: 0.0007  max mem: 30592
Search Epoch: [4] Total time: 3:41:46 (0.7513 s / it)
Averaged stats: lr: 0.0000  loss: 13.4858  loss_ita: 5.1539  loss_sp_attn: 3.8924  loss_sp_mlp: 4.4395
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 23.36, 'txt_r5': 49.22, 'txt_r10': 61.38, 'txt_r_mean': 44.653333333333336, 'img_r1': 15.729708116753299, 'img_r5': 36.42143142742903, 'img_r10': 47.361055577768894, 'img_r_mean': 33.170731707317074, 'r_mean': 38.912032520325205}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0451
Text_CKA_Similarity: 0.3323
Image_Cosine_Similarity: 0.0711
Image_CKA_Similarity: 0.6114
sim_matrix_pearson_correlation: 0.3934
KD:False
Search Epoch: [5]  [    0/17710]  eta: 3 days, 20:39:06  lr: 0.00001000  loss: 12.3813  loss_ita: 4.9219  loss_sp_attn: 3.4615  loss_sp_mlp: 3.9978  time: 18.8338  data: 0.4247  max mem: 30592
KD is False
Current compression ratio of attn:  tensor(0.4893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5747755621763161
Current compression ratio of attn:  tensor(0.4928, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5757240813654059
Current compression ratio of attn:  tensor(0.4882, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5766703639362726
Current compression ratio of attn:  tensor(0.4954, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4132, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5776144062127233
Current compression ratio of attn:  tensor(0.4942, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4162, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5785562045272683
Current compression ratio of attn:  tensor(0.4970, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4169, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5794957552211354
Current compression ratio of attn:  tensor(0.4971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4191, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5804330546442841
Current compression ratio of attn:  tensor(0.4973, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4214, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5813680991554198
Current compression ratio of attn:  tensor(0.5014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4212, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5823008851220078
Current compression ratio of attn:  tensor(0.5043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5832314089202881
Current compression ratio of attn:  tensor(0.5064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5841596669352884
Current compression ratio of attn:  tensor(0.5065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.585085655560839
Current compression ratio of attn:  tensor(0.5067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5860093711995864
Current compression ratio of attn:  tensor(0.5061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4299, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5869308102630073
Current compression ratio of attn:  tensor(0.5103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4297, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5878499691714228
Current compression ratio of attn:  tensor(0.5101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4322, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5887668443540122
Current compression ratio of attn:  tensor(0.5149, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4313, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5896814322488262
Current compression ratio of attn:  tensor(0.5110, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4363, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5905937293028021
Current compression ratio of attn:  tensor(0.5121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5915037319717762
Current compression ratio of attn:  tensor(0.5142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.592411436720499
Current compression ratio of attn:  tensor(0.5154, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4405, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5933168400226473
Current compression ratio of attn:  tensor(0.5134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4440, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5942199383608391
Current compression ratio of attn:  tensor(0.5204, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4420, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.595120728226647
Current compression ratio of attn:  tensor(0.5143, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4481, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5960192061206115
Current compression ratio of attn:  tensor(0.5209, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4463, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5969153685522551
Search Epoch: [5]  [ 5000/17710]  eta: 2:40:16  lr: 0.00001000  loss: 11.9896  loss_ita: 5.0097  loss_sp_attn: 3.2378  loss_sp_mlp: 3.7421  time: 0.7541  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.5182, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4502, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5978092120400954
Current compression ratio of attn:  tensor(0.5252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.598700733111659
Current compression ratio of attn:  tensor(0.5219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4526, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5995899283034943
Current compression ratio of attn:  tensor(0.5265, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4519, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6004767941611864
Current compression ratio of attn:  tensor(0.5217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4571, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6013613272393684
Current compression ratio of attn:  tensor(0.5301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4544, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6022435241017371
Current compression ratio of attn:  tensor(0.5228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6031233813210644
Current compression ratio of attn:  tensor(0.5316, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6040008954792118
Current compression ratio of attn:  tensor(0.5282, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4624, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6048760631671433
Current compression ratio of attn:  tensor(0.5332, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4616, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6057488809849385
Current compression ratio of attn:  tensor(0.5315, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4649, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.606619345541806
Current compression ratio of attn:  tensor(0.5368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4638, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6074874534560968
Current compression ratio of attn:  tensor(0.5344, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4676, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6083532013553167
Current compression ratio of attn:  tensor(0.5422, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6092165858761402
Current compression ratio of attn:  tensor(0.5373, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4704, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6100776036644233
Current compression ratio of attn:  tensor(0.5434, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4689, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6109362513752161
Current compression ratio of attn:  tensor(0.5399, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6117925256727768
Current compression ratio of attn:  tensor(0.5456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4720, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.612646423230583
Current compression ratio of attn:  tensor(0.5432, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4758, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6134979407313469
Current compression ratio of attn:  tensor(0.5454, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6143470748670257
Current compression ratio of attn:  tensor(0.5486, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4770, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6151938223388368
Current compression ratio of attn:  tensor(0.5479, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4794, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6160381798572687
Current compression ratio of attn:  tensor(0.5512, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4798, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6168801441420948
Current compression ratio of attn:  tensor(0.5494, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4831, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6177197119223861
Current compression ratio of attn:  tensor(0.5523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4836, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6185568799365238
Search Epoch: [5]  [10000/17710]  eta: 1:37:16  lr: 0.00001000  loss: 12.5159  loss_ita: 6.0002  loss_sp_attn: 3.0255  loss_sp_mlp: 3.4902  time: 0.7353  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.5542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6193916449322113
Current compression ratio of attn:  tensor(0.5542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4869, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6202240036664882
Current compression ratio of attn:  tensor(0.5582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4865, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6210539529057415
Current compression ratio of attn:  tensor(0.5611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6218814894257193
Current compression ratio of attn:  tensor(0.5600, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4900, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6227066100115426
Current compression ratio of attn:  tensor(0.5622, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4908, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6235293114577178
Current compression ratio of attn:  tensor(0.5640, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4919, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6243495905681496
Current compression ratio of attn:  tensor(0.5687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4912, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6251674441561534
Current compression ratio of attn:  tensor(0.5633, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4967, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6259828690444671
Current compression ratio of attn:  tensor(0.5680, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4960, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6267958620652637
Current compression ratio of attn:  tensor(0.5717, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4960, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6276064200601641
Current compression ratio of attn:  tensor(0.5720, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4976, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.628414539880249
Current compression ratio of attn:  tensor(0.5753, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4980, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6292202183860706
Current compression ratio of attn:  tensor(0.5753, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6300234524476657
Current compression ratio of attn:  tensor(0.5772, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6308242389445675
Current compression ratio of attn:  tensor(0.5801, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6316225747658175
Current compression ratio of attn:  tensor(0.5804, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6324184568099781
Current compression ratio of attn:  tensor(0.5834, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6332118819851438
Current compression ratio of attn:  tensor(0.5830, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6340028472089543
Current compression ratio of attn:  tensor(0.5889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6347913494086053
Current compression ratio of attn:  tensor(0.5863, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6355773855208615
Current compression ratio of attn:  tensor(0.5903, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6363609524920684
Current compression ratio of attn:  tensor(0.5866, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6371420472781627
Current compression ratio of attn:  tensor(0.5921, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5115, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6379206668446862
Current compression ratio of attn:  tensor(0.5940, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6386968081667963
Search Epoch: [5]  [15000/17710]  eta: 0:34:01  lr: 0.00001000  loss: 11.8919  loss_ita: 5.8519  loss_sp_attn: 2.7441  loss_sp_mlp: 3.2960  time: 0.7289  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.5965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5130, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6394704682292784
Current compression ratio of attn:  tensor(0.5928, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5174, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6402416440265565
Current compression ratio of attn:  tensor(0.6035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5130, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6410103325627065
Current compression ratio of attn:  tensor(0.6028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5156, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6417765308514665
Current compression ratio of attn:  tensor(0.6020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6425402359162492
Current compression ratio of attn:  tensor(0.6038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.643301444790153
Current compression ratio of attn:  tensor(0.6060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5198, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6440601545159739
Current compression ratio of attn:  tensor(0.6049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5227, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6448163621462164
Current compression ratio of attn:  tensor(0.6082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5227, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6455700647431057
Current compression ratio of attn:  tensor(0.6093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6463212593785986
Current compression ratio of attn:  tensor(0.6130, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6470699431343953
Current compression ratio of attn:  tensor(0.6152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5246, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6478161131019498
Current compression ratio of attn:  tensor(0.6155, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5264, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6485597663824825
Current compression ratio of attn:  tensor(0.6211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6493009000869908
Search Epoch: [5]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 12.4563  loss_ita: 6.6867  loss_sp_attn: 2.5606  loss_sp_mlp: 3.2089  time: 0.7636  data: 0.0007  max mem: 30592
Search Epoch: [5] Total time: 3:42:20 (0.7533 s / it)
Averaged stats: lr: 0.0000  loss: 12.3408  loss_ita: 5.7254  loss_sp_attn: 3.0506  loss_sp_mlp: 3.5648
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 16.94, 'txt_r5': 39.78, 'txt_r10': 51.56, 'txt_r_mean': 36.093333333333334, 'img_r1': 12.754898040783686, 'img_r5': 31.963214714114354, 'img_r10': 43.59856057576969, 'img_r_mean': 29.438891110222574, 'r_mean': 32.76611222177795}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0308
Text_CKA_Similarity: 0.2574
Image_Cosine_Similarity: 0.0534
Image_CKA_Similarity: 0.6121
sim_matrix_pearson_correlation: 0.3591
KD:False
Search Epoch: [6]  [    0/17710]  eta: 6:26:59  lr: 0.00001000  loss: 12.5715  loss_ita: 6.8019  loss_sp_attn: 2.5606  loss_sp_mlp: 3.2089  time: 1.3111  data: 0.3782  max mem: 30592
KD is False
Current compression ratio of attn:  tensor(0.6173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6500395113362597
Current compression ratio of attn:  tensor(0.6206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6507755972608745
Current compression ratio of attn:  tensor(0.6202, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5320, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6515091550012304
Current compression ratio of attn:  tensor(0.6217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5331, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6522401817075448
Current compression ratio of attn:  tensor(0.6254, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5329, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6529686745398675
Current compression ratio of attn:  tensor(0.6246, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5354, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.653694630668092
Current compression ratio of attn:  tensor(0.6260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5362, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6544180472719672
Current compression ratio of attn:  tensor(0.6259, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5386, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6551389215411071
Current compression ratio of attn:  tensor(0.6285, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5391, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6558572506750027
Current compression ratio of attn:  tensor(0.6292, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5406, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6565730318830323
Current compression ratio of attn:  tensor(0.6314, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5413, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6572862623844726
Current compression ratio of attn:  tensor(0.6317, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6579969394085101
Current compression ratio of attn:  tensor(0.6351, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6587050601942505
Current compression ratio of attn:  tensor(0.6342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6594106219907302
Current compression ratio of attn:  tensor(0.6353, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6601136220569276
Current compression ratio of attn:  tensor(0.6398, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5462, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6608140576617726
Current compression ratio of attn:  tensor(0.6374, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5494, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6615119260841577
Current compression ratio of attn:  tensor(0.6392, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5505, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6622072246129488
Current compression ratio of attn:  tensor(0.6422, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5507, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6628999505469955
Current compression ratio of attn:  tensor(0.6390, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5544, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6635901011951415
Current compression ratio of attn:  tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5533, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6642776738762353
Current compression ratio of attn:  tensor(0.6384, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6649626659191403
Current compression ratio of attn:  tensor(0.6475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5552, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6656450746627458
Current compression ratio of attn:  tensor(0.6467, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5576, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6663248974559763
Current compression ratio of attn:  tensor(0.6500, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.667002131657803
Search Epoch: [6]  [ 5000/17710]  eta: 2:39:35  lr: 0.00001000  loss: 12.0458  loss_ita: 6.6897  loss_sp_attn: 2.3653  loss_sp_mlp: 2.9908  time: 0.7325  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.6484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5604, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6676767746372528
Current compression ratio of attn:  tensor(0.6490, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5619, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6683488237734198
Current compression ratio of attn:  tensor(0.6497, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6690182764554746
Current compression ratio of attn:  tensor(0.6542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5627, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6696851300826746
Current compression ratio of attn:  tensor(0.6556, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5638, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6703493820643747
Current compression ratio of attn:  tensor(0.6551, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5659, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6710110298200361
Current compression ratio of attn:  tensor(0.6565, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5668, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6716700707792377
Current compression ratio of attn:  tensor(0.6568, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5686, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6723265023816853
Current compression ratio of attn:  tensor(0.6570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5705, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6729803220772218
Current compression ratio of attn:  tensor(0.6588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5713, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.673631527325837
Current compression ratio of attn:  tensor(0.6591, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5730, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6742801155976774
Current compression ratio of attn:  tensor(0.6613, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5736, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6749260843730562
Current compression ratio of attn:  tensor(0.6627, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5745, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6755694311424634
Current compression ratio of attn:  tensor(0.6621, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5765, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6762101534065743
Current compression ratio of attn:  tensor(0.6671, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5755, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6768482486762609
Current compression ratio of attn:  tensor(0.6638, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5792, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6774837144726007
Current compression ratio of attn:  tensor(0.6691, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5780, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6781165483268858
Current compression ratio of attn:  tensor(0.6740, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6787467477806335
Current compression ratio of attn:  tensor(0.6684, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5820, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6793743103855956
Current compression ratio of attn:  tensor(0.6741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5805, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6799992337037674
Current compression ratio of attn:  tensor(0.6696, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5851, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6806215153073973
Current compression ratio of attn:  tensor(0.6761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5828, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6812411527789971
Current compression ratio of attn:  tensor(0.6740, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5860, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6818581437113502
Current compression ratio of attn:  tensor(0.6785, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5850, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.682472485707522
Current compression ratio of attn:  tensor(0.6795, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5861, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6830841763808679
Search Epoch: [6]  [10000/17710]  eta: 1:36:23  lr: 0.00001000  loss: 10.7931  loss_ita: 5.8300  loss_sp_attn: 2.1659  loss_sp_mlp: 2.7972  time: 0.7362  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.6805, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6836932133550442
Current compression ratio of attn:  tensor(0.6776, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5908, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6842995942640158
Current compression ratio of attn:  tensor(0.6845, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5885, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6849033167520666
Current compression ratio of attn:  tensor(0.6835, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5909, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6855043784738081
Current compression ratio of attn:  tensor(0.6813, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5940, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.686102777094188
Current compression ratio of attn:  tensor(0.6863, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5927, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6866985102885007
Current compression ratio of attn:  tensor(0.6817, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5972, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6872915757423949
Current compression ratio of attn:  tensor(0.6891, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5945, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6878819711518829
Current compression ratio of attn:  tensor(0.6897, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5959, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6884696942233506
Current compression ratio of attn:  tensor(0.6918, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6890547426735648
Current compression ratio of attn:  tensor(0.6928, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6896371142296837
Current compression ratio of attn:  tensor(0.6946, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5979, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6902168066292639
Current compression ratio of attn:  tensor(0.6924, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.690793817620271
Current compression ratio of attn:  tensor(0.6958, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6913681449610873
Current compression ratio of attn:  tensor(0.6935, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6037, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6919397864205208
Current compression ratio of attn:  tensor(0.7013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6925087397778135
Current compression ratio of attn:  tensor(0.6975, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.693075002822651
Current compression ratio of attn:  tensor(0.7001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6936385733551698
Current compression ratio of attn:  tensor(0.7002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6941994491859667
Current compression ratio of attn:  tensor(0.7036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6058, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6947576281361073
Current compression ratio of attn:  tensor(0.7062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.695313108037134
Current compression ratio of attn:  tensor(0.7023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6958658867310749
Current compression ratio of attn:  tensor(0.7097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6072, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6964159620704515
Current compression ratio of attn:  tensor(0.7066, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6107, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6969633319182882
Current compression ratio of attn:  tensor(0.7112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6975079941481193
Search Epoch: [6]  [15000/17710]  eta: 0:33:51  lr: 0.00001000  loss: 11.2791  loss_ita: 6.6872  loss_sp_attn: 1.9516  loss_sp_mlp: 2.6403  time: 0.7413  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.7069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6138, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.698049946643998
Current compression ratio of attn:  tensor(0.7099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6136, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.698589187300505
Current compression ratio of attn:  tensor(0.7109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6147, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6991257140227554
Current compression ratio of attn:  tensor(0.7150, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6996595247264081
Current compression ratio of attn:  tensor(0.7132, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6163, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7001906173376733
Current compression ratio of attn:  tensor(0.7129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6182, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7007189897933204
Current compression ratio of attn:  tensor(0.7138, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6192, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7012446400406869
Current compression ratio of attn:  tensor(0.7164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.701767566037685
Current compression ratio of attn:  tensor(0.7190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6192, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7022877657528106
Current compression ratio of attn:  tensor(0.7195, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6202, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7028052371651512
Current compression ratio of attn:  tensor(0.7196, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.703319978264393
Current compression ratio of attn:  tensor(0.7218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7038319870508292
Current compression ratio of attn:  tensor(0.7215, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6237, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7043412615353678
Search Epoch: [6]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 11.6184  loss_ita: 7.1926  loss_sp_attn: 1.8825  loss_sp_mlp: 2.5433  time: 0.8042  data: 0.0006  max mem: 30592
Search Epoch: [6] Total time: 3:41:38 (0.7509 s / it)
Averaged stats: lr: 0.0000  loss: 11.2804  loss_ita: 6.2084  loss_sp_attn: 2.2254  loss_sp_mlp: 2.8466
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 15.4, 'txt_r5': 37.7, 'txt_r10': 50.26, 'txt_r_mean': 34.45333333333333, 'img_r1': 12.73890443822471, 'img_r5': 33.170731707317074, 'img_r10': 44.95801679328269, 'img_r_mean': 30.289217646274825, 'r_mean': 32.37127548980408}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: -0.0656
Text_CKA_Similarity: 0.1760
Image_Cosine_Similarity: 0.0488
Image_CKA_Similarity: 0.5701
sim_matrix_pearson_correlation: 0.3066
KD:False
Search Epoch: [7]  [    0/17710]  eta: 6:23:48  lr: 0.00001000  loss: 10.5108  loss_ita: 6.0850  loss_sp_attn: 1.8825  loss_sp_mlp: 2.5433  time: 1.3003  data: 0.4199  max mem: 30592
KD is False
Current compression ratio of attn:  tensor(0.7244, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6236, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7048477997395393
Current compression ratio of attn:  tensor(0.7254, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6244, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7053515996955041
Current compression ratio of attn:  tensor(0.7238, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7058526594460603
Current compression ratio of attn:  tensor(0.7301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7063509770446521
Current compression ratio of attn:  tensor(0.7273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7068465505553756
Current compression ratio of attn:  tensor(0.7278, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6291, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7073393780529879
Current compression ratio of attn:  tensor(0.7304, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6290, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.707829457622914
Current compression ratio of attn:  tensor(0.7280, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6319, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7083167873612543
Current compression ratio of attn:  tensor(0.7318, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6311, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7088013653747918
Current compression ratio of attn:  tensor(0.7323, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6318, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7092831897809996
Current compression ratio of attn:  tensor(0.7352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6314, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7097622587080484
Current compression ratio of attn:  tensor(0.7312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6356, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7102385702948135
Current compression ratio of attn:  tensor(0.7387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7107121226908825
Current compression ratio of attn:  tensor(0.7346, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6364, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7111829140565612
Current compression ratio of attn:  tensor(0.7364, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6367, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7116509425628827
Current compression ratio of attn:  tensor(0.7364, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6381, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7121162063916127
Current compression ratio of attn:  tensor(0.7386, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6381, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.712578703735258
Current compression ratio of attn:  tensor(0.7386, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6396, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7130384327970722
Current compression ratio of attn:  tensor(0.7403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6398, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7134953917910639
Current compression ratio of attn:  tensor(0.7367, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6436, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7139495789420027
Current compression ratio of attn:  tensor(0.7466, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7144009924854267
Current compression ratio of attn:  tensor(0.7417, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7148496306676488
Current compression ratio of attn:  tensor(0.7476, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6410, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7152954917457643
Current compression ratio of attn:  tensor(0.7410, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6464, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7157385739876571
Current compression ratio of attn:  tensor(0.7460, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6447, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7161788756720062
Search Epoch: [7]  [ 5000/17710]  eta: 2:42:05  lr: 0.00001000  loss: 10.9001  loss_ita: 6.7825  loss_sp_attn: 1.7165  loss_sp_mlp: 2.4011  time: 0.7333  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.7440, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6471, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7166163950882931
Current compression ratio of attn:  tensor(0.7478, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6461, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7170511305368079
Current compression ratio of attn:  tensor(0.7490, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6466, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.717483080328656
Current compression ratio of attn:  tensor(0.7499, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.717912242785765
Current compression ratio of attn:  tensor(0.7483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7183386162408908
Current compression ratio of attn:  tensor(0.7529, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7187621990376243
Current compression ratio of attn:  tensor(0.7483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7191829895303974
Current compression ratio of attn:  tensor(0.7529, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6508, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7196009860844905
Current compression ratio of attn:  tensor(0.7521, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6524, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7200161870760373
Current compression ratio of attn:  tensor(0.7592, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7204285908920326
Current compression ratio of attn:  tensor(0.7538, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6541, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7208381959303375
Current compression ratio of attn:  tensor(0.7567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6536, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7212450005996861
Current compression ratio of attn:  tensor(0.7546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7216490033196916
Current compression ratio of attn:  tensor(0.7584, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6550, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7220502025208525
Current compression ratio of attn:  tensor(0.7559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7224485966445585
Current compression ratio of attn:  tensor(0.7597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7228441841430967
Current compression ratio of attn:  tensor(0.7546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7232369634796577
Current compression ratio of attn:  tensor(0.7567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7236269331283415
Current compression ratio of attn:  tensor(0.7617, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6591, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7240140915741633
Current compression ratio of attn:  tensor(0.7605, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7243984373130593
Current compression ratio of attn:  tensor(0.7625, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7247799688518932
Current compression ratio of attn:  tensor(0.7642, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6612, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7251586847084611
Current compression ratio of attn:  tensor(0.7633, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6624, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7255345834114979
Current compression ratio of attn:  tensor(0.7658, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6622, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7259076635006826
Current compression ratio of attn:  tensor(0.7628, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6652, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7262779235266444
Search Epoch: [7]  [10000/17710]  eta: 1:39:30  lr: 0.00001000  loss: 9.8883  loss_ita: 6.0229  loss_sp_attn: 1.6028  loss_sp_mlp: 2.2626  time: 0.8373  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.7649, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7266453620509682
Current compression ratio of attn:  tensor(0.7645, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6665, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7270099776461996
Current compression ratio of attn:  tensor(0.7690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6648, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7273717688958512
Current compression ratio of attn:  tensor(0.7661, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6678, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7277307343944082
Current compression ratio of attn:  tensor(0.7702, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6663, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7280868727473331
Current compression ratio of attn:  tensor(0.7617, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6724, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7284401825710713
Current compression ratio of attn:  tensor(0.7714, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6678, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7287906624930572
Current compression ratio of attn:  tensor(0.7680, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6710, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.729138311151719
Current compression ratio of attn:  tensor(0.7730, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7294831271964836
Current compression ratio of attn:  tensor(0.7678, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7298251092877824
Current compression ratio of attn:  tensor(0.7741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6703, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7301642560970567
Current compression ratio of attn:  tensor(0.7728, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6723, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7305005663067621
Current compression ratio of attn:  tensor(0.7774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6706, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7308340386103743
Current compression ratio of attn:  tensor(0.7731, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6742, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7311646717123939
Current compression ratio of attn:  tensor(0.7759, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7314924643283514
Current compression ratio of attn:  tensor(0.7742, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.731817415184812
Current compression ratio of attn:  tensor(0.7775, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6746, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7321395230193815
Current compression ratio of attn:  tensor(0.7778, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6754, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7324587865807096
Current compression ratio of attn:  tensor(0.7798, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6750, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7327752046284963
Current compression ratio of attn:  tensor(0.7747, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7330887759334959
Current compression ratio of attn:  tensor(0.7822, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6757, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7333994992775218
Current compression ratio of attn:  tensor(0.7774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6794, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7337073734534515
Current compression ratio of attn:  tensor(0.7841, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6763, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7340123972652313
Current compression ratio of attn:  tensor(0.7760, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6824, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7343145695278804
Current compression ratio of attn:  tensor(0.7831, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6790, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7346138890674967
Search Epoch: [7]  [15000/17710]  eta: 0:35:51  lr: 0.00001000  loss: 9.9905  loss_ita: 6.3549  loss_sp_attn: 1.4660  loss_sp_mlp: 2.1696  time: 0.8377  data: 0.0003  max mem: 30592
Current compression ratio of attn:  tensor(0.7770, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6836, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7349103547212595
Current compression ratio of attn:  tensor(0.7841, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6802, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7352039653374363
Current compression ratio of attn:  tensor(0.7798, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6838, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7354947197753849
Current compression ratio of attn:  tensor(0.7843, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6819, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7357826169055599
Current compression ratio of attn:  tensor(0.7791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6860, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.736067655609516
Current compression ratio of attn:  tensor(0.7862, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6823, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7363498347799121
Current compression ratio of attn:  tensor(0.7852, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6840, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7366291533205165
Current compression ratio of attn:  tensor(0.7864, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6842, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7369056101462106
Current compression ratio of attn:  tensor(0.7854, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6856, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.737179204182993
Current compression ratio of attn:  tensor(0.7878, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6851, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7374499343679841
Current compression ratio of attn:  tensor(0.7864, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6868, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.73771779964943
Current compression ratio of attn:  tensor(0.7939, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6830, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7379827989867067
Current compression ratio of attn:  tensor(0.7861, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6885, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7382449313503239
Current compression ratio of attn:  tensor(0.7894, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6875, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7385041957219288
Search Epoch: [7]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 9.9208  loss_ita: 6.3849  loss_sp_attn: 1.4236  loss_sp_mlp: 2.1123  time: 0.8512  data: 0.0007  max mem: 30592
Search Epoch: [7] Total time: 3:56:08 (0.8001 s / it)
Averaged stats: lr: 0.0000  loss: 10.3551  loss_ita: 6.4209  loss_sp_attn: 1.6273  loss_sp_mlp: 2.3069
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 13.84, 'txt_r5': 34.6, 'txt_r10': 47.08, 'txt_r_mean': 31.84, 'img_r1': 10.31187524990004, 'img_r5': 28.56057576969212, 'img_r10': 40.39984006397441, 'img_r_mean': 26.424097027855524, 'r_mean': 29.132048513927764}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: -0.0136
Text_CKA_Similarity: 0.2224
Image_Cosine_Similarity: 0.0392
Image_CKA_Similarity: 0.5350
sim_matrix_pearson_correlation: 0.2396
KD:False
Search Epoch: [8]  [    0/17710]  eta: 6:47:46  lr: 0.00001000  loss: 10.4311  loss_ita: 6.8952  loss_sp_attn: 1.4236  loss_sp_mlp: 2.1123  time: 1.3815  data: 0.4113  max mem: 30592
KD is False
Current compression ratio of attn:  tensor(0.7892, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6883, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7387605910943111
Current compression ratio of attn:  tensor(0.7925, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6870, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7390141164714059
Current compression ratio of attn:  tensor(0.7838, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6933, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7392647708682978
Current compression ratio of attn:  tensor(0.7951, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7395125533112248
Current compression ratio of attn:  tensor(0.7873, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6927, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7397574628375821
Current compression ratio of attn:  tensor(0.7910, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6912, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7399994984959263
Current compression ratio of attn:  tensor(0.7929, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6908, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7402386593459777
Current compression ratio of attn:  tensor(0.7936, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6909, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7404749444586256
Current compression ratio of attn:  tensor(0.7904, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7407083529159311
Current compression ratio of attn:  tensor(0.7941, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6923, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7409388838111306
Current compression ratio of attn:  tensor(0.7913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7411665362486395
Current compression ratio of attn:  tensor(0.7955, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6929, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7413913093440558
Current compression ratio of attn:  tensor(0.7944, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6942, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7416132022241632
Current compression ratio of attn:  tensor(0.7981, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6927, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7418322140269347
Current compression ratio of attn:  tensor(0.7957, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7420483439015361
Current compression ratio of attn:  tensor(0.7985, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7422615910083291
Current compression ratio of attn:  tensor(0.7940, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6972, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7424719545188745
Current compression ratio of attn:  tensor(0.8007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7426794336159355
Current compression ratio of attn:  tensor(0.7910, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7428840274934811
Current compression ratio of attn:  tensor(0.8020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6943, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7430857353566889
Current compression ratio of attn:  tensor(0.7983, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6972, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7432845564219482
Current compression ratio of attn:  tensor(0.7977, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6982, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7434804899168634
Current compression ratio of attn:  tensor(0.7970, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6991, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7436735350802566
Current compression ratio of attn:  tensor(0.8015, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7438636911621708
Current compression ratio of attn:  tensor(0.7962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7440509574238725
Search Epoch: [8]  [ 5000/17710]  eta: 2:56:15  lr: 0.00001000  loss: 10.4413  loss_ita: 7.0426  loss_sp_attn: 1.3777  loss_sp_mlp: 2.0210  time: 0.8209  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.8007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6988, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7442353331378552
Current compression ratio of attn:  tensor(0.7978, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7444168175878415
Current compression ratio of attn:  tensor(0.8002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7445954100687864
Current compression ratio of attn:  tensor(0.7974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7447711098868797
Current compression ratio of attn:  tensor(0.7997, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7015, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.744943916359549
Current compression ratio of attn:  tensor(0.8003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7451138288154621
Current compression ratio of attn:  tensor(0.8039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7452808465945295
Current compression ratio of attn:  tensor(0.7981, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7454449690479078
Current compression ratio of attn:  tensor(0.8030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7456061955380009
Current compression ratio of attn:  tensor(0.8027, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7457645254384634
Current compression ratio of attn:  tensor(0.8038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.745919958134203
Current compression ratio of attn:  tensor(0.7975, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7066, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7460724930213825
Current compression ratio of attn:  tensor(0.8084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7462221295074222
Current compression ratio of attn:  tensor(0.8038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7037, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7463688670110027
Current compression ratio of attn:  tensor(0.8035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7465127049620666
Current compression ratio of attn:  tensor(0.8084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7466536428018207
Current compression ratio of attn:  tensor(0.8069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7467916799827389
Current compression ratio of attn:  tensor(0.8057, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7469268159685631
Current compression ratio of attn:  tensor(0.8033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7470590502343069
Current compression ratio of attn:  tensor(0.8038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7471883822662557
Current compression ratio of attn:  tensor(0.8070, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7473148115619704
Current compression ratio of attn:  tensor(0.8054, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7474383376302889
Current compression ratio of attn:  tensor(0.8064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7475589599913267
Current compression ratio of attn:  tensor(0.8026, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7476766781764812
Current compression ratio of attn:  tensor(0.8114, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7477914917284313
Search Epoch: [8]  [10000/17710]  eta: 1:46:56  lr: 0.00001000  loss: 10.0229  loss_ita: 6.7450  loss_sp_attn: 1.2746  loss_sp_mlp: 2.0032  time: 0.8433  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.8089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7479034002011402
Current compression ratio of attn:  tensor(0.8095, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7480124031598572
Current compression ratio of attn:  tensor(0.8118, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7481185001811188
Current compression ratio of attn:  tensor(0.8084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7482216908527511
Current compression ratio of attn:  tensor(0.8085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.748321974773871
Current compression ratio of attn:  tensor(0.8095, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7484193515548873
Current compression ratio of attn:  tensor(0.8083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7078, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7485138208175032
Current compression ratio of attn:  tensor(0.8097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7486053821947172
Current compression ratio of attn:  tensor(0.8124, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7058, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7486940353308242
Current compression ratio of attn:  tensor(0.8099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7487797798814178
Current compression ratio of attn:  tensor(0.8095, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7488626155133905
Current compression ratio of attn:  tensor(0.8144, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.748942541904936
Current compression ratio of attn:  tensor(0.8127, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7490195587455503
Current compression ratio of attn:  tensor(0.8146, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7490936657360319
Current compression ratio of attn:  tensor(0.8142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7063, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7491648625884844
Current compression ratio of attn:  tensor(0.8125, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7492331490263164
Current compression ratio of attn:  tensor(0.8087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7492985247842436
Current compression ratio of attn:  tensor(0.8131, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.749360989608289
Current compression ratio of attn:  tensor(0.8106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7494205432557844
Current compression ratio of attn:  tensor(0.8150, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7494771854953711
Current compression ratio of attn:  tensor(0.8142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7495309161070008
Current compression ratio of attn:  tensor(0.8125, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7495817348819368
Current compression ratio of attn:  tensor(0.8134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496296416227539
Current compression ratio of attn:  tensor(0.8121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496746361433407
Current compression ratio of attn:  tensor(0.8152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497167182688986
Search Epoch: [8]  [15000/17710]  eta: 0:37:35  lr: 0.00001000  loss: 10.2371  loss_ita: 7.0112  loss_sp_attn: 1.2487  loss_sp_mlp: 1.9772  time: 0.8204  data: 0.0002  max mem: 30592
Current compression ratio of attn:  tensor(0.8157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497558878359438
Current compression ratio of attn:  tensor(0.8179, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497921446923073
Current compression ratio of attn:  tensor(0.8145, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498254886971355
Current compression ratio of attn:  tensor(0.8136, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498559197208912
Current compression ratio of attn:  tensor(0.8154, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498834376453531
Current compression ratio of attn:  tensor(0.8141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499080423636181
Current compression ratio of attn:  tensor(0.8150, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499297337800992
Current compression ratio of attn:  tensor(0.8181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499485118105282
Current compression ratio of attn:  tensor(0.8142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499643763819548
Current compression ratio of attn:  tensor(0.8177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499773274327468
Current compression ratio of attn:  tensor(0.8099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7116, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499873649125912
Current compression ratio of attn:  tensor(0.8155, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499944887824934
Current compression ratio of attn:  tensor(0.8164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499986990147782
Current compression ratio of attn:  tensor(0.8160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.7079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.75
Search Epoch: [8]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 10.4203  loss_ita: 7.2036  loss_sp_attn: 1.2408  loss_sp_mlp: 1.9759  time: 0.8453  data: 0.0007  max mem: 30592
Search Epoch: [8] Total time: 4:05:40 (0.8323 s / it)
Averaged stats: lr: 0.0000  loss: 10.0156  loss_ita: 6.6845  loss_sp_attn: 1.3193  loss_sp_mlp: 2.0118
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 22.48, 'txt_r5': 46.98, 'txt_r10': 59.9, 'txt_r_mean': 43.12, 'img_r1': 15.70171931227509, 'img_r5': 37.792882846861254, 'img_r10': 49.636145541783286, 'img_r_mean': 34.37691590030654, 'r_mean': 38.748457950153266}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0484
Text_CKA_Similarity: 0.2233
Image_Cosine_Similarity: 0.0498
Image_CKA_Similarity: 0.5791
sim_matrix_pearson_correlation: 0.2728
mask_attn_vision:   [1.56, 1.56, 1.56, 1.56, 1.56, 1.56, 45.31, 25.0, 40.62, 42.19, 46.88, 34.38, 25.0, 40.62, 40.62, 20.31, 21.88, 18.75, 15.62, 10.94, 14.06, 7.81, 18.75, 12.5]
mask_attn_language:  [57.81, 35.94, 10.94, 7.81, 3.12, 6.25, 3.12, 6.25, 7.81, 12.5, 10.94, 9.38]
mask_mlp_vision:  [60.55, 16.94, 20.92, 20.53, 28.83, 24.34, 33.28, 32.96, 41.82, 49.66, 46.39, 47.73, 56.81, 48.12, 44.09, 39.48, 22.92, 15.31, 13.7, 13.43, 17.33, 22.36, 22.73, 20.41]
mask_mlp_language:  [56.38, 21.78, 16.7, 19.4, 19.82, 20.28, 20.18, 18.13, 18.95, 18.52, 19.56, 21.32]
mask_vision:  0.31520432233810425
mask_language:  0.22417090833187103
mask_attn:  0.1840277761220932
mask_mlp:  0.29209578037261963
Creating model for training
VisionTransformerを作成
Start training
KD:False
Train Epoch: [0]  [    0/17710]  eta: 5:29:35  lr: 0.00001000  loss: 6.9180  time: 1.1167  data: 0.4605  max mem: 30592
KD is False
Train Epoch: [0]  [ 5000/17710]  eta: 1:37:52  lr: 0.00001000  loss: 4.8452  time: 0.4570  data: 0.0002  max mem: 30592
Train Epoch: [0]  [10000/17710]  eta: 0:59:20  lr: 0.00001000  loss: 4.6626  time: 0.4628  data: 0.0003  max mem: 30592
Train Epoch: [0]  [15000/17710]  eta: 0:20:50  lr: 0.00001000  loss: 4.0611  time: 0.4574  data: 0.0002  max mem: 30592
Train Epoch: [0]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 3.3076  time: 0.4677  data: 0.0007  max mem: 30592
Train Epoch: [0] Total time: 2:16:01 (0.4608 s / it)
Averaged stats: lr: 0.0000  loss: 3.9508
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0725
Text_CKA_Similarity: 0.4859
Image_Cosine_Similarity: 0.1343
Image_CKA_Similarity: 0.7084
sim_matrix_pearson_correlation: 0.6128
{'txt_r1': 54.06, 'txt_r5': 80.88, 'txt_r10': 88.5, 'txt_r_mean': 74.48, 'img_r1': 39.2562974810076, 'img_r5': 69.18032786885246, 'img_r10': 79.52019192323071, 'img_r_mean': 62.652272424363595, 'r_mean': 68.5661362121818}
{'txt_r1': 53.24, 'txt_r5': 79.76, 'txt_r10': 88.02, 'txt_r_mean': 73.67333333333333, 'img_r1': 39.11235505797681, 'img_r5': 68.45261895241903, 'img_r10': 79.06437425029988, 'img_r_mean': 62.20978275356524, 'r_mean': 67.94155804344929}
LOG:  {'train_lr': '0.000', 'train_loss': '3.951', 'val_txt_r1': 54.06, 'val_txt_r5': 80.88, 'val_txt_r10': 88.5, 'val_txt_r_mean': 74.48, 'val_img_r1': 39.2562974810076, 'val_img_r5': 69.18032786885246, 'val_img_r10': 79.52019192323071, 'val_img_r_mean': 62.652272424363595, 'val_r_mean': 68.5661362121818, 'test_txt_r1': 53.24, 'test_txt_r5': 79.76, 'test_txt_r10': 88.02, 'test_txt_r_mean': 73.67333333333333, 'test_img_r1': 39.11235505797681, 'test_img_r5': 68.45261895241903, 'test_img_r10': 79.06437425029988, 'test_img_r_mean': 62.20978275356524, 'test_r_mean': 67.94155804344929, 'epoch': 0, 'best_epoch': 0}
KD:False
Train Epoch: [1]  [    0/17710]  eta: 5:22:27  lr: 0.00000970  loss: 5.1255  time: 1.0925  data: 0.4197  max mem: 30592
KD is False
Train Epoch: [1]  [ 5000/17710]  eta: 1:37:34  lr: 0.00000970  loss: 3.8369  time: 0.4843  data: 0.0002  max mem: 30592
Train Epoch: [1]  [10000/17710]  eta: 0:59:10  lr: 0.00000970  loss: 3.2415  time: 0.4755  data: 0.0002  max mem: 30592
Train Epoch: [1]  [15000/17710]  eta: 0:20:43  lr: 0.00000970  loss: 3.4870  time: 0.4507  data: 0.0002  max mem: 30592
Train Epoch: [1]  [17709/17710]  eta: 0:00:00  lr: 0.00000970  loss: 2.3386  time: 0.4611  data: 0.0012  max mem: 30592
Train Epoch: [1] Total time: 2:15:24 (0.4587 s / it)
Averaged stats: lr: 0.0000  loss: 3.6313
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0724
Text_CKA_Similarity: 0.5031
Image_Cosine_Similarity: 0.1275
Image_CKA_Similarity: 0.7092
sim_matrix_pearson_correlation: 0.6036
{'txt_r1': 56.38, 'txt_r5': 83.12, 'txt_r10': 90.6, 'txt_r_mean': 76.7, 'img_r1': 41.96321471411436, 'img_r5': 71.06357457017194, 'img_r10': 81.33546581367453, 'img_r_mean': 64.78741836598694, 'r_mean': 70.74370918299347}
{'txt_r1': 56.5, 'txt_r5': 82.16, 'txt_r10': 89.52, 'txt_r_mean': 76.06, 'img_r1': 41.52738904438225, 'img_r5': 70.56777289084366, 'img_r10': 81.22750899640144, 'img_r_mean': 64.44089031054244, 'r_mean': 70.25044515527122}
LOG:  {'train_lr': '0.000', 'train_loss': '3.631', 'val_txt_r1': 56.38, 'val_txt_r5': 83.12, 'val_txt_r10': 90.6, 'val_txt_r_mean': 76.7, 'val_img_r1': 41.96321471411436, 'val_img_r5': 71.06357457017194, 'val_img_r10': 81.33546581367453, 'val_img_r_mean': 64.78741836598694, 'val_r_mean': 70.74370918299347, 'test_txt_r1': 56.5, 'test_txt_r5': 82.16, 'test_txt_r10': 89.52, 'test_txt_r_mean': 76.06, 'test_img_r1': 41.52738904438225, 'test_img_r5': 70.56777289084366, 'test_img_r10': 81.22750899640144, 'test_img_r_mean': 64.44089031054244, 'test_r_mean': 70.25044515527122, 'epoch': 1, 'best_epoch': 1}
KD:False
Train Epoch: [2]  [    0/17710]  eta: 5:11:03  lr: 0.00000883  loss: 4.2283  time: 1.0538  data: 0.4113  max mem: 30592
KD is False
Train Epoch: [2]  [ 5000/17710]  eta: 1:37:09  lr: 0.00000883  loss: 4.2069  time: 0.4495  data: 0.0002  max mem: 30592
Train Epoch: [2]  [10000/17710]  eta: 0:58:45  lr: 0.00000883  loss: 2.9883  time: 0.4512  data: 0.0002  max mem: 30592
Train Epoch: [2]  [15000/17710]  eta: 0:20:38  lr: 0.00000883  loss: 3.5628  time: 0.4555  data: 0.0002  max mem: 30592
Train Epoch: [2]  [17709/17710]  eta: 0:00:00  lr: 0.00000883  loss: 2.3817  time: 0.4942  data: 0.0012  max mem: 30592
Train Epoch: [2] Total time: 2:14:48 (0.4567 s / it)
Averaged stats: lr: 0.0000  loss: 3.3788
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0567
Text_CKA_Similarity: 0.5115
Image_Cosine_Similarity: 0.0794
Image_CKA_Similarity: 0.6989
sim_matrix_pearson_correlation: 0.5665
{'txt_r1': 58.9, 'txt_r5': 84.7, 'txt_r10': 92.1, 'txt_r_mean': 78.56666666666666, 'img_r1': 43.37065173930428, 'img_r5': 72.05117952818873, 'img_r10': 82.09116353458617, 'img_r_mean': 65.83766493402639, 'r_mean': 72.20216580034653}
{'txt_r1': 58.72, 'txt_r5': 83.72, 'txt_r10': 90.72, 'txt_r_mean': 77.72, 'img_r1': 42.39904038384646, 'img_r5': 71.32746901239504, 'img_r10': 81.53138744502199, 'img_r_mean': 65.08596561375451, 'r_mean': 71.40298280687725}
LOG:  {'train_lr': '0.000', 'train_loss': '3.379', 'val_txt_r1': 58.9, 'val_txt_r5': 84.7, 'val_txt_r10': 92.1, 'val_txt_r_mean': 78.56666666666666, 'val_img_r1': 43.37065173930428, 'val_img_r5': 72.05117952818873, 'val_img_r10': 82.09116353458617, 'val_img_r_mean': 65.83766493402639, 'val_r_mean': 72.20216580034653, 'test_txt_r1': 58.72, 'test_txt_r5': 83.72, 'test_txt_r10': 90.72, 'test_txt_r_mean': 77.72, 'test_img_r1': 42.39904038384646, 'test_img_r5': 71.32746901239504, 'test_img_r10': 81.53138744502199, 'test_img_r_mean': 65.08596561375451, 'test_r_mean': 71.40298280687725, 'epoch': 2, 'best_epoch': 2}
KD:False
Train Epoch: [3]  [    0/17710]  eta: 5:09:29  lr: 0.00000750  loss: 3.5607  time: 1.0485  data: 0.3831  max mem: 30592
KD is False
Train Epoch: [3]  [ 5000/17710]  eta: 1:36:53  lr: 0.00000750  loss: 3.4028  time: 0.4725  data: 0.0003  max mem: 30592
Train Epoch: [3]  [10000/17710]  eta: 0:58:35  lr: 0.00000750  loss: 1.8237  time: 0.4853  data: 0.0002  max mem: 30592
Train Epoch: [3]  [15000/17710]  eta: 0:20:34  lr: 0.00000750  loss: 3.9494  time: 0.4622  data: 0.0002  max mem: 30592
Train Epoch: [3]  [17709/17710]  eta: 0:00:00  lr: 0.00000750  loss: 3.7446  time: 0.4546  data: 0.0012  max mem: 30592
Train Epoch: [3] Total time: 2:14:32 (0.4558 s / it)
Averaged stats: lr: 0.0000  loss: 3.1680
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0584
Text_CKA_Similarity: 0.4967
Image_Cosine_Similarity: 0.1130
Image_CKA_Similarity: 0.6883
sim_matrix_pearson_correlation: 0.5631
{'txt_r1': 59.8, 'txt_r5': 85.58, 'txt_r10': 92.4, 'txt_r_mean': 79.26, 'img_r1': 44.56617353058777, 'img_r5': 73.47860855657737, 'img_r10': 82.79088364654139, 'img_r_mean': 66.94522191123552, 'r_mean': 73.10261095561776}
{'txt_r1': 59.04, 'txt_r5': 84.32, 'txt_r10': 91.36, 'txt_r_mean': 78.24, 'img_r1': 43.79048380647741, 'img_r5': 72.5029988004798, 'img_r10': 82.45101959216314, 'img_r_mean': 66.24816739970679, 'r_mean': 72.24408369985339}
LOG:  {'train_lr': '0.000', 'train_loss': '3.168', 'val_txt_r1': 59.8, 'val_txt_r5': 85.58, 'val_txt_r10': 92.4, 'val_txt_r_mean': 79.26, 'val_img_r1': 44.56617353058777, 'val_img_r5': 73.47860855657737, 'val_img_r10': 82.79088364654139, 'val_img_r_mean': 66.94522191123552, 'val_r_mean': 73.10261095561776, 'test_txt_r1': 59.04, 'test_txt_r5': 84.32, 'test_txt_r10': 91.36, 'test_txt_r_mean': 78.24, 'test_img_r1': 43.79048380647741, 'test_img_r5': 72.5029988004798, 'test_img_r10': 82.45101959216314, 'test_img_r_mean': 66.24816739970679, 'test_r_mean': 72.24408369985339, 'epoch': 3, 'best_epoch': 3}
KD:False
Train Epoch: [4]  [    0/17710]  eta: 5:16:59  lr: 0.00000587  loss: 2.2137  time: 1.0739  data: 0.4136  max mem: 30592
KD is False
Train Epoch: [4]  [ 5000/17710]  eta: 1:37:02  lr: 0.00000587  loss: 3.0594  time: 0.4615  data: 0.0002  max mem: 30592
Train Epoch: [4]  [10000/17710]  eta: 0:58:41  lr: 0.00000587  loss: 2.7696  time: 0.4633  data: 0.0002  max mem: 30592
Train Epoch: [4]  [15000/17710]  eta: 0:20:34  lr: 0.00000587  loss: 3.3453  time: 0.4550  data: 0.0002  max mem: 30592
Train Epoch: [4]  [17709/17710]  eta: 0:00:00  lr: 0.00000587  loss: 2.6131  time: 0.4859  data: 0.0012  max mem: 30592
Train Epoch: [4] Total time: 2:14:27 (0.4556 s / it)
Averaged stats: lr: 0.0000  loss: 2.9758
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0566
Text_CKA_Similarity: 0.4957
Image_Cosine_Similarity: 0.0814
Image_CKA_Similarity: 0.6738
sim_matrix_pearson_correlation: 0.5563
{'txt_r1': 58.62, 'txt_r5': 85.38, 'txt_r10': 92.42, 'txt_r_mean': 78.80666666666667, 'img_r1': 44.55017992802879, 'img_r5': 73.47461015593763, 'img_r10': 82.87085165933627, 'img_r_mean': 66.96521391443423, 'r_mean': 72.88594029055045}
LOG:  {'train_lr': '0.000', 'train_loss': '2.976', 'val_txt_r1': 58.62, 'val_txt_r5': 85.38, 'val_txt_r10': 92.42, 'val_txt_r_mean': 78.80666666666667, 'val_img_r1': 44.55017992802879, 'val_img_r5': 73.47461015593763, 'val_img_r10': 82.87085165933627, 'val_img_r_mean': 66.96521391443423, 'val_r_mean': 72.88594029055045, 'test_txt_r1': 59.04, 'test_txt_r5': 84.32, 'test_txt_r10': 91.36, 'test_txt_r_mean': 78.24, 'test_img_r1': 43.79048380647741, 'test_img_r5': 72.5029988004798, 'test_img_r10': 82.45101959216314, 'test_img_r_mean': 66.24816739970679, 'test_r_mean': 72.24408369985339, 'epoch': 4, 'best_epoch': 3}
KD:False
Train Epoch: [5]  [    0/17710]  eta: 5:15:53  lr: 0.00000413  loss: 4.5481  time: 1.0702  data: 0.4179  max mem: 30592
KD is False
Train Epoch: [5]  [ 5000/17710]  eta: 1:37:28  lr: 0.00000413  loss: 1.5081  time: 0.4587  data: 0.0002  max mem: 30592
Train Epoch: [5]  [10000/17710]  eta: 0:59:16  lr: 0.00000413  loss: 2.8672  time: 0.4669  data: 0.0002  max mem: 30592
Train Epoch: [5]  [15000/17710]  eta: 0:20:49  lr: 0.00000413  loss: 2.7703  time: 0.4665  data: 0.0002  max mem: 30592
Train Epoch: [5]  [17709/17710]  eta: 0:00:00  lr: 0.00000413  loss: 1.8380  time: 0.4836  data: 0.0012  max mem: 30592
Train Epoch: [5] Total time: 2:16:21 (0.4620 s / it)
Averaged stats: lr: 0.0000  loss: 2.7924
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0559
Text_CKA_Similarity: 0.4754
Image_Cosine_Similarity: 0.0960
Image_CKA_Similarity: 0.6477
sim_matrix_pearson_correlation: 0.5331
{'txt_r1': 60.04, 'txt_r5': 85.74, 'txt_r10': 92.68, 'txt_r_mean': 79.48666666666666, 'img_r1': 45.31387445021991, 'img_r5': 74.24230307876849, 'img_r10': 83.21071571371452, 'img_r_mean': 67.5889644142343, 'r_mean': 73.53781554045048}
{'txt_r1': 60.68, 'txt_r5': 85.46, 'txt_r10': 91.98, 'txt_r_mean': 79.37333333333333, 'img_r1': 44.7141143542583, 'img_r5': 73.47061175529788, 'img_r10': 82.6469412235106, 'img_r_mean': 66.94388911102226, 'r_mean': 73.1586112221778}
LOG:  {'train_lr': '0.000', 'train_loss': '2.792', 'val_txt_r1': 60.04, 'val_txt_r5': 85.74, 'val_txt_r10': 92.68, 'val_txt_r_mean': 79.48666666666666, 'val_img_r1': 45.31387445021991, 'val_img_r5': 74.24230307876849, 'val_img_r10': 83.21071571371452, 'val_img_r_mean': 67.5889644142343, 'val_r_mean': 73.53781554045048, 'test_txt_r1': 60.68, 'test_txt_r5': 85.46, 'test_txt_r10': 91.98, 'test_txt_r_mean': 79.37333333333333, 'test_img_r1': 44.7141143542583, 'test_img_r5': 73.47061175529788, 'test_img_r10': 82.6469412235106, 'test_img_r_mean': 66.94388911102226, 'test_r_mean': 73.1586112221778, 'epoch': 5, 'best_epoch': 5}
KD:False
Train Epoch: [6]  [    0/17710]  eta: 5:13:43  lr: 0.00000250  loss: 3.4913  time: 1.0629  data: 0.3733  max mem: 30592
KD is False
Train Epoch: [6]  [ 5000/17710]  eta: 1:37:11  lr: 0.00000250  loss: 2.3432  time: 0.4474  data: 0.0002  max mem: 30592
Train Epoch: [6]  [10000/17710]  eta: 0:59:03  lr: 0.00000250  loss: 2.7649  time: 0.4637  data: 0.0002  max mem: 30592
Train Epoch: [6]  [15000/17710]  eta: 0:20:46  lr: 0.00000250  loss: 2.9166  time: 0.4545  data: 0.0002  max mem: 30592
Train Epoch: [6]  [17709/17710]  eta: 0:00:00  lr: 0.00000250  loss: 3.5274  time: 0.4909  data: 0.0012  max mem: 30592
Train Epoch: [6] Total time: 2:15:36 (0.4594 s / it)
Averaged stats: lr: 0.0000  loss: 2.6360
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0314
Text_CKA_Similarity: 0.4446
Image_Cosine_Similarity: 0.0791
Image_CKA_Similarity: 0.6361
sim_matrix_pearson_correlation: 0.5114
{'txt_r1': 60.32, 'txt_r5': 86.16, 'txt_r10': 93.1, 'txt_r_mean': 79.86, 'img_r1': 46.10955617752899, 'img_r5': 74.15833666533386, 'img_r10': 83.55857656937225, 'img_r_mean': 67.94215647074503, 'r_mean': 73.90107823537252}
{'txt_r1': 60.6, 'txt_r5': 85.84, 'txt_r10': 92.04, 'txt_r_mean': 79.49333333333334, 'img_r1': 45.1499400239904, 'img_r5': 73.51859256297482, 'img_r10': 82.55497800879648, 'img_r_mean': 67.07450353192057, 'r_mean': 73.28391843262696}
LOG:  {'train_lr': '0.000', 'train_loss': '2.636', 'val_txt_r1': 60.32, 'val_txt_r5': 86.16, 'val_txt_r10': 93.1, 'val_txt_r_mean': 79.86, 'val_img_r1': 46.10955617752899, 'val_img_r5': 74.15833666533386, 'val_img_r10': 83.55857656937225, 'val_img_r_mean': 67.94215647074503, 'val_r_mean': 73.90107823537252, 'test_txt_r1': 60.6, 'test_txt_r5': 85.84, 'test_txt_r10': 92.04, 'test_txt_r_mean': 79.49333333333334, 'test_img_r1': 45.1499400239904, 'test_img_r5': 73.51859256297482, 'test_img_r10': 82.55497800879648, 'test_img_r_mean': 67.07450353192057, 'test_r_mean': 73.28391843262696, 'epoch': 6, 'best_epoch': 6}
KD:False
Train Epoch: [7]  [    0/17710]  eta: 5:04:51  lr: 0.00000117  loss: 2.6901  time: 1.0328  data: 0.4153  max mem: 30592
KD is False
Train Epoch: [7]  [ 5000/17710]  eta: 1:37:08  lr: 0.00000117  loss: 1.5663  time: 0.4538  data: 0.0002  max mem: 30592
Train Epoch: [7]  [10000/17710]  eta: 0:58:41  lr: 0.00000117  loss: 2.0115  time: 0.4708  data: 0.0002  max mem: 30592
Train Epoch: [7]  [15000/17710]  eta: 0:20:36  lr: 0.00000117  loss: 3.5560  time: 0.4526  data: 0.0002  max mem: 30592
Train Epoch: [7]  [17709/17710]  eta: 0:00:00  lr: 0.00000117  loss: 2.6534  time: 0.4899  data: 0.0009  max mem: 30592
Train Epoch: [7] Total time: 2:14:33 (0.4559 s / it)
Averaged stats: lr: 0.0000  loss: 2.5202
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0404
Text_CKA_Similarity: 0.4270
Image_Cosine_Similarity: 0.0830
Image_CKA_Similarity: 0.6121
sim_matrix_pearson_correlation: 0.4966
{'txt_r1': 60.08, 'txt_r5': 86.16, 'txt_r10': 92.7, 'txt_r_mean': 79.64666666666666, 'img_r1': 45.40183926429428, 'img_r5': 73.83046781287484, 'img_r10': 83.02279088364654, 'img_r_mean': 67.41836598693855, 'r_mean': 73.53251632680261}
LOG:  {'train_lr': '0.000', 'train_loss': '2.520', 'val_txt_r1': 60.08, 'val_txt_r5': 86.16, 'val_txt_r10': 92.7, 'val_txt_r_mean': 79.64666666666666, 'val_img_r1': 45.40183926429428, 'val_img_r5': 73.83046781287484, 'val_img_r10': 83.02279088364654, 'val_img_r_mean': 67.41836598693855, 'val_r_mean': 73.53251632680261, 'test_txt_r1': 60.6, 'test_txt_r5': 85.84, 'test_txt_r10': 92.04, 'test_txt_r_mean': 79.49333333333334, 'test_img_r1': 45.1499400239904, 'test_img_r5': 73.51859256297482, 'test_img_r10': 82.55497800879648, 'test_img_r_mean': 67.07450353192057, 'test_r_mean': 73.28391843262696, 'epoch': 7, 'best_epoch': 6}
KD:False
Train Epoch: [8]  [    0/17710]  eta: 5:06:55  lr: 0.00000030  loss: 1.6781  time: 1.0398  data: 0.4658  max mem: 30592
KD is False
Train Epoch: [8]  [ 5000/17710]  eta: 1:37:03  lr: 0.00000030  loss: 2.5094  time: 0.4681  data: 0.0002  max mem: 30592
Train Epoch: [8]  [10000/17710]  eta: 0:58:51  lr: 0.00000030  loss: 2.6957  time: 0.4567  data: 0.0002  max mem: 30592
Train Epoch: [8]  [15000/17710]  eta: 0:20:41  lr: 0.00000030  loss: 2.2730  time: 0.4511  data: 0.0002  max mem: 30592
Train Epoch: [8]  [17709/17710]  eta: 0:00:00  lr: 0.00000030  loss: 2.5630  time: 0.4930  data: 0.0012  max mem: 30592
Train Epoch: [8] Total time: 2:15:17 (0.4584 s / it)
Averaged stats: lr: 0.0000  loss: 2.4844
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0378
Text_CKA_Similarity: 0.4208
Image_Cosine_Similarity: 0.0939
Image_CKA_Similarity: 0.6005
sim_matrix_pearson_correlation: 0.5048
{'txt_r1': 60.86, 'txt_r5': 86.06, 'txt_r10': 92.7, 'txt_r_mean': 79.87333333333333, 'img_r1': 45.5577768892443, 'img_r5': 73.70251899240304, 'img_r10': 82.94282287085166, 'img_r_mean': 67.40103958416633, 'r_mean': 73.63718645874982}
LOG:  {'train_lr': '0.000', 'train_loss': '2.484', 'val_txt_r1': 60.86, 'val_txt_r5': 86.06, 'val_txt_r10': 92.7, 'val_txt_r_mean': 79.87333333333333, 'val_img_r1': 45.5577768892443, 'val_img_r5': 73.70251899240304, 'val_img_r10': 82.94282287085166, 'val_img_r_mean': 67.40103958416633, 'val_r_mean': 73.63718645874982, 'test_txt_r1': 60.6, 'test_txt_r5': 85.84, 'test_txt_r10': 92.04, 'test_txt_r_mean': 79.49333333333334, 'test_img_r1': 45.1499400239904, 'test_img_r5': 73.51859256297482, 'test_img_r10': 82.55497800879648, 'test_img_r_mean': 67.07450353192057, 'test_r_mean': 73.28391843262696, 'epoch': 8, 'best_epoch': 6}
