| distributed init (rank 0, word 4): env://
| distributed init (rank 3, word 4): env://
| distributed init (rank 2, word 4): env://
| distributed init (rank 1, word 4): env://
node21:1705384:1705384 [0] NCCL INFO Bootstrap : Using eno1:192.168.170.21<0>
node21:1705384:1705384 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node21:1705384:1705384 [0] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.21<0> [1]eno2:10.0.0.21<0> [2]veth19f1e29:fe80::9cb6:ccff:fee2:96b3%veth19f1e29<0>
node21:1705384:1705384 [0] NCCL INFO Using network Socket
NCCL version 2.10.3+cuda11.3
node21:1705387:1705387 [3] NCCL INFO Bootstrap : Using eno1:192.168.170.21<0>
node21:1705387:1705387 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node21:1705387:1705387 [3] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.21<0> [1]eno2:10.0.0.21<0> [2]veth19f1e29:fe80::9cb6:ccff:fee2:96b3%veth19f1e29<0>
node21:1705387:1705387 [3] NCCL INFO Using network Socket
node21:1705385:1705385 [1] NCCL INFO Bootstrap : Using eno1:192.168.170.21<0>
node21:1705385:1705385 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node21:1705385:1705385 [1] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.21<0> [1]eno2:10.0.0.21<0> [2]veth19f1e29:fe80::9cb6:ccff:fee2:96b3%veth19f1e29<0>
node21:1705385:1705385 [1] NCCL INFO Using network Socket
node21:1705386:1705386 [2] NCCL INFO Bootstrap : Using eno1:192.168.170.21<0>
node21:1705386:1705386 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node21:1705386:1705386 [2] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.21<0> [1]eno2:10.0.0.21<0> [2]veth19f1e29:fe80::9cb6:ccff:fee2:96b3%veth19f1e29<0>
node21:1705386:1705386 [2] NCCL INFO Using network Socket
node21:1705384:1705433 [0] NCCL INFO Channel 00/02 :    0   1   2   3
node21:1705384:1705433 [0] NCCL INFO Channel 01/02 :    0   1   2   3
node21:1705386:1705436 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
node21:1705384:1705433 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
node21:1705385:1705435 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
node21:1705387:1705434 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
node21:1705384:1705433 [0] NCCL INFO Setting affinity for GPU 0 to ff,ff000000,0000ffff
node21:1705386:1705436 [2] NCCL INFO Setting affinity for GPU 2 to 0f,fff00000,00000fff,f0000000
node21:1705385:1705435 [1] NCCL INFO Setting affinity for GPU 1 to ff,ff000000,0000ffff
node21:1705387:1705434 [3] NCCL INFO Setting affinity for GPU 3 to 0f,fff00000,00000fff,f0000000
node21:1705387:1705434 [3] NCCL INFO Channel 00 : 3[ca000] -> 0[31000] via direct shared memory
node21:1705387:1705434 [3] NCCL INFO Channel 01 : 3[ca000] -> 0[31000] via direct shared memory
node21:1705386:1705436 [2] NCCL INFO Channel 00 : 2[b1000] -> 3[ca000] via direct shared memory
node21:1705386:1705436 [2] NCCL INFO Channel 01 : 2[b1000] -> 3[ca000] via direct shared memory
node21:1705384:1705433 [0] NCCL INFO Channel 00 : 0[31000] -> 1[4b000] via direct shared memory
node21:1705384:1705433 [0] NCCL INFO Channel 01 : 0[31000] -> 1[4b000] via direct shared memory
node21:1705385:1705435 [1] NCCL INFO Channel 00 : 1[4b000] -> 2[b1000] via direct shared memory
node21:1705385:1705435 [1] NCCL INFO Channel 01 : 1[4b000] -> 2[b1000] via direct shared memory
node21:1705387:1705434 [3] NCCL INFO Connected all rings
node21:1705386:1705436 [2] NCCL INFO Connected all rings
node21:1705387:1705434 [3] NCCL INFO Channel 00 : 3[ca000] -> 2[b1000] via direct shared memory
node21:1705385:1705435 [1] NCCL INFO Connected all rings
node21:1705384:1705433 [0] NCCL INFO Connected all rings
node21:1705387:1705434 [3] NCCL INFO Channel 01 : 3[ca000] -> 2[b1000] via direct shared memory
node21:1705386:1705436 [2] NCCL INFO Channel 00 : 2[b1000] -> 1[4b000] via direct shared memory
node21:1705386:1705436 [2] NCCL INFO Channel 01 : 2[b1000] -> 1[4b000] via direct shared memory
node21:1705385:1705435 [1] NCCL INFO Channel 00 : 1[4b000] -> 0[31000] via direct shared memory
node21:1705385:1705435 [1] NCCL INFO Channel 01 : 1[4b000] -> 0[31000] via direct shared memory
node21:1705384:1705433 [0] NCCL INFO Connected all trees
node21:1705384:1705433 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node21:1705384:1705433 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node21:1705387:1705434 [3] NCCL INFO Connected all trees
node21:1705387:1705434 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node21:1705387:1705434 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node21:1705386:1705436 [2] NCCL INFO Connected all trees
node21:1705386:1705436 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node21:1705386:1705436 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node21:1705385:1705435 [1] NCCL INFO Connected all trees
node21:1705385:1705435 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node21:1705385:1705435 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node21:1705384:1705433 [0] NCCL INFO comm 0x7c1034003070 rank 0 nranks 4 cudaDev 0 busId 31000 - Init COMPLETE
node21:1705385:1705435 [1] NCCL INFO comm 0x73dc64003070 rank 1 nranks 4 cudaDev 1 busId 4b000 - Init COMPLETE
node21:1705386:1705436 [2] NCCL INFO comm 0x7754e0003070 rank 2 nranks 4 cudaDev 2 busId b1000 - Init COMPLETE
node21:1705387:1705434 [3] NCCL INFO comm 0x723af0003070 rank 3 nranks 4 cudaDev 3 busId ca000 - Init COMPLETE
node21:1705384:1705384 [0] NCCL INFO Launch mode Parallel
Target compression ratio: 75.0%
Creating retrieval dataset
Using downloaded and verified file: annotation/coco_karpathy_train.json
Using downloaded and verified file: annotation/coco_karpathy_val.json
Using downloaded and verified file: annotation/coco_karpathy_test.json
Creating model for searching
VisionTransformerを作成
VisionTransformerを作成
teacher_model evaluation
Computing features for evaluation...
do itm_eval
test_result_teacher {'txt_r1': 71.56, 'txt_r5': 90.84, 'txt_r10': 95.4, 'txt_r_mean': 85.93333333333334, 'img_r1': 56.837265093962415, 'img_r5': 80.67572970811675, 'img_r10': 87.65293882447021, 'img_r_mean': 75.05531120884979, 'r_mean': 80.49432227109156}
KD True
Start searching
KD:True
mask_update_step
Current compression ratio of attn:  tensor(0., device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0., device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  7.3912862300216045e-06
Search Epoch: [0]  [    0/17710]  eta: 13:54:36  lr: 0.00001000  loss: 17.9517  loss_ita: 4.4349  loss_sp_attn: 6.7584  loss_sp_mlp: 6.7584  time: 2.8276  data: 1.2141  max mem: 42234
mask_update_step
Current compression ratio of attn:  tensor(3.3975e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(2.3842e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0014856477282517901
mask_update_step
Current compression ratio of attn:  tensor(1.8835e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(6.6757e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.002963898397875447
mask_update_step
Current compression ratio of attn:  tensor(4.6313e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(1.2815e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.004442137553113352
mask_update_step
Current compression ratio of attn:  tensor(8.5592e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(2.2769e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.005920359451184036
mask_update_step
Current compression ratio of attn:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(3.1292e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0073985583493792785
mask_update_step
Current compression ratio of attn:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(4.8280e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.008876728505071634
mask_update_step
Current compression ratio of attn:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(6.6996e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01035486417575154
mask_update_step
Current compression ratio of attn:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(8.6784e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01183295961903906
mask_update_step
Current compression ratio of attn:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.013311009092714682
mask_update_step
Current compression ratio of attn:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.014789006854734655
mask_update_step
Current compression ratio of attn:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01626694716325612
mask_update_step
Current compression ratio of attn:  tensor(0.0008, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.017744824276661013
mask_update_step
Current compression ratio of attn:  tensor(0.0009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.019222632453576173
mask_update_step
Current compression ratio of attn:  tensor(0.0011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.020700365952895317
mask_update_step
Current compression ratio of attn:  tensor(0.0012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.022178019033804126
mask_update_step
Current compression ratio of attn:  tensor(0.0014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.023655585955799172
mask_update_step
Current compression ratio of attn:  tensor(0.0016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.02513306097871193
mask_update_step
Current compression ratio of attn:  tensor(0.0017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.026610438362731758
mask_update_step
Current compression ratio of attn:  tensor(0.0019, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.02808771236842607
mask_update_step
Current compression ratio of attn:  tensor(0.0022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.02956487725676441
mask_update_step
Current compression ratio of attn:  tensor(0.0024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.031041927289140698
mask_update_step
Current compression ratio of attn:  tensor(0.0026, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.032518856727395136
mask_update_step
Current compression ratio of attn:  tensor(0.0028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.033995659833835394
mask_update_step
Current compression ratio of attn:  tensor(0.0031, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0008, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03547233087126095
mask_update_step
Current compression ratio of attn:  tensor(0.0033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03694886410298356
Search Epoch: [0]  [ 5000/17710]  eta: 4:07:12  lr: 0.00001000  loss: 18.2853  loss_ita: 4.7948  loss_sp_attn: 6.7377  loss_sp_mlp: 6.7528  time: 1.1918  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.0036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.038425253792850854
mask_update_step
Current compression ratio of attn:  tensor(0.0038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.039901494205268125
mask_update_step
Current compression ratio of attn:  tensor(0.0041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04137757960522
mask_update_step
Current compression ratio of attn:  tensor(0.0044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04285350425829422
mask_update_step
Current compression ratio of attn:  tensor(0.0047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04432926243070241
mask_update_step
Current compression ratio of attn:  tensor(0.0050, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0015, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04580484838930303
mask_update_step
Current compression ratio of attn:  tensor(0.0052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04728025640162357
mask_update_step
Current compression ratio of attn:  tensor(0.0056, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.048755480735883025
mask_update_step
Current compression ratio of attn:  tensor(0.0058, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0019, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05023051566101345
mask_update_step
Current compression ratio of attn:  tensor(0.0062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05170535544668334
mask_update_step
Current compression ratio of attn:  tensor(0.0065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0021, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.053179994363319154
mask_update_step
Current compression ratio of attn:  tensor(0.0069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05465442668212743
mask_update_step
Current compression ratio of attn:  tensor(0.0071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.056128646675117286
mask_update_step
Current compression ratio of attn:  tensor(0.0075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.057602648615122855
mask_update_step
Current compression ratio of attn:  tensor(0.0079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0026, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05907642677582574
mask_update_step
Current compression ratio of attn:  tensor(0.0082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0605499754317763
mask_update_step
Current compression ratio of attn:  tensor(0.0086, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06202328885841684
mask_update_step
Current compression ratio of attn:  tensor(0.0090, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06349636133210318
mask_update_step
Current compression ratio of attn:  tensor(0.0093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06496918713012782
mask_update_step
Current compression ratio of attn:  tensor(0.0096, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06644176053074069
mask_update_step
Current compression ratio of attn:  tensor(0.0100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06791407581317324
mask_update_step
Current compression ratio of attn:  tensor(0.0103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0040, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06938612725765893
mask_update_step
Current compression ratio of attn:  tensor(0.0108, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07085790914545662
mask_update_step
Current compression ratio of attn:  tensor(0.0111, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07232941575887186
mask_update_step
Current compression ratio of attn:  tensor(0.0117, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0045, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07380064138128026
Search Epoch: [0]  [10000/17710]  eta: 2:30:03  lr: 0.00001000  loss: 18.8671  loss_ita: 5.4553  loss_sp_attn: 6.6832  loss_sp_mlp: 6.7286  time: 1.2087  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.0121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07527158029714863
mask_update_step
Current compression ratio of attn:  tensor(0.0125, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0050, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0767422267920575
mask_update_step
Current compression ratio of attn:  tensor(0.0129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07821257515272403
mask_update_step
Current compression ratio of attn:  tensor(0.0134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0054, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07968261966702295
mask_update_step
Current compression ratio of attn:  tensor(0.0139, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0057, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08115235462400965
mask_update_step
Current compression ratio of attn:  tensor(0.0142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08262177431394206
mask_update_step
Current compression ratio of attn:  tensor(0.0147, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08409087302830308
mask_update_step
Current compression ratio of attn:  tensor(0.0153, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08555964505982216
mask_update_step
Current compression ratio of attn:  tensor(0.0156, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08702808470249841
mask_update_step
Current compression ratio of attn:  tensor(0.0162, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08849618625162162
mask_update_step
Current compression ratio of attn:  tensor(0.0167, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08996394400379538
mask_update_step
Current compression ratio of attn:  tensor(0.0172, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09143135225695911
mask_update_step
Current compression ratio of attn:  tensor(0.0178, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09289840531040969
mask_update_step
Current compression ratio of attn:  tensor(0.0184, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09436509746482372
mask_update_step
Current compression ratio of attn:  tensor(0.0189, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09583142302228018
mask_update_step
Current compression ratio of attn:  tensor(0.0196, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09729737628628227
mask_update_step
Current compression ratio of attn:  tensor(0.0202, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0086, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09876295156177933
mask_update_step
Current compression ratio of attn:  tensor(0.0207, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10022814315518895
mask_update_step
Current compression ratio of attn:  tensor(0.0211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10169294537441986
mask_update_step
Current compression ratio of attn:  tensor(0.0218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0095, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10315735252889298
mask_update_step
Current compression ratio of attn:  tensor(0.0223, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0098, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.104621358929564
mask_update_step
Current compression ratio of attn:  tensor(0.0230, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10608495888894581
mask_update_step
Current compression ratio of attn:  tensor(0.0239, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0102, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10754814672113003
mask_update_step
Current compression ratio of attn:  tensor(0.0244, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10901091674180938
mask_update_step
Current compression ratio of attn:  tensor(0.0250, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1104732632682997
Search Epoch: [0]  [15000/17710]  eta: 0:52:46  lr: 0.00001000  loss: 18.3825  loss_ita: 5.1019  loss_sp_attn: 6.5938  loss_sp_mlp: 6.6868  time: 1.1817  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.0258, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0111, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1119351806195624
mask_update_step
Current compression ratio of attn:  tensor(0.0267, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11339666311622557
mask_update_step
Current compression ratio of attn:  tensor(0.0274, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0116, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11485770508060716
mask_update_step
Current compression ratio of attn:  tensor(0.0282, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0118, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11631830083673636
mask_update_step
Current compression ratio of attn:  tensor(0.0286, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1177784447103756
mask_update_step
Current compression ratio of attn:  tensor(0.0295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0124, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11923813102904338
mask_update_step
Current compression ratio of attn:  tensor(0.0303, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0127, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12069735412203514
mask_update_step
Current compression ratio of attn:  tensor(0.0309, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0131, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12215610832044638
mask_update_step
Current compression ratio of attn:  tensor(0.0320, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0132, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12361438795719379
mask_update_step
Current compression ratio of attn:  tensor(0.0327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0136, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12507218736703787
mask_update_step
Current compression ratio of attn:  tensor(0.0335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0139, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12652950088660495
mask_update_step
Current compression ratio of attn:  tensor(0.0341, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0143, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12798632285440845
mask_update_step
Current compression ratio of attn:  tensor(0.0347, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0147, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.129442647610872
Search Epoch: [0]  [17709/17710]  eta: 0:00:01  lr: 0.00001000  loss: 17.2608  loss_ita: 4.0778  loss_sp_attn: 6.5240  loss_sp_mlp: 6.6590  time: 1.1491  data: 0.0004  max mem: 65452
Search Epoch: [0] Total time: 5:44:45 (1.1680 s / it)
Averaged stats: lr: 0.0000  loss: 19.0285  loss_ita: 5.6235  loss_sp_attn: 6.6788  loss_sp_mlp: 6.7262
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 70.46, 'txt_r5': 90.22, 'txt_r10': 94.96, 'txt_r_mean': 85.21333333333332, 'img_r1': 57.33706517393043, 'img_r5': 80.91163534586165, 'img_r10': 88.2127149140344, 'img_r_mean': 75.48713847794215, 'r_mean': 80.35023590563773}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.7398
Text_CKA_Similarity: 0.9139
Image_Cosine_Similarity: 0.5999
Image_CKA_Similarity: 0.9656
sim_matrix_pearson_correlation: 0.9727
KD:True
Search Epoch: [1]  [    0/17710]  eta: 7 days, 10:32:04  lr: 0.00001000  loss: 19.6549  loss_ita: 6.4720  loss_sp_attn: 6.5240  loss_sp_mlp: 6.6590  time: 36.2916  data: 0.2217  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.0355, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13089846949835054
mask_update_step
Current compression ratio of attn:  tensor(0.0365, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0153, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13235378286115237
mask_update_step
Current compression ratio of attn:  tensor(0.0374, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0156, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13380858204556192
mask_update_step
Current compression ratio of attn:  tensor(0.0384, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13526286139986077
mask_update_step
Current compression ratio of attn:  tensor(0.0388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13671661527434975
mask_update_step
Current compression ratio of attn:  tensor(0.0401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13816983802137175
mask_update_step
Current compression ratio of attn:  tensor(0.0406, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13962252399533243
mask_update_step
Current compression ratio of attn:  tensor(0.0416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14107466755272308
mask_update_step
Current compression ratio of attn:  tensor(0.0424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1425262630521421
mask_update_step
Current compression ratio of attn:  tensor(0.0435, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0179, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14397730485431703
mask_update_step
Current compression ratio of attn:  tensor(0.0440, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0185, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14542778732212655
mask_update_step
Current compression ratio of attn:  tensor(0.0452, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0187, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14687770482062218
mask_update_step
Current compression ratio of attn:  tensor(0.0461, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14832705171705013
mask_update_step
Current compression ratio of attn:  tensor(0.0467, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0196, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14977582238087378
mask_update_step
Current compression ratio of attn:  tensor(0.0480, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15122401118379467
mask_update_step
Current compression ratio of attn:  tensor(0.0489, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0202, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15267161249977496
mask_update_step
Current compression ratio of attn:  tensor(0.0505, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0201, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15411862070505927
mask_update_step
Current compression ratio of attn:  tensor(0.0512, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15556503017819603
mask_update_step
Current compression ratio of attn:  tensor(0.0520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15701083530006
mask_update_step
Current compression ratio of attn:  tensor(0.0528, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0216, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1584560304538737
mask_update_step
Current compression ratio of attn:  tensor(0.0537, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0220, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1599006100252292
mask_update_step
Current compression ratio of attn:  tensor(0.0551, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0222, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16134456840211003
mask_update_step
Current compression ratio of attn:  tensor(0.0556, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0229, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16278789997491308
mask_update_step
Current compression ratio of attn:  tensor(0.0573, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1642305991364703
mask_update_step
Current compression ratio of attn:  tensor(0.0581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16567266028207048
Search Epoch: [1]  [ 5000/17710]  eta: 4:11:22  lr: 0.00001000  loss: 18.3101  loss_ita: 5.3441  loss_sp_attn: 6.3657  loss_sp_mlp: 6.6003  time: 1.2172  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.0588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16711407780948084
mask_update_step
Current compression ratio of attn:  tensor(0.0604, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1685548461189692
mask_update_step
Current compression ratio of attn:  tensor(0.0618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0243, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16999495961332545
mask_update_step
Current compression ratio of attn:  tensor(0.0625, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0248, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17143441269788331
mask_update_step
Current compression ratio of attn:  tensor(0.0637, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17287319978054227
mask_update_step
Current compression ratio of attn:  tensor(0.0654, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1743113152717889
mask_update_step
Current compression ratio of attn:  tensor(0.0654, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17574875358471886
mask_update_step
Current compression ratio of attn:  tensor(0.0672, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17718550913505893
mask_update_step
Current compression ratio of attn:  tensor(0.0679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0269, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17862157634118786
mask_update_step
Current compression ratio of attn:  tensor(0.0686, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0276, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1800569496241589
mask_update_step
Current compression ratio of attn:  tensor(0.0697, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0281, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1814916234077208
mask_update_step
Current compression ratio of attn:  tensor(0.0716, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0281, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18292559211833997
mask_update_step
Current compression ratio of attn:  tensor(0.0723, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0287, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1843588501852219
mask_update_step
Current compression ratio of attn:  tensor(0.0738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0290, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18579139204033307
mask_update_step
Current compression ratio of attn:  tensor(0.0756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0290, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18722321211842177
mask_update_step
Current compression ratio of attn:  tensor(0.0761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0298, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18865430485704082
mask_update_step
Current compression ratio of attn:  tensor(0.0778, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1900846646965686
mask_update_step
Current compression ratio of attn:  tensor(0.0786, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0306, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19151428608023063
mask_update_step
Current compression ratio of attn:  tensor(0.0793, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0314, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19294316345412116
mask_update_step
Current compression ratio of attn:  tensor(0.0809, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0316, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1943712912672249
mask_update_step
Current compression ratio of attn:  tensor(0.0827, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0317, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19579866397143852
mask_update_step
Current compression ratio of attn:  tensor(0.0835, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0324, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19722527602159226
mask_update_step
Current compression ratio of attn:  tensor(0.0842, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0333, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19865112187547138
mask_update_step
Current compression ratio of attn:  tensor(0.0858, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20007619599383758
mask_update_step
Current compression ratio of attn:  tensor(0.0875, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0337, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20150049284045085
Search Epoch: [1]  [10000/17710]  eta: 2:31:41  lr: 0.00001000  loss: 17.9536  loss_ita: 5.2555  loss_sp_attn: 6.1673  loss_sp_mlp: 6.5308  time: 1.1542  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.0883, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0344, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2029240068820906
mask_update_step
Current compression ratio of attn:  tensor(0.0900, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0346, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2043467325885776
mask_update_step
Current compression ratio of attn:  tensor(0.0904, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0356, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2057686644327949
mask_update_step
Current compression ratio of attn:  tensor(0.0922, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0358, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2071897968907098
mask_update_step
Current compression ratio of attn:  tensor(0.0928, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0367, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20861012444139515
mask_update_step
Current compression ratio of attn:  tensor(0.0941, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0372, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21002964156705062
mask_update_step
Current compression ratio of attn:  tensor(0.0951, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0378, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21144834275302443
mask_update_step
Current compression ratio of attn:  tensor(0.0965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0383, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2128662224878345
mask_update_step
Current compression ratio of attn:  tensor(0.0977, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21428327526319008
mask_update_step
Current compression ratio of attn:  tensor(0.0987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0395, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21569949557401297
mask_update_step
Current compression ratio of attn:  tensor(0.0991, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0406, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21711487791845904
mask_update_step
Current compression ratio of attn:  tensor(0.1016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0404, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21852941679793958
mask_update_step
Current compression ratio of attn:  tensor(0.1026, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0411, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21994310671714273
mask_update_step
Current compression ratio of attn:  tensor(0.1036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0417, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22135594218405447
mask_update_step
Current compression ratio of attn:  tensor(0.1051, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0423, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2227679177099805
mask_update_step
Current compression ratio of attn:  tensor(0.1048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22417902780956706
mask_update_step
Current compression ratio of attn:  tensor(0.1076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0435, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22558926700082263
mask_update_step
Current compression ratio of attn:  tensor(0.1085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0443, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22699862980513913
mask_update_step
Current compression ratio of attn:  tensor(0.1098, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0448, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22840711074731274
mask_update_step
Current compression ratio of attn:  tensor(0.1100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0461, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22981470435556609
mask_update_step
Current compression ratio of attn:  tensor(0.1129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0457, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23122140516156853
mask_update_step
Current compression ratio of attn:  tensor(0.1132, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0469, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2326272077004584
mask_update_step
Current compression ratio of attn:  tensor(0.1146, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23403210651086293
mask_update_step
Current compression ratio of attn:  tensor(0.1162, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0479, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.235436096134921
mask_update_step
Current compression ratio of attn:  tensor(0.1170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0488, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23683917111830297
Search Epoch: [1]  [15000/17710]  eta: 0:53:27  lr: 0.00001000  loss: 18.3532  loss_ita: 5.9575  loss_sp_attn: 5.9673  loss_sp_mlp: 6.4284  time: 1.1314  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.1172, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0502, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2382413260102329
mask_update_step
Current compression ratio of attn:  tensor(0.1191, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0505, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23964255536350898
mask_update_step
Current compression ratio of attn:  tensor(0.1198, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0515, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24104285373452528
mask_update_step
Current compression ratio of attn:  tensor(0.1218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0517, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2424422156832923
mask_update_step
Current compression ratio of attn:  tensor(0.1222, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0529, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24384063577345869
mask_update_step
Current compression ratio of attn:  tensor(0.1239, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0533, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24523810857233214
mask_update_step
Current compression ratio of attn:  tensor(0.1260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0535, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24663462865090013
mask_update_step
Current compression ratio of attn:  tensor(0.1266, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0547, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24803019058385162
mask_update_step
Current compression ratio of attn:  tensor(0.1260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0565, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2494247889495978
mask_update_step
Current compression ratio of attn:  tensor(0.1292, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0561, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2508184183302933
mask_update_step
Current compression ratio of attn:  tensor(0.1298, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0572, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25221107331185677
mask_update_step
Current compression ratio of attn:  tensor(0.1316, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0576, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25360274848399267
mask_update_step
Current compression ratio of attn:  tensor(0.1313, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0592, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25499343844021183
mask_update_step
Current compression ratio of attn:  tensor(0.1337, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2563831377778524
Search Epoch: [1]  [17709/17710]  eta: 0:00:01  lr: 0.00001000  loss: 17.2394  loss_ita: 5.0274  loss_sp_attn: 5.8549  loss_sp_mlp: 6.3570  time: 1.1652  data: 0.0004  max mem: 65452
Search Epoch: [1] Total time: 5:48:50 (1.1819 s / it)
Averaged stats: lr: 0.0000  loss: 18.3977  loss_ita: 5.6547  loss_sp_attn: 6.2092  loss_sp_mlp: 6.5338
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 70.68, 'txt_r5': 90.74, 'txt_r10': 94.88, 'txt_r_mean': 85.43333333333334, 'img_r1': 56.5453818472611, 'img_r5': 80.49580167932827, 'img_r10': 87.73290683726509, 'img_r_mean': 74.92469678795148, 'r_mean': 80.1790150606424}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.7111
Text_CKA_Similarity: 0.9130
Image_Cosine_Similarity: 0.5397
Image_CKA_Similarity: 0.9310
sim_matrix_pearson_correlation: 0.9680
KD:True
Search Epoch: [2]  [    0/17710]  eta: 8 days, 21:17:49  lr: 0.00001000  loss: 18.4154  loss_ita: 6.2035  loss_sp_attn: 5.8549  loss_sp_mlp: 6.3570  time: 43.3579  data: 0.2363  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.1344, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0604, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2577718410981008
mask_update_step
Current compression ratio of attn:  tensor(0.1374, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0602, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2591595430060134
mask_update_step
Current compression ratio of attn:  tensor(0.1375, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0616, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26054623811053645
mask_update_step
Current compression ratio of attn:  tensor(0.1378, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0630, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2619319210245276
mask_update_step
Current compression ratio of attn:  tensor(0.1416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0622, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.263316586364777
mask_update_step
Current compression ratio of attn:  tensor(0.1408, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0644, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2647002287520276
mask_update_step
Current compression ratio of attn:  tensor(0.1434, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0644, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2660828428109967
mask_update_step
Current compression ratio of attn:  tensor(0.1444, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0652, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2674644231703963
mask_update_step
Current compression ratio of attn:  tensor(0.1456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0661, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26884496446295425
mask_update_step
Current compression ratio of attn:  tensor(0.1465, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0672, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27022446132543515
mask_update_step
Current compression ratio of attn:  tensor(0.1479, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27160290839866097
mask_update_step
Current compression ratio of attn:  tensor(0.1475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0697, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.272980300327532
mask_update_step
Current compression ratio of attn:  tensor(0.1492, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0702, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27435663176104774
mask_update_step
Current compression ratio of attn:  tensor(0.1525, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0699, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2757318973523275
mask_update_step
Current compression ratio of attn:  tensor(0.1514, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0722, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27710609175863127
mask_update_step
Current compression ratio of attn:  tensor(0.1545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0719, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27847920964138045
mask_update_step
Current compression ratio of attn:  tensor(0.1545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0736, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2798512456661786
mask_update_step
Current compression ratio of attn:  tensor(0.1580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0730, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28122219450283226
mask_update_step
Current compression ratio of attn:  tensor(0.1567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0755, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2825920508253715
mask_update_step
Current compression ratio of attn:  tensor(0.1566, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0772, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2839608093120706
mask_update_step
Current compression ratio of attn:  tensor(0.1597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0770, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28532846464546874
mask_update_step
Current compression ratio of attn:  tensor(0.1603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0783, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.286695011512391
mask_update_step
Current compression ratio of attn:  tensor(0.1634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0781, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2880604446039686
mask_update_step
Current compression ratio of attn:  tensor(0.1633, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2894247586156596
mask_update_step
Current compression ratio of attn:  tensor(0.1642, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0810, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29078794824726933
Search Epoch: [2]  [ 5000/17710]  eta: 4:06:23  lr: 0.00001000  loss: 18.5766  loss_ita: 6.7172  loss_sp_attn: 5.6484  loss_sp_mlp: 6.2110  time: 1.1907  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.1648, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0823, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29215000820297166
mask_update_step
Current compression ratio of attn:  tensor(0.1670, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0828, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29351093319132876
mask_update_step
Current compression ratio of attn:  tensor(0.1674, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0842, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2948707179253122
mask_update_step
Current compression ratio of attn:  tensor(0.1695, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29622935712232323
mask_update_step
Current compression ratio of attn:  tensor(0.1727, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0843, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2975868455042132
mask_update_step
Current compression ratio of attn:  tensor(0.1720, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0866, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29894317779730456
mask_update_step
Current compression ratio of attn:  tensor(0.1738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30029834873241085
mask_update_step
Current compression ratio of attn:  tensor(0.1740, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3016523530448573
mask_update_step
Current compression ratio of attn:  tensor(0.1768, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0890, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30300518547450156
mask_update_step
Current compression ratio of attn:  tensor(0.1760, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0912, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30435684076575353
mask_update_step
Current compression ratio of attn:  tensor(0.1773, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0922, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3057073136675964
mask_update_step
Current compression ratio of attn:  tensor(0.1775, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3070565989336068
mask_update_step
Current compression ratio of attn:  tensor(0.1785, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0950, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30840469132197523
mask_update_step
Current compression ratio of attn:  tensor(0.1782, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0970, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30975158559552607
mask_update_step
Current compression ratio of attn:  tensor(0.1804, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31109727652173863
mask_update_step
Current compression ratio of attn:  tensor(0.1830, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0975, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3124417588727667
mask_update_step
Current compression ratio of attn:  tensor(0.1816, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3137850274254596
mask_update_step
Current compression ratio of attn:  tensor(0.1875, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0985, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31512707696138187
mask_update_step
Current compression ratio of attn:  tensor(0.1791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1054, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31646790226683386
mask_update_step
Current compression ratio of attn:  tensor(0.1861, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31780749813287174
mask_update_step
Current compression ratio of attn:  tensor(0.1858, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1050, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3191458593553283
mask_update_step
Current compression ratio of attn:  tensor(0.1857, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3204829807348325
mask_update_step
Current compression ratio of attn:  tensor(0.1887, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3218188570768298
mask_update_step
Current compression ratio of attn:  tensor(0.1924, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32315348319160275
mask_update_step
Current compression ratio of attn:  tensor(0.1902, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32448685389429077
Search Epoch: [2]  [10000/17710]  eta: 2:29:37  lr: 0.00001000  loss: 17.4247  loss_ita: 5.9348  loss_sp_attn: 5.4728  loss_sp_mlp: 6.0171  time: 1.1764  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.1929, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3258189640049105
mask_update_step
Current compression ratio of attn:  tensor(0.1916, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1125, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3271498083483756
mask_update_step
Current compression ratio of attn:  tensor(0.1947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32847938175451724
mask_update_step
Current compression ratio of attn:  tensor(0.1939, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1149, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3298076790581041
mask_update_step
Current compression ratio of attn:  tensor(0.1981, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3311346950988622
mask_update_step
Current compression ratio of attn:  tensor(0.1978, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1163, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3324604247214952
mask_update_step
Current compression ratio of attn:  tensor(0.2005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3337848627757043
mask_update_step
Current compression ratio of attn:  tensor(0.2003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1186, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33510800411620834
mask_update_step
Current compression ratio of attn:  tensor(0.1998, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1208, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33642984360276373
mask_update_step
Current compression ratio of attn:  tensor(0.2009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1220, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3377503761001843
mask_update_step
Current compression ratio of attn:  tensor(0.2043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33906959647836166
mask_update_step
Current compression ratio of attn:  tensor(0.2025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3403874996122844
mask_update_step
Current compression ratio of attn:  tensor(0.2074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1238, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34170408038205896
mask_update_step
Current compression ratio of attn:  tensor(0.2072, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3430193336729286
mask_update_step
Current compression ratio of attn:  tensor(0.2076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1274, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3443332543752938
mask_update_step
Current compression ratio of attn:  tensor(0.2038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1316, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.345645837384732
mask_update_step
Current compression ratio of attn:  tensor(0.2086, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1307, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34695707760201755
mask_update_step
Current compression ratio of attn:  tensor(0.2092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1323, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34826696993314116
mask_update_step
Current compression ratio of attn:  tensor(0.2130, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1319, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34957550928933
mask_update_step
Current compression ratio of attn:  tensor(0.2138, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1334, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3508826905870675
mask_update_step
Current compression ratio of attn:  tensor(0.2134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1356, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3521885087481127
mask_update_step
Current compression ratio of attn:  tensor(0.2166, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1357, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35349295869952047
mask_update_step
Current compression ratio of attn:  tensor(0.2178, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1367, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35479603537366117
mask_update_step
Current compression ratio of attn:  tensor(0.2172, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1392, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3560977337082397
mask_update_step
Current compression ratio of attn:  tensor(0.2184, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1404, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3573980486463161
Search Epoch: [2]  [15000/17710]  eta: 0:52:28  lr: 0.00001000  loss: 18.0992  loss_ita: 7.0075  loss_sp_attn: 5.2823  loss_sp_mlp: 5.8095  time: 1.1880  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.2221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35869697513632454
mask_update_step
Current compression ratio of attn:  tensor(0.2252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1402, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3599945081320931
mask_update_step
Current compression ratio of attn:  tensor(0.2202, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3612906425928636
mask_update_step
Current compression ratio of attn:  tensor(0.2308, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1408, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3625853734833107
mask_update_step
Current compression ratio of attn:  tensor(0.2255, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1461, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3638786957735621
mask_update_step
Current compression ratio of attn:  tensor(0.2320, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1441, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3651706044392174
mask_update_step
Current compression ratio of attn:  tensor(0.2305, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3664610944613683
mask_update_step
Current compression ratio of attn:  tensor(0.2335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1473, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3677501608266175
mask_update_step
Current compression ratio of attn:  tensor(0.2279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1528, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3690377985270986
mask_update_step
Current compression ratio of attn:  tensor(0.2332, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1516, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3703240025604953
mask_update_step
Current compression ratio of attn:  tensor(0.2357, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1521, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3716087679300609
mask_update_step
Current compression ratio of attn:  tensor(0.2397, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1516, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37289208964463794
mask_update_step
Current compression ratio of attn:  tensor(0.2367, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1556, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37417396271867687
Search Epoch: [2]  [17709/17710]  eta: 0:00:01  lr: 0.00001000  loss: 17.8172  loss_ita: 6.9515  loss_sp_attn: 5.1589  loss_sp_mlp: 5.7068  time: 1.1977  data: 0.0005  max mem: 65452
Search Epoch: [2] Total time: 5:42:52 (1.1616 s / it)
Averaged stats: lr: 0.0000  loss: 17.9917  loss_ita: 6.4246  loss_sp_attn: 5.5085  loss_sp_mlp: 6.0586
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 66.04, 'txt_r5': 88.98, 'txt_r10': 94.42, 'txt_r_mean': 83.14666666666666, 'img_r1': 53.93042782886845, 'img_r5': 79.07636945221911, 'img_r10': 86.86125549780088, 'img_r_mean': 73.28935092629615, 'r_mean': 78.2180087964814}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.5186
Text_CKA_Similarity: 0.8966
Image_Cosine_Similarity: 0.3750
Image_CKA_Similarity: 0.8332
sim_matrix_pearson_correlation: 0.9597
KD:True
Search Epoch: [3]  [    0/17710]  eta: 8 days, 19:23:57  lr: 0.00001000  loss: 17.8850  loss_ita: 7.0192  loss_sp_attn: 5.1589  loss_sp_mlp: 5.7068  time: 42.9722  data: 0.2474  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.2388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1562, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3754543821722566
mask_update_step
Current compression ratio of attn:  tensor(0.2416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3767333430311026
mask_update_step
Current compression ratio of attn:  tensor(0.2444, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37801084032660753
mask_update_step
Current compression ratio of attn:  tensor(0.2421, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1605, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37928686909584886
mask_update_step
Current compression ratio of attn:  tensor(0.2456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1605, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3805614243816098
mask_update_step
Current compression ratio of attn:  tensor(0.2477, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1613, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3818345012323977
mask_update_step
Current compression ratio of attn:  tensor(0.2527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3831060947024633
mask_update_step
Current compression ratio of attn:  tensor(0.2518, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1629, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38437619985182037
mask_update_step
Current compression ratio of attn:  tensor(0.2522, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1648, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3856448117462642
mask_update_step
Current compression ratio of attn:  tensor(0.2575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1636, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3869119254573918
mask_update_step
Current compression ratio of attn:  tensor(0.2520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1691, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38817753606261984
mask_update_step
Current compression ratio of attn:  tensor(0.2549, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1695, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38944163864520476
mask_update_step
Current compression ratio of attn:  tensor(0.2535, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1725, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39070422829426116
mask_update_step
Current compression ratio of attn:  tensor(0.2595, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1709, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39196530010478176
mask_update_step
Current compression ratio of attn:  tensor(0.2615, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1717, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3932248491776553
mask_update_step
Current compression ratio of attn:  tensor(0.2634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1727, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39448287061968634
mask_update_step
Current compression ratio of attn:  tensor(0.2611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1763, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3957393595436144
mask_update_step
Current compression ratio of attn:  tensor(0.2651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1760, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3969943110681321
mask_update_step
Current compression ratio of attn:  tensor(0.2660, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1775, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39824772031790534
mask_update_step
Current compression ratio of attn:  tensor(0.2703, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1771, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.399499582423591
mask_update_step
Current compression ratio of attn:  tensor(0.2695, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1797, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4007498925218568
mask_update_step
Current compression ratio of attn:  tensor(0.2710, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1809, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4019986457553994
mask_update_step
Current compression ratio of attn:  tensor(0.2707, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1833, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40324583727296426
mask_update_step
Current compression ratio of attn:  tensor(0.2732, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1840, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40449146222936344
mask_update_step
Current compression ratio of attn:  tensor(0.2752, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1849, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40573551578549516
Search Epoch: [3]  [ 5000/17710]  eta: 4:08:28  lr: 0.00001000  loss: 17.4963  loss_ita: 7.0888  loss_sp_attn: 4.8986  loss_sp_mlp: 5.5089  time: 1.0192  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.2730, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1884, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40697799310836213
mask_update_step
Current compression ratio of attn:  tensor(0.2769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1882, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40821888937109074
mask_update_step
Current compression ratio of attn:  tensor(0.2756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1912, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4094581997529496
mask_update_step
Current compression ratio of attn:  tensor(0.2793, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1910, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.410695919439368
mask_update_step
Current compression ratio of attn:  tensor(0.2777, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1942, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41193204362195535
mask_update_step
Current compression ratio of attn:  tensor(0.2812, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1943, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4131665674985189
mask_update_step
Current compression ratio of attn:  tensor(0.2815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1963, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4143994862730832
mask_update_step
Current compression ratio of attn:  tensor(0.2855, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1960, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4156307951559085
mask_update_step
Current compression ratio of attn:  tensor(0.2835, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1993, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.416860489363509
mask_update_step
Current compression ratio of attn:  tensor(0.2913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1969, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41808856411867185
mask_update_step
Current compression ratio of attn:  tensor(0.2871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4193150146504756
mask_update_step
Current compression ratio of attn:  tensor(0.2894, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4205398361943088
mask_update_step
Current compression ratio of attn:  tensor(0.2892, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4217630239918883
mask_update_step
Current compression ratio of attn:  tensor(0.2881, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42298457329127775
mask_update_step
Current compression ratio of attn:  tensor(0.2929, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4242044793469063
mask_update_step
Current compression ratio of attn:  tensor(0.2962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2072, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.425422737419587
mask_update_step
Current compression ratio of attn:  tensor(0.2948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42663934277653504
mask_update_step
Current compression ratio of attn:  tensor(0.3018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2081, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42785429069138603
mask_update_step
Current compression ratio of attn:  tensor(0.2987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4290675764442148
mask_update_step
Current compression ratio of attn:  tensor(0.3005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43027919532155323
mask_update_step
Current compression ratio of attn:  tensor(0.3041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43148914261640914
mask_update_step
Current compression ratio of attn:  tensor(0.3030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43269741362828396
mask_update_step
Current compression ratio of attn:  tensor(0.3063, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4339040036631913
mask_update_step
Current compression ratio of attn:  tensor(0.3052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2196, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4351089080336753
mask_update_step
Current compression ratio of attn:  tensor(0.3083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2199, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43631212205882863
Search Epoch: [3]  [10000/17710]  eta: 2:30:13  lr: 0.00001000  loss: 17.6807  loss_ita: 7.7333  loss_sp_attn: 4.6748  loss_sp_mlp: 5.2726  time: 1.1452  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.3059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2237, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4375136410643108
mask_update_step
Current compression ratio of attn:  tensor(0.3120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2222, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43871346038236614
mask_update_step
Current compression ratio of attn:  tensor(0.3149, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2226, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43991157535184205
mask_update_step
Current compression ratio of attn:  tensor(0.3114, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4411079813182074
mask_update_step
Current compression ratio of attn:  tensor(0.3105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2297, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44230267363357
mask_update_step
Current compression ratio of attn:  tensor(0.3090, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2331, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44349564765669514
mask_update_step
Current compression ratio of attn:  tensor(0.3142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2321, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4446868987530235
mask_update_step
Current compression ratio of attn:  tensor(0.3179, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2322, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4458764222946888
mask_update_step
Current compression ratio of attn:  tensor(0.3143, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2366, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44706421366053684
mask_update_step
Current compression ratio of attn:  tensor(0.3219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4482502682361418
mask_update_step
Current compression ratio of attn:  tensor(0.3191, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2382, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4494345814138258
mask_update_step
Current compression ratio of attn:  tensor(0.3161, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45061714859267554
mask_update_step
Current compression ratio of attn:  tensor(0.3195, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2426, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4517979651785613
mask_update_step
Current compression ratio of attn:  tensor(0.3201, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2446, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45297702658415356
mask_update_step
Current compression ratio of attn:  tensor(0.3291, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2414, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45415432822894203
mask_update_step
Current compression ratio of attn:  tensor(0.3223, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2478, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4553298655392525
mask_update_step
Current compression ratio of attn:  tensor(0.3265, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4565036339482649
mask_update_step
Current compression ratio of attn:  tensor(0.3271, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4576756288960318
mask_update_step
Current compression ratio of attn:  tensor(0.3293, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4588458458294946
mask_update_step
Current compression ratio of attn:  tensor(0.3277, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2537, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4600142802025026
mask_update_step
Current compression ratio of attn:  tensor(0.3301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46118092747582995
mask_update_step
Current compression ratio of attn:  tensor(0.3390, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2514, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4623457831171936
mask_update_step
Current compression ratio of attn:  tensor(0.3369, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2549, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46350884260127045
mask_update_step
Current compression ratio of attn:  tensor(0.3399, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2552, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46467010140971576
mask_update_step
Current compression ratio of attn:  tensor(0.3413, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2568, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46582955503117984
Search Epoch: [3]  [15000/17710]  eta: 0:52:44  lr: 0.00001000  loss: 17.3586  loss_ita: 7.8838  loss_sp_attn: 4.4519  loss_sp_mlp: 5.0230  time: 1.1267  data: 0.0001  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.3411, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2592, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4669871989613258
mask_update_step
Current compression ratio of attn:  tensor(0.3408, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2616, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4681430287028477
mask_update_step
Current compression ratio of attn:  tensor(0.3457, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2609, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46929703976548687
mask_update_step
Current compression ratio of attn:  tensor(0.3417, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2658, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4704492276660506
mask_update_step
Current compression ratio of attn:  tensor(0.3463, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2652, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4715995879284284
mask_update_step
Current compression ratio of attn:  tensor(0.3414, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2707, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47274811608361045
mask_update_step
Current compression ratio of attn:  tensor(0.3527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2660, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4738948076697039
mask_update_step
Current compression ratio of attn:  tensor(0.3500, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2701, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47503965823195127
mask_update_step
Current compression ratio of attn:  tensor(0.3508, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2718, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47618266332274684
mask_update_step
Current compression ratio of attn:  tensor(0.3486, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2755, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47732381850165456
mask_update_step
Current compression ratio of attn:  tensor(0.3561, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47846311933542485
mask_update_step
Current compression ratio of attn:  tensor(0.3475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2809, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4796005613980124
mask_update_step
Current compression ratio of attn:  tensor(0.3533, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2797, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4807361402705925
mask_update_step
Current compression ratio of attn:  tensor(0.3542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2816, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48186985154157913
Search Epoch: [3]  [17709/17710]  eta: 0:00:01  lr: 0.00001000  loss: 17.3007  loss_ita: 8.0804  loss_sp_attn: 4.3649  loss_sp_mlp: 4.8554  time: 1.1985  data: 0.0004  max mem: 65452
Search Epoch: [3] Total time: 5:44:47 (1.1681 s / it)
Averaged stats: lr: 0.0000  loss: 17.5177  loss_ita: 7.4674  loss_sp_attn: 4.7406  loss_sp_mlp: 5.3097
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 58.78, 'txt_r5': 85.68, 'txt_r10': 92.5, 'txt_r_mean': 78.98666666666666, 'img_r1': 49.90803678528589, 'img_r5': 76.74930027988805, 'img_r10': 85.08196721311475, 'img_r_mean': 70.57976809276289, 'r_mean': 74.78321737971478}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.3113
Text_CKA_Similarity: 0.7727
Image_Cosine_Similarity: 0.2481
Image_CKA_Similarity: 0.7635
sim_matrix_pearson_correlation: 0.9434
KD:True
Search Epoch: [4]  [    0/17710]  eta: 7 days, 22:54:55  lr: 0.00001000  loss: 17.3625  loss_ita: 8.1422  loss_sp_attn: 4.3649  loss_sp_mlp: 4.8554  time: 38.8083  data: 0.2440  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.3581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48300169080664157
mask_update_step
Current compression ratio of attn:  tensor(0.3614, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2818, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48413165366872135
mask_update_step
Current compression ratio of attn:  tensor(0.3606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4852597357380499
mask_update_step
Current compression ratio of attn:  tensor(0.3687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2820, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48638593263216534
mask_update_step
Current compression ratio of attn:  tensor(0.3614, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4875102399759293
mask_update_step
Current compression ratio of attn:  tensor(0.3673, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2876, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48863265340154394
mask_update_step
Current compression ratio of attn:  tensor(0.3622, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2931, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4897531685485694
mask_update_step
Current compression ratio of attn:  tensor(0.3687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2915, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4908717810639402
mask_update_step
Current compression ratio of attn:  tensor(0.3664, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49198848660198236
mask_update_step
Current compression ratio of attn:  tensor(0.3713, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2946, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4931032808244306
mask_update_step
Current compression ratio of attn:  tensor(0.3678, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2991, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49421615940044417
mask_update_step
Current compression ratio of attn:  tensor(0.3709, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2996, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4953271180066251
mask_update_step
Current compression ratio of attn:  tensor(0.3743, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2997, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49643615232703375
mask_update_step
Current compression ratio of attn:  tensor(0.3786, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2992, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4975432580532065
mask_update_step
Current compression ratio of attn:  tensor(0.3743, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49864843088417166
mask_update_step
Current compression ratio of attn:  tensor(0.3783, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4997516665264671
mask_update_step
Current compression ratio of attn:  tensor(0.3745, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.500852960694156
mask_update_step
Current compression ratio of attn:  tensor(0.3768, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3102, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5019523091088441
mask_update_step
Current compression ratio of attn:  tensor(0.3741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5030497074996962
mask_update_step
Current compression ratio of attn:  tensor(0.3816, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3118, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5041451516034526
mask_update_step
Current compression ratio of attn:  tensor(0.3789, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.505238637164446
mask_update_step
Current compression ratio of attn:  tensor(0.3847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3148, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5063301599346175
mask_update_step
Current compression ratio of attn:  tensor(0.3809, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3195, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5074197156735335
mask_update_step
Current compression ratio of attn:  tensor(0.3855, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5085073001484022
mask_update_step
Current compression ratio of attn:  tensor(0.3781, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3260, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5095929091340897
Search Epoch: [4]  [ 5000/17710]  eta: 4:07:10  lr: 0.00001000  loss: 17.3871  loss_ita: 8.6285  loss_sp_attn: 4.2033  loss_sp_mlp: 4.5553  time: 1.1972  data: 0.0002  max mem: 65452
mask_update_step
Current compression ratio of attn:  tensor(0.3907, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.510676538413137
mask_update_step
Current compression ratio of attn:  tensor(0.3853, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5117581837757756
mask_update_step
Current compression ratio of attn:  tensor(0.3971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3214, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5128378410199446
mask_update_step
Current compression ratio of attn:  tensor(0.3872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3299, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5139155059513064
mask_update_step
Current compression ratio of attn:  tensor(0.3925, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3290, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5149911743832636
mask_update_step
Current compression ratio of attn:  tensor(0.3984, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3278, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5160648421369747
mask_update_step
Current compression ratio of attn:  tensor(0.3938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3330, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5171365050413709
mask_update_step
Current compression ratio of attn:  tensor(0.3986, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5182061589331715
mask_update_step
Current compression ratio of attn:  tensor(0.3985, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3349, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5192737996569011
mask_update_step
Current compression ratio of attn:  tensor(0.4011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3357, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.520339423064905
mask_update_step
Current compression ratio of attn:  tensor(0.3986, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3394, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5214030250173655
mask_update_step
Current compression ratio of attn:  tensor(0.4024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3393, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.522464601382318
mask_update_step
Current compression ratio of attn:  tensor(0.4042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3409, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5235241480356669
mask_update_step
Current compression ratio of attn:  tensor(0.3989, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3464, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5245816608612023
mask_update_step
Current compression ratio of attn:  tensor(0.4079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5256371357506149
mask_update_step
Current compression ratio of attn:  tensor(0.4048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3477, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5266905686035129
mask_update_step
Current compression ratio of attn:  tensor(0.4071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3486, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5277419553274374
mask_update_step
Current compression ratio of attn:  tensor(0.4082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5287912918378785
mask_update_step
Current compression ratio of attn:  tensor(0.4090, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3522, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5298385740582914
mask_update_step
Current compression ratio of attn:  tensor(0.4105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3536, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5308837979201112
mask_update_step
Current compression ratio of attn:  tensor(0.4110, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5319269593627701
mask_update_step
Current compression ratio of attn:  tensor(0.4167, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5329680543337129
mask_update_step
Current compression ratio of attn:  tensor(0.4169, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3569, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5340070787884115
mask_update_step
Current compression ratio of attn:  tensor(0.4199, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5350440286903819
mask_update_step
Current compression ratio of attn:  tensor(0.4163, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3621, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5360789000111996
Search Epoch: [4]  [10000/17710]  eta: 2:29:13  lr: 0.00001000  loss: 16.9318  loss_ita: 8.6757  loss_sp_attn: 3.9447  loss_sp_mlp: 4.3115  time: 1.1146  data: 0.0001  max mem: 65455
mask_update_step
Current compression ratio of attn:  tensor(0.4209, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3617, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5371116887305152
mask_update_step
Current compression ratio of attn:  tensor(0.4210, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3639, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5381423908360696
mask_update_step
Current compression ratio of attn:  tensor(0.4169, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3688, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5391710023237102
mask_update_step
Current compression ratio of attn:  tensor(0.4217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3683, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.540197519197406
mask_update_step
Current compression ratio of attn:  tensor(0.4222, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3704, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5412219374692637
mask_update_step
Current compression ratio of attn:  tensor(0.4249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3711, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5422442531595426
mask_update_step
Current compression ratio of attn:  tensor(0.4263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3726, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5432644622966699
mask_update_step
Current compression ratio of attn:  tensor(0.4284, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3737, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5442825609172572
mask_update_step
Current compression ratio of attn:  tensor(0.4276, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3765, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5452985450661147
mask_update_step
Current compression ratio of attn:  tensor(0.4284, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3783, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5463124107962671
mask_update_step
Current compression ratio of attn:  tensor(0.4263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3821, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5473241541689694
mask_update_step
Current compression ratio of attn:  tensor(0.4312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5483337712537208
mask_update_step
Current compression ratio of attn:  tensor(0.4384, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3795, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5493412581282818
mask_update_step
Current compression ratio of attn:  tensor(0.4366, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3829, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5503466108786879
mask_update_step
Current compression ratio of attn:  tensor(0.4301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5513498255992657
mask_update_step
Current compression ratio of attn:  tensor(0.4462, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3817, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5523508983926476
mask_update_step
Current compression ratio of attn:  tensor(0.4361, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3904, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5533498253697874
mask_update_step
Current compression ratio of attn:  tensor(0.4424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5543466026499748
mask_update_step
Current compression ratio of attn:  tensor(0.4441, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3901, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5553412263608508
mask_update_step
Current compression ratio of attn:  tensor(0.4472, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3907, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5563336926384235
mask_update_step
Current compression ratio of attn:  tensor(0.4415, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5573239976270811
mask_update_step
Current compression ratio of attn:  tensor(0.4462, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3960, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5583121374796094
mask_update_step
Current compression ratio of attn:  tensor(0.4460, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3984, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5592981083572045
mask_update_step
Current compression ratio of attn:  tensor(0.4445, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5602819064294895
mask_update_step
Current compression ratio of attn:  tensor(0.4453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4037, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5612635278745279
Search Epoch: [4]  [15000/17710]  eta: 0:52:31  lr: 0.00001000  loss: 16.3583  loss_ita: 8.5794  loss_sp_attn: 3.7488  loss_sp_mlp: 4.0301  time: 1.0786  data: 0.0001  max mem: 65455
mask_update_step
Current compression ratio of attn:  tensor(0.4532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5622429688788397
mask_update_step
Current compression ratio of attn:  tensor(0.4504, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5632202256374154
mask_update_step
Current compression ratio of attn:  tensor(0.4555, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4045, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.564195294353731
mask_update_step
Current compression ratio of attn:  tensor(0.4491, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5651681712397625
mask_update_step
Current compression ratio of attn:  tensor(0.4603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5661388525160016
mask_update_step
Current compression ratio of attn:  tensor(0.4545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4122, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5671073344114691
mask_update_step
Current compression ratio of attn:  tensor(0.4609, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4107, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5680736131637303
mask_update_step
Current compression ratio of attn:  tensor(0.4646, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4107, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5690376850189096
mask_update_step
Current compression ratio of attn:  tensor(0.4611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5699995462317045
mask_update_step
Current compression ratio of attn:  tensor(0.4649, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4153, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5709591930654012
mask_update_step
Current compression ratio of attn:  tensor(0.4716, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5719166217918881
mask_update_step
Current compression ratio of attn:  tensor(0.4668, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4188, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5728718286916703
mask_update_step
Current compression ratio of attn:  tensor(0.4679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4204, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5738248100538854
Search Epoch: [4]  [17709/17710]  eta: 0:00:01  lr: 0.00001000  loss: 16.2482  loss_ita: 8.7346  loss_sp_attn: 3.5962  loss_sp_mlp: 3.9174  time: 1.2004  data: 0.0005  max mem: 65455
Search Epoch: [4] Total time: 5:44:06 (1.1658 s / it)
Averaged stats: lr: 0.0000  loss: 16.7570  loss_ita: 8.3889  loss_sp_attn: 3.9827  loss_sp_mlp: 4.3855
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 50.58, 'txt_r5': 81.8, 'txt_r10': 90.0, 'txt_r_mean': 74.12666666666667, 'img_r1': 47.74890043982407, 'img_r5': 75.4938024790084, 'img_r10': 84.34626149540183, 'img_r_mean': 69.19632147141142, 'r_mean': 71.66149406903904}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0970
Text_CKA_Similarity: 0.7522
Image_Cosine_Similarity: 0.1314
Image_CKA_Similarity: 0.7221
sim_matrix_pearson_correlation: 0.9348
KD:True
Search Epoch: [5]  [    0/17710]  eta: 8 days, 22:46:40  lr: 0.00001000  loss: 16.2999  loss_ita: 8.7863  loss_sp_attn: 3.5962  loss_sp_mlp: 3.9174  time: 43.6590  data: 0.2247  max mem: 65455
mask_update_step
Current compression ratio of attn:  tensor(0.4677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4229, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5747755621763161
mask_update_step
Current compression ratio of attn:  tensor(0.4634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5757240813654059
mask_update_step
Current compression ratio of attn:  tensor(0.4756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5766703639362726
mask_update_step
Current compression ratio of attn:  tensor(0.4696, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4288, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5776144062127233
mask_update_step
Current compression ratio of attn:  tensor(0.4718, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4298, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5785562045272683
mask_update_step
Current compression ratio of attn:  tensor(0.4641, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4367, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5794957552211354
mask_update_step
Current compression ratio of attn:  tensor(0.4743, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4330, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5804330546442841
mask_update_step
Current compression ratio of attn:  tensor(0.4703, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5813680991554198
mask_update_step
Current compression ratio of attn:  tensor(0.4853, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4309, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5823008851220078
mask_update_step
Current compression ratio of attn:  tensor(0.4756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4392, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5832314089202881
mask_update_step
Current compression ratio of attn:  tensor(0.4861, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4350, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5841596669352884
mask_update_step
Current compression ratio of attn:  tensor(0.4791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.585085655560839
mask_update_step
Current compression ratio of attn:  tensor(0.4843, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4407, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5860093711995864
mask_update_step
Current compression ratio of attn:  tensor(0.4840, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5869308102630073
mask_update_step
Current compression ratio of attn:  tensor(0.4861, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4443, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5878499691714228
mask_update_step
Current compression ratio of attn:  tensor(0.4893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4447, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5887668443540122
mask_update_step
Current compression ratio of attn:  tensor(0.4928, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5896814322488262
mask_update_step
Current compression ratio of attn:  tensor(0.4956, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4455, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5905937293028021
mask_update_step
Current compression ratio of attn:  tensor(0.4953, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4480, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5915037319717762
mask_update_step
Current compression ratio of attn:  tensor(0.4858, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4561, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.592411436720499
mask_update_step
Current compression ratio of attn:  tensor(0.4972, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4513, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5933168400226473
mask_update_step
Current compression ratio of attn:  tensor(0.4986, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4528, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5942199383608391
mask_update_step
Current compression ratio of attn:  tensor(0.5035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.595120728226647
mask_update_step
Current compression ratio of attn:  tensor(0.5022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4553, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5960192061206115
mask_update_step
Current compression ratio of attn:  tensor(0.5043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4562, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5969153685522551
Search Epoch: [5]  [ 5000/17710]  eta: 4:04:20  lr: 0.00001000  loss: 16.3905  loss_ita: 9.3652  loss_sp_attn: 3.3499  loss_sp_mlp: 3.6754  time: 1.0196  data: 0.0001  max mem: 65455
mask_update_step
Current compression ratio of attn:  tensor(0.5051, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5978092120400954
mask_update_step
Current compression ratio of attn:  tensor(0.5097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.598700733111659
mask_update_step
Current compression ratio of attn:  tensor(0.5104, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5995899283034943
mask_update_step
Current compression ratio of attn:  tensor(0.5077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6004767941611864
mask_update_step
Current compression ratio of attn:  tensor(0.5126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6013613272393684
mask_update_step
Current compression ratio of attn:  tensor(0.5176, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6022435241017371
mask_update_step
Current compression ratio of attn:  tensor(0.5145, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4660, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6031233813210644
mask_update_step
Current compression ratio of attn:  tensor(0.5173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4666, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6040008954792118
mask_update_step
Current compression ratio of attn:  tensor(0.5167, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4693, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6048760631671433
mask_update_step
Current compression ratio of attn:  tensor(0.5100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6057488809849385
mask_update_step
Current compression ratio of attn:  tensor(0.5269, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4675, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.606619345541806
mask_update_step
Current compression ratio of attn:  tensor(0.5242, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4715, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6074874534560968
mask_update_step
Current compression ratio of attn:  tensor(0.5225, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4748, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6083532013553167
mask_update_step
Current compression ratio of attn:  tensor(0.5267, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4743, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6092165858761402
mask_update_step
Current compression ratio of attn:  tensor(0.5345, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4719, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6100776036644233
mask_update_step
Current compression ratio of attn:  tensor(0.5264, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6109362513752161
mask_update_step
Current compression ratio of attn:  tensor(0.5318, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4780, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6117925256727768
mask_update_step
Current compression ratio of attn:  tensor(0.5293, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4819, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.612646423230583
mask_update_step
Current compression ratio of attn:  tensor(0.5418, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4765, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6134979407313469
mask_update_step
Current compression ratio of attn:  tensor(0.5326, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4842, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6143470748670257
mask_update_step
Current compression ratio of attn:  tensor(0.5387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4826, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6151938223388368
mask_update_step
Current compression ratio of attn:  tensor(0.5344, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4876, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6160381798572687
mask_update_step
Current compression ratio of attn:  tensor(0.5433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4844, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6168801441420948
mask_update_step
Current compression ratio of attn:  tensor(0.5416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6177197119223861
mask_update_step
Current compression ratio of attn:  tensor(0.5330, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6185568799365238
Search Epoch: [5]  [10000/17710]  eta: 2:28:38  lr: 0.00001000  loss: 16.5839  loss_ita: 10.0164  loss_sp_attn: 3.1561  loss_sp_mlp: 3.4113  time: 1.1728  data: 0.0002  max mem: 65456
mask_update_step
Current compression ratio of attn:  tensor(0.5506, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4865, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6193916449322113
mask_update_step
Current compression ratio of attn:  tensor(0.5481, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4904, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6202240036664882
mask_update_step
Current compression ratio of attn:  tensor(0.5488, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4922, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6210539529057415
mask_update_step
Current compression ratio of attn:  tensor(0.5510, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4929, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6218814894257193
mask_update_step
Current compression ratio of attn:  tensor(0.5517, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6227066100115426
mask_update_step
Current compression ratio of attn:  tensor(0.5571, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4936, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6235293114577178
mask_update_step
Current compression ratio of attn:  tensor(0.5582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4951, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6243495905681496
mask_update_step
Current compression ratio of attn:  tensor(0.5539, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6251674441561534
mask_update_step
Current compression ratio of attn:  tensor(0.5619, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4973, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6259828690444671
mask_update_step
Current compression ratio of attn:  tensor(0.5564, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6267958620652637
mask_update_step
Current compression ratio of attn:  tensor(0.5648, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4999, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6276064200601641
mask_update_step
Current compression ratio of attn:  tensor(0.5630, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.628414539880249
mask_update_step
Current compression ratio of attn:  tensor(0.5655, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6292202183860706
mask_update_step
Current compression ratio of attn:  tensor(0.5651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5063, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6300234524476657
mask_update_step
Current compression ratio of attn:  tensor(0.5713, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6308242389445675
mask_update_step
Current compression ratio of attn:  tensor(0.5688, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6316225747658175
mask_update_step
Current compression ratio of attn:  tensor(0.5764, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6324184568099781
mask_update_step
Current compression ratio of attn:  tensor(0.5735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6332118819851438
mask_update_step
Current compression ratio of attn:  tensor(0.5790, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6340028472089543
mask_update_step
Current compression ratio of attn:  tensor(0.5779, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5115, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6347913494086053
mask_update_step
Current compression ratio of attn:  tensor(0.5804, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6355773855208615
mask_update_step
Current compression ratio of attn:  tensor(0.5815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6363609524920684
mask_update_step
Current compression ratio of attn:  tensor(0.5774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5180, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6371420472781627
mask_update_step
Current compression ratio of attn:  tensor(0.5877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6379206668446862
mask_update_step
Current compression ratio of attn:  tensor(0.5888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5154, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6386968081667963
Search Epoch: [5]  [15000/17710]  eta: 0:52:20  lr: 0.00001000  loss: 16.1348  loss_ita: 10.0807  loss_sp_attn: 2.7791  loss_sp_mlp: 3.2750  time: 1.1513  data: 0.0002  max mem: 65456
mask_update_step
Current compression ratio of attn:  tensor(0.5877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6394704682292784
mask_update_step
Current compression ratio of attn:  tensor(0.5873, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6402416440265565
mask_update_step
Current compression ratio of attn:  tensor(0.5961, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6410103325627065
mask_update_step
Current compression ratio of attn:  tensor(0.5890, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5238, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6417765308514665
mask_update_step
Current compression ratio of attn:  tensor(0.5968, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6425402359162492
mask_update_step
Current compression ratio of attn:  tensor(0.5949, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5244, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.643301444790153
mask_update_step
Current compression ratio of attn:  tensor(0.5952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6440601545159739
mask_update_step
Current compression ratio of attn:  tensor(0.5978, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5268, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6448163621462164
mask_update_step
Current compression ratio of attn:  tensor(0.6011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5268, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6455700647431057
mask_update_step
Current compression ratio of attn:  tensor(0.6022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5283, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6463212593785986
mask_update_step
Current compression ratio of attn:  tensor(0.5980, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5330, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6470699431343953
mask_update_step
Current compression ratio of attn:  tensor(0.5995, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5341, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6478161131019498
mask_update_step
Current compression ratio of attn:  tensor(0.6084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5307, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6485597663824825
mask_update_step
Current compression ratio of attn:  tensor(0.6106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5313, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6493009000869908
Search Epoch: [5]  [17709/17710]  eta: 0:00:01  lr: 0.00001000  loss: 15.7254  loss_ita: 9.9262  loss_sp_attn: 2.6317  loss_sp_mlp: 3.1675  time: 1.0786  data: 0.0004  max mem: 65456
Search Epoch: [5] Total time: 5:41:53 (1.1583 s / it)
Averaged stats: lr: 0.0000  loss: 16.1303  loss_ita: 9.4795  loss_sp_attn: 3.1389  loss_sp_mlp: 3.5120
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 44.38, 'txt_r5': 76.3, 'txt_r10': 85.64, 'txt_r_mean': 68.77333333333333, 'img_r1': 45.133946421431425, 'img_r5': 73.39864054378249, 'img_r10': 83.04278288684526, 'img_r_mean': 67.19178995068638, 'r_mean': 67.98256164200986}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: -0.0463
Text_CKA_Similarity: 0.7957
Image_Cosine_Similarity: 0.0499
Image_CKA_Similarity: 0.7053
sim_matrix_pearson_correlation: 0.9253
KD:True
Search Epoch: [6]  [    0/17710]  eta: 8 days, 2:41:00  lr: 0.00001000  loss: 15.6786  loss_ita: 9.8793  loss_sp_attn: 2.6317  loss_sp_mlp: 3.1675  time: 39.5743  data: 0.2092  max mem: 65456
mask_update_step
Current compression ratio of attn:  tensor(0.6102, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5338, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6500395113362597
mask_update_step
Current compression ratio of attn:  tensor(0.6109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5354, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6507755972608745
mask_update_step
Current compression ratio of attn:  tensor(0.6131, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5361, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6515091550012304
mask_update_step
Current compression ratio of attn:  tensor(0.6096, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6522401817075448
mask_update_step
Current compression ratio of attn:  tensor(0.6171, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6529686745398675
mask_update_step
Current compression ratio of attn:  tensor(0.6159, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5405, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.653694630668092
mask_update_step
Current compression ratio of attn:  tensor(0.6188, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5407, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6544180472719672
mask_update_step
Current compression ratio of attn:  tensor(0.6153, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6551389215411071
mask_update_step
Current compression ratio of attn:  tensor(0.6228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5423, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6558572506750027
mask_update_step
Current compression ratio of attn:  tensor(0.6212, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6565730318830323
mask_update_step
Current compression ratio of attn:  tensor(0.6173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5497, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6572862623844726
mask_update_step
Current compression ratio of attn:  tensor(0.6211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5494, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6579969394085101
mask_update_step
Current compression ratio of attn:  tensor(0.6339, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5436, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6587050601942505
mask_update_step
Current compression ratio of attn:  tensor(0.6296, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6594106219907302
mask_update_step
Current compression ratio of attn:  tensor(0.6349, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6601136220569276
mask_update_step
Current compression ratio of attn:  tensor(0.6337, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5497, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6608140576617726
mask_update_step
Current compression ratio of attn:  tensor(0.6389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6615119260841577
mask_update_step
Current compression ratio of attn:  tensor(0.6327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5543, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6622072246129488
mask_update_step
Current compression ratio of attn:  tensor(0.6360, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6628999505469955
mask_update_step
Current compression ratio of attn:  tensor(0.6405, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5534, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6635901011951415
mask_update_step
Current compression ratio of attn:  tensor(0.6397, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6642776738762353
mask_update_step
Current compression ratio of attn:  tensor(0.6476, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5528, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6649626659191403
mask_update_step
Current compression ratio of attn:  tensor(0.6456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5562, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6656450746627458
mask_update_step
Current compression ratio of attn:  tensor(0.6451, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5584, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6663248974559763
mask_update_step
Current compression ratio of attn:  tensor(0.6473, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5590, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.667002131657803
Search Epoch: [6]  [ 5000/17710]  eta: 4:05:06  lr: 0.00001000  loss: 15.5833  loss_ita: 10.2193  loss_sp_attn: 2.3836  loss_sp_mlp: 2.9804  time: 1.1734  data: 0.0002  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.6487, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5601, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6676767746372528
mask_update_step
Current compression ratio of attn:  tensor(0.6498, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5614, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6683488237734198
mask_update_step
Current compression ratio of attn:  tensor(0.6524, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5616, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6690182764554746
mask_update_step
Current compression ratio of attn:  tensor(0.6534, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5630, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6696851300826746
mask_update_step
Current compression ratio of attn:  tensor(0.6548, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5639, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6703493820643747
mask_update_step
Current compression ratio of attn:  tensor(0.6594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5632, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6710110298200361
mask_update_step
Current compression ratio of attn:  tensor(0.6518, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5697, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6716700707792377
mask_update_step
Current compression ratio of attn:  tensor(0.6669, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5623, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6723265023816853
mask_update_step
Current compression ratio of attn:  tensor(0.6605, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5680, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6729803220772218
mask_update_step
Current compression ratio of attn:  tensor(0.6651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5671, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.673631527325837
mask_update_step
Current compression ratio of attn:  tensor(0.6676, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5674, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6742801155976774
mask_update_step
Current compression ratio of attn:  tensor(0.6679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5691, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6749260843730562
mask_update_step
Current compression ratio of attn:  tensor(0.6724, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5683, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6755694311424634
mask_update_step
Current compression ratio of attn:  tensor(0.6735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5696, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6762101534065743
mask_update_step
Current compression ratio of attn:  tensor(0.6729, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5716, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6768482486762609
mask_update_step
Current compression ratio of attn:  tensor(0.6747, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5725, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6774837144726007
mask_update_step
Current compression ratio of attn:  tensor(0.6797, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5712, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6781165483268858
mask_update_step
Current compression ratio of attn:  tensor(0.6780, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5742, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6787467477806335
mask_update_step
Current compression ratio of attn:  tensor(0.6806, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5740, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6793743103855956
mask_update_step
Current compression ratio of attn:  tensor(0.6847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5737, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6799992337037674
mask_update_step
Current compression ratio of attn:  tensor(0.6850, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5754, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6806215153073973
mask_update_step
Current compression ratio of attn:  tensor(0.6872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5758, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6812411527789971
mask_update_step
Current compression ratio of attn:  tensor(0.6858, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5785, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6818581437113502
mask_update_step
Current compression ratio of attn:  tensor(0.6892, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5782, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.682472485707522
mask_update_step
Current compression ratio of attn:  tensor(0.6898, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5796, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6830841763808679
Search Epoch: [6]  [10000/17710]  eta: 2:29:42  lr: 0.00001000  loss: 15.3338  loss_ita: 10.3961  loss_sp_attn: 2.0964  loss_sp_mlp: 2.8412  time: 1.1829  data: 0.0002  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.6865, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5835, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6836932133550442
mask_update_step
Current compression ratio of attn:  tensor(0.6938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5808, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6842995942640158
mask_update_step
Current compression ratio of attn:  tensor(0.6920, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5836, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6849033167520666
mask_update_step
Current compression ratio of attn:  tensor(0.6926, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5848, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6855043784738081
mask_update_step
Current compression ratio of attn:  tensor(0.6952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5852, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.686102777094188
mask_update_step
Current compression ratio of attn:  tensor(0.6974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5855, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6866985102885007
mask_update_step
Current compression ratio of attn:  tensor(0.7060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5821, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6872915757423949
mask_update_step
Current compression ratio of attn:  tensor(0.7030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5857, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6878819711518829
mask_update_step
Current compression ratio of attn:  tensor(0.7012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5884, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6884696942233506
mask_update_step
Current compression ratio of attn:  tensor(0.7066, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5869, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6890547426735648
mask_update_step
Current compression ratio of attn:  tensor(0.7056, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6896371142296837
mask_update_step
Current compression ratio of attn:  tensor(0.7014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5935, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6902168066292639
mask_update_step
Current compression ratio of attn:  tensor(0.7032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5942, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.690793817620271
mask_update_step
Current compression ratio of attn:  tensor(0.7142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5892, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6913681449610873
mask_update_step
Current compression ratio of attn:  tensor(0.7128, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5917, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6919397864205208
mask_update_step
Current compression ratio of attn:  tensor(0.7141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5924, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6925087397778135
mask_update_step
Current compression ratio of attn:  tensor(0.7135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5946, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.693075002822651
mask_update_step
Current compression ratio of attn:  tensor(0.7201, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5923, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6936385733551698
mask_update_step
Current compression ratio of attn:  tensor(0.7151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5970, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6941994491859667
mask_update_step
Current compression ratio of attn:  tensor(0.7177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6947576281361073
mask_update_step
Current compression ratio of attn:  tensor(0.7219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5961, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.695313108037134
mask_update_step
Current compression ratio of attn:  tensor(0.7224, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5973, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6958658867310749
mask_update_step
Current compression ratio of attn:  tensor(0.7291, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5949, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6964159620704515
mask_update_step
Current compression ratio of attn:  tensor(0.7240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5998, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6969633319182882
mask_update_step
Current compression ratio of attn:  tensor(0.7250, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6975079941481193
Search Epoch: [6]  [15000/17710]  eta: 0:52:35  lr: 0.00001000  loss: 14.9829  loss_ita: 10.4267  loss_sp_attn: 1.8589  loss_sp_mlp: 2.6974  time: 1.0885  data: 0.0001  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.7288, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.698049946643998
mask_update_step
Current compression ratio of attn:  tensor(0.7289, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.698589187300505
mask_update_step
Current compression ratio of attn:  tensor(0.7274, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6991257140227554
mask_update_step
Current compression ratio of attn:  tensor(0.7361, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6996595247264081
mask_update_step
Current compression ratio of attn:  tensor(0.7326, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7001906173376733
mask_update_step
Current compression ratio of attn:  tensor(0.7401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7007189897933204
mask_update_step
Current compression ratio of attn:  tensor(0.7394, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7012446400406869
mask_update_step
Current compression ratio of attn:  tensor(0.7424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.701767566037685
mask_update_step
Current compression ratio of attn:  tensor(0.7315, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7022877657528106
mask_update_step
Current compression ratio of attn:  tensor(0.7353, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7028052371651512
mask_update_step
Current compression ratio of attn:  tensor(0.7452, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6058, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.703319978264393
mask_update_step
Current compression ratio of attn:  tensor(0.7454, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7038319870508292
mask_update_step
Current compression ratio of attn:  tensor(0.7512, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6054, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7043412615353678
Search Epoch: [6]  [17709/17710]  eta: 0:00:01  lr: 0.00001000  loss: 15.1050  loss_ita: 10.7566  loss_sp_attn: 1.6814  loss_sp_mlp: 2.6670  time: 1.1991  data: 0.0005  max mem: 65458
Search Epoch: [6] Total time: 5:43:14 (1.1629 s / it)
Averaged stats: lr: 0.0000  loss: 15.2182  loss_ita: 10.1646  loss_sp_attn: 2.1742  loss_sp_mlp: 2.8795
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 41.88, 'txt_r5': 73.34, 'txt_r10': 83.14, 'txt_r_mean': 66.12, 'img_r1': 42.255097960815675, 'img_r5': 70.79968012794882, 'img_r10': 80.76769292283086, 'img_r_mean': 64.60749033719846, 'r_mean': 65.36374516859922}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0326
Text_CKA_Similarity: 0.8383
Image_Cosine_Similarity: 0.0518
Image_CKA_Similarity: 0.7311
sim_matrix_pearson_correlation: 0.9152
KD:True
Search Epoch: [7]  [    0/17710]  eta: 6 days, 22:57:12  lr: 0.00001000  loss: 14.6875  loss_ita: 10.3390  loss_sp_attn: 1.6814  loss_sp_mlp: 2.6670  time: 33.9375  data: 0.2380  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.7485, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7048477997395393
mask_update_step
Current compression ratio of attn:  tensor(0.7470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7053515996955041
mask_update_step
Current compression ratio of attn:  tensor(0.7426, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7058526594460603
mask_update_step
Current compression ratio of attn:  tensor(0.7513, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7063509770446521
mask_update_step
Current compression ratio of attn:  tensor(0.7523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7068465505553756
mask_update_step
Current compression ratio of attn:  tensor(0.7520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6138, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7073393780529879
mask_update_step
Current compression ratio of attn:  tensor(0.7701, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.707829457622914
mask_update_step
Current compression ratio of attn:  tensor(0.7575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7083167873612543
mask_update_step
Current compression ratio of attn:  tensor(0.7650, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7088013653747918
mask_update_step
Current compression ratio of attn:  tensor(0.7610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6144, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7092831897809996
mask_update_step
Current compression ratio of attn:  tensor(0.7582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6176, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7097622587080484
mask_update_step
Current compression ratio of attn:  tensor(0.7559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6205, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7102385702948135
mask_update_step
Current compression ratio of attn:  tensor(0.7634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7107121226908825
mask_update_step
Current compression ratio of attn:  tensor(0.7597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6207, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7111829140565612
mask_update_step
Current compression ratio of attn:  tensor(0.7627, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7116509425628827
mask_update_step
Current compression ratio of attn:  tensor(0.7645, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6209, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7121162063916127
mask_update_step
Current compression ratio of attn:  tensor(0.7699, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.712578703735258
mask_update_step
Current compression ratio of attn:  tensor(0.7621, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7130384327970722
mask_update_step
Current compression ratio of attn:  tensor(0.7713, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6210, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7134953917910639
mask_update_step
Current compression ratio of attn:  tensor(0.7685, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6239, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7139495789420027
mask_update_step
Current compression ratio of attn:  tensor(0.7834, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6163, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7144009924854267
mask_update_step
Current compression ratio of attn:  tensor(0.7740, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6232, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7148496306676488
mask_update_step
Current compression ratio of attn:  tensor(0.7753, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6238, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7152954917457643
mask_update_step
Current compression ratio of attn:  tensor(0.7766, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6243, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7157385739876571
mask_update_step
Current compression ratio of attn:  tensor(0.7846, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7161788756720062
Search Epoch: [7]  [ 5000/17710]  eta: 4:08:16  lr: 0.00001000  loss: 14.6703  loss_ita: 10.6502  loss_sp_attn: 1.4560  loss_sp_mlp: 2.5641  time: 1.1880  data: 0.0002  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.7813, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6242, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7166163950882931
mask_update_step
Current compression ratio of attn:  tensor(0.7810, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7170511305368079
mask_update_step
Current compression ratio of attn:  tensor(0.7798, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6278, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.717483080328656
mask_update_step
Current compression ratio of attn:  tensor(0.7769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6309, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.717912242785765
mask_update_step
Current compression ratio of attn:  tensor(0.7849, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7183386162408908
mask_update_step
Current compression ratio of attn:  tensor(0.7820, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6304, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7187621990376243
mask_update_step
Current compression ratio of attn:  tensor(0.7837, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6304, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7191829895303974
mask_update_step
Current compression ratio of attn:  tensor(0.7883, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6291, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7196009860844905
mask_update_step
Current compression ratio of attn:  tensor(0.7867, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6311, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7200161870760373
mask_update_step
Current compression ratio of attn:  tensor(0.7913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6294, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7204285908920326
mask_update_step
Current compression ratio of attn:  tensor(0.7947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6288, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7208381959303375
mask_update_step
Current compression ratio of attn:  tensor(0.7922, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6315, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7212450005996861
mask_update_step
Current compression ratio of attn:  tensor(0.7910, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7216490033196916
mask_update_step
Current compression ratio of attn:  tensor(0.7927, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6336, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7220502025208525
mask_update_step
Current compression ratio of attn:  tensor(0.7973, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6319, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7224485966445585
mask_update_step
Current compression ratio of attn:  tensor(0.7952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6344, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7228441841430967
mask_update_step
Current compression ratio of attn:  tensor(0.7977, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6343, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7232369634796577
mask_update_step
Current compression ratio of attn:  tensor(0.7994, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6345, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7236269331283415
mask_update_step
Current compression ratio of attn:  tensor(0.8003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7240140915741633
mask_update_step
Current compression ratio of attn:  tensor(0.8028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6348, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7243984373130593
mask_update_step
Current compression ratio of attn:  tensor(0.8045, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6350, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7247799688518932
mask_update_step
Current compression ratio of attn:  tensor(0.8036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6367, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7251586847084611
mask_update_step
Current compression ratio of attn:  tensor(0.8049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6371, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7255345834114979
mask_update_step
Current compression ratio of attn:  tensor(0.8066, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6372, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7259076635006826
mask_update_step
Current compression ratio of attn:  tensor(0.8103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6361, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7262779235266444
Search Epoch: [7]  [10000/17710]  eta: 2:29:34  lr: 0.00001000  loss: 14.5473  loss_ita: 10.8059  loss_sp_attn: 1.2818  loss_sp_mlp: 2.4596  time: 1.2003  data: 0.0002  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.8103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6370, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7266453620509682
mask_update_step
Current compression ratio of attn:  tensor(0.8124, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6370, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7270099776461996
mask_update_step
Current compression ratio of attn:  tensor(0.8141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6372, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7273717688958512
mask_update_step
Current compression ratio of attn:  tensor(0.8166, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7277307343944082
mask_update_step
Current compression ratio of attn:  tensor(0.8157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6384, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7280868727473331
mask_update_step
Current compression ratio of attn:  tensor(0.8170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7284401825710713
mask_update_step
Current compression ratio of attn:  tensor(0.8182, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6391, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7287906624930572
mask_update_step
Current compression ratio of attn:  tensor(0.8177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.729138311151719
mask_update_step
Current compression ratio of attn:  tensor(0.8169, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6421, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7294831271964836
mask_update_step
Current compression ratio of attn:  tensor(0.8236, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6391, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7298251092877824
mask_update_step
Current compression ratio of attn:  tensor(0.8117, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7301642560970567
mask_update_step
Current compression ratio of attn:  tensor(0.8248, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7305005663067621
mask_update_step
Current compression ratio of attn:  tensor(0.8247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6415, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7308340386103743
mask_update_step
Current compression ratio of attn:  tensor(0.8230, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6436, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7311646717123939
mask_update_step
Current compression ratio of attn:  tensor(0.8327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7314924643283514
mask_update_step
Current compression ratio of attn:  tensor(0.8326, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6398, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.731817415184812
mask_update_step
Current compression ratio of attn:  tensor(0.8342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6397, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7321395230193815
mask_update_step
Current compression ratio of attn:  tensor(0.8312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6426, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7324587865807096
mask_update_step
Current compression ratio of attn:  tensor(0.8312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7327752046284963
mask_update_step
Current compression ratio of attn:  tensor(0.8324, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7330887759334959
mask_update_step
Current compression ratio of attn:  tensor(0.8361, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6426, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7333994992775218
mask_update_step
Current compression ratio of attn:  tensor(0.8331, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6454, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7337073734534515
mask_update_step
Current compression ratio of attn:  tensor(0.8385, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7340123972652313
mask_update_step
Current compression ratio of attn:  tensor(0.8457, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6396, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7343145695278804
mask_update_step
Current compression ratio of attn:  tensor(0.8371, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6459, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7346138890674967
Search Epoch: [7]  [15000/17710]  eta: 0:52:35  lr: 0.00001000  loss: 14.3548  loss_ita: 10.8602  loss_sp_attn: 1.1012  loss_sp_mlp: 2.3935  time: 1.1459  data: 0.0002  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.8425, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6435, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7349103547212595
mask_update_step
Current compression ratio of attn:  tensor(0.8445, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7352039653374363
mask_update_step
Current compression ratio of attn:  tensor(0.8440, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6443, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7354947197753849
mask_update_step
Current compression ratio of attn:  tensor(0.8482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6427, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7357826169055599
mask_update_step
Current compression ratio of attn:  tensor(0.8430, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6468, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.736067655609516
mask_update_step
Current compression ratio of attn:  tensor(0.8412, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6488, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7363498347799121
mask_update_step
Current compression ratio of attn:  tensor(0.8492, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6448, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7366291533205165
mask_update_step
Current compression ratio of attn:  tensor(0.8520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7369056101462106
mask_update_step
Current compression ratio of attn:  tensor(0.8519, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6448, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.737179204182993
mask_update_step
Current compression ratio of attn:  tensor(0.8561, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6432, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7374499343679841
mask_update_step
Current compression ratio of attn:  tensor(0.8449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6509, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.73771779964943
mask_update_step
Current compression ratio of attn:  tensor(0.8554, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7379827989867067
mask_update_step
Current compression ratio of attn:  tensor(0.8489, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7382449313503239
mask_update_step
Current compression ratio of attn:  tensor(0.8595, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6444, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7385041957219288
Search Epoch: [7]  [17709/17710]  eta: 0:00:01  lr: 0.00001000  loss: 14.5850  loss_ita: 11.2322  loss_sp_attn: 0.9499  loss_sp_mlp: 2.4030  time: 1.2177  data: 0.0007  max mem: 65458
Search Epoch: [7] Total time: 5:43:41 (1.1644 s / it)
Averaged stats: lr: 0.0000  loss: 14.6945  loss_ita: 10.8715  loss_sp_attn: 1.3383  loss_sp_mlp: 2.4847
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 30.36, 'txt_r5': 60.56, 'txt_r10': 73.98, 'txt_r_mean': 54.96666666666667, 'img_r1': 33.710515793682525, 'img_r5': 62.97081167532987, 'img_r10': 74.922031187525, 'img_r_mean': 57.20111955217913, 'r_mean': 56.0838931094229}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0452
Text_CKA_Similarity: 0.7862
Image_Cosine_Similarity: 0.0515
Image_CKA_Similarity: 0.7247
sim_matrix_pearson_correlation: 0.8919
KD:True
Search Epoch: [8]  [    0/17710]  eta: 8 days, 10:10:48  lr: 0.00001000  loss: 14.2256  loss_ita: 10.8727  loss_sp_attn: 0.9499  loss_sp_mlp: 2.4030  time: 41.0982  data: 0.2217  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.8482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6522, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7387605910943111
mask_update_step
Current compression ratio of attn:  tensor(0.8549, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6486, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7390141164714059
mask_update_step
Current compression ratio of attn:  tensor(0.8603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6461, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7392647708682978
mask_update_step
Current compression ratio of attn:  tensor(0.8551, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7395125533112248
mask_update_step
Current compression ratio of attn:  tensor(0.8635, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6460, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7397574628375821
mask_update_step
Current compression ratio of attn:  tensor(0.8659, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6452, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7399994984959263
mask_update_step
Current compression ratio of attn:  tensor(0.8568, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6516, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7402386593459777
mask_update_step
Current compression ratio of attn:  tensor(0.8647, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6475, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7404749444586256
mask_update_step
Current compression ratio of attn:  tensor(0.8586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7407083529159311
mask_update_step
Current compression ratio of attn:  tensor(0.8683, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6468, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7409388838111306
mask_update_step
Current compression ratio of attn:  tensor(0.8630, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6507, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7411665362486395
mask_update_step
Current compression ratio of attn:  tensor(0.8598, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6534, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7413913093440558
mask_update_step
Current compression ratio of attn:  tensor(0.8609, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6534, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7416132022241632
mask_update_step
Current compression ratio of attn:  tensor(0.8676, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6500, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7418322140269347
mask_update_step
Current compression ratio of attn:  tensor(0.8692, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6498, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7420483439015361
mask_update_step
Current compression ratio of attn:  tensor(0.8698, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6500, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7422615910083291
mask_update_step
Current compression ratio of attn:  tensor(0.8666, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7424719545188745
mask_update_step
Current compression ratio of attn:  tensor(0.8712, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6505, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7426794336159355
mask_update_step
Current compression ratio of attn:  tensor(0.8706, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6516, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7428840274934811
mask_update_step
Current compression ratio of attn:  tensor(0.8665, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7430857353566889
mask_update_step
Current compression ratio of attn:  tensor(0.8740, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6507, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7432845564219482
mask_update_step
Current compression ratio of attn:  tensor(0.8734, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6517, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7434804899168634
mask_update_step
Current compression ratio of attn:  tensor(0.8754, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6511, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7436735350802566
mask_update_step
Current compression ratio of attn:  tensor(0.8752, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6519, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7438636911621708
mask_update_step
Current compression ratio of attn:  tensor(0.8749, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6526, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7440509574238725
Search Epoch: [8]  [ 5000/17710]  eta: 4:05:36  lr: 0.00001000  loss: 15.1624  loss_ita: 11.9695  loss_sp_attn: 0.8451  loss_sp_mlp: 2.3478  time: 1.1812  data: 0.0001  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.8696, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6565, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7442353331378552
mask_update_step
Current compression ratio of attn:  tensor(0.8681, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7444168175878415
mask_update_step
Current compression ratio of attn:  tensor(0.8752, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7445954100687864
mask_update_step
Current compression ratio of attn:  tensor(0.8771, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6536, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7447711098868797
mask_update_step
Current compression ratio of attn:  tensor(0.8773, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6540, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.744943916359549
mask_update_step
Current compression ratio of attn:  tensor(0.8671, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6608, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7451138288154621
mask_update_step
Current compression ratio of attn:  tensor(0.8824, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7452808465945295
mask_update_step
Current compression ratio of attn:  tensor(0.8770, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7454449690479078
mask_update_step
Current compression ratio of attn:  tensor(0.8815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6536, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7456061955380009
mask_update_step
Current compression ratio of attn:  tensor(0.8744, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6584, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7457645254384634
mask_update_step
Current compression ratio of attn:  tensor(0.8754, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6583, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.745919958134203
mask_update_step
Current compression ratio of attn:  tensor(0.8765, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7460724930213825
mask_update_step
Current compression ratio of attn:  tensor(0.8805, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6561, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7462221295074222
mask_update_step
Current compression ratio of attn:  tensor(0.8829, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6552, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7463688670110027
mask_update_step
Current compression ratio of attn:  tensor(0.8839, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6550, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7465127049620666
mask_update_step
Current compression ratio of attn:  tensor(0.8754, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6607, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7466536428018207
mask_update_step
Current compression ratio of attn:  tensor(0.8898, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7467916799827389
mask_update_step
Current compression ratio of attn:  tensor(0.8822, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7469268159685631
mask_update_step
Current compression ratio of attn:  tensor(0.8815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7470590502343069
mask_update_step
Current compression ratio of attn:  tensor(0.8821, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6583, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7471883822662557
mask_update_step
Current compression ratio of attn:  tensor(0.8831, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7473148115619704
mask_update_step
Current compression ratio of attn:  tensor(0.8867, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7474383376302889
mask_update_step
Current compression ratio of attn:  tensor(0.8804, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6600, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7475589599913267
mask_update_step
Current compression ratio of attn:  tensor(0.8931, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6529, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7476766781764812
mask_update_step
Current compression ratio of attn:  tensor(0.8811, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7477914917284313
Search Epoch: [8]  [10000/17710]  eta: 2:29:43  lr: 0.00001000  loss: 14.5466  loss_ita: 11.4489  loss_sp_attn: 0.8037  loss_sp_mlp: 2.2939  time: 1.2105  data: 0.0002  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.8868, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7479034002011402
mask_update_step
Current compression ratio of attn:  tensor(0.8896, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7480124031598572
mask_update_step
Current compression ratio of attn:  tensor(0.8862, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7481185001811188
mask_update_step
Current compression ratio of attn:  tensor(0.8915, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6553, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7482216908527511
mask_update_step
Current compression ratio of attn:  tensor(0.8938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.748321974773871
mask_update_step
Current compression ratio of attn:  tensor(0.8848, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6598, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7484193515548873
mask_update_step
Current compression ratio of attn:  tensor(0.8876, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6587, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7485138208175032
mask_update_step
Current compression ratio of attn:  tensor(0.8855, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6602, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7486053821947172
mask_update_step
Current compression ratio of attn:  tensor(0.8921, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6565, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7486940353308242
mask_update_step
Current compression ratio of attn:  tensor(0.8952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6551, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7487797798814178
mask_update_step
Current compression ratio of attn:  tensor(0.8958, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6547, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7488626155133905
mask_update_step
Current compression ratio of attn:  tensor(0.8889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6592, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.748942541904936
mask_update_step
Current compression ratio of attn:  tensor(0.8886, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7490195587455503
mask_update_step
Current compression ratio of attn:  tensor(0.8956, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6556, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7490936657360319
mask_update_step
Current compression ratio of attn:  tensor(0.8944, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6568, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7491648625884844
mask_update_step
Current compression ratio of attn:  tensor(0.8919, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6583, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7492331490263164
mask_update_step
Current compression ratio of attn:  tensor(0.8976, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6550, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7492985247842436
mask_update_step
Current compression ratio of attn:  tensor(0.8925, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6583, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.749360989608289
mask_update_step
Current compression ratio of attn:  tensor(0.8964, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6564, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7494205432557844
mask_update_step
Current compression ratio of attn:  tensor(0.8883, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6613, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7494771854953711
mask_update_step
Current compression ratio of attn:  tensor(0.8957, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6569, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7495309161070008
mask_update_step
Current compression ratio of attn:  tensor(0.8940, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6579, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7495817348819368
mask_update_step
Current compression ratio of attn:  tensor(0.8976, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6561, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496296416227539
mask_update_step
Current compression ratio of attn:  tensor(0.8998, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496746361433407
mask_update_step
Current compression ratio of attn:  tensor(0.8955, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6577, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497167182688986
Search Epoch: [8]  [15000/17710]  eta: 0:52:42  lr: 0.00001000  loss: 14.7095  loss_ita: 11.6896  loss_sp_attn: 0.7063  loss_sp_mlp: 2.3136  time: 1.1796  data: 0.0001  max mem: 65458
mask_update_step
Current compression ratio of attn:  tensor(0.8925, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497558878359438
mask_update_step
Current compression ratio of attn:  tensor(0.8952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497921446923073
mask_update_step
Current compression ratio of attn:  tensor(0.8935, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6593, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498254886971355
mask_update_step
Current compression ratio of attn:  tensor(0.8970, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498559197208912
mask_update_step
Current compression ratio of attn:  tensor(0.8948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498834376453531
mask_update_step
Current compression ratio of attn:  tensor(0.8918, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6605, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499080423636181
mask_update_step
Current compression ratio of attn:  tensor(0.8953, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6587, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499297337800992
mask_update_step
Current compression ratio of attn:  tensor(0.8910, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6612, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499485118105282
mask_update_step
Current compression ratio of attn:  tensor(0.8967, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499643763819548
mask_update_step
Current compression ratio of attn:  tensor(0.8945, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6591, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499773274327468
mask_update_step
Current compression ratio of attn:  tensor(0.8963, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499873649125912
mask_update_step
Current compression ratio of attn:  tensor(0.8941, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6591, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499944887824934
mask_update_step
Current compression ratio of attn:  tensor(0.8880, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6631, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499986990147782
mask_update_step
Current compression ratio of attn:  tensor(0.8967, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.75
Search Epoch: [8]  [17709/17710]  eta: 0:00:01  lr: 0.00001000  loss: 12.4975  loss_ita: 9.4636  loss_sp_attn: 0.7568  loss_sp_mlp: 2.2771  time: 1.1997  data: 0.0007  max mem: 65458
Search Epoch: [8] Total time: 5:44:19 (1.1665 s / it)
Averaged stats: lr: 0.0000  loss: 14.6296  loss_ita: 11.4961  loss_sp_attn: 0.8040  loss_sp_mlp: 2.3296
Computing features for evaluation...
do itm_eval
search_result {'txt_r1': 25.06, 'txt_r5': 54.76, 'txt_r10': 68.02, 'txt_r_mean': 49.279999999999994, 'img_r1': 30.263894442223112, 'img_r5': 59.564174330267896, 'img_r10': 71.83526589364254, 'img_r_mean': 53.88777822204452, 'r_mean': 51.58388911102226}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0152
Text_CKA_Similarity: 0.7930
Image_Cosine_Similarity: 0.0175
Image_CKA_Similarity: 0.6605
sim_matrix_pearson_correlation: 0.8794
mask_attn_vision:   [1.56, 1.56, 1.56, 1.56, 1.56, 1.56, 32.81, 1.56, 23.44, 26.56, 31.25, 26.56, 9.38, 23.44, 20.31, 15.62, 9.38, 9.38, 9.38, 1.56, 6.25, 9.38, 6.25, 10.94]
mask_attn_language:  [40.62, 4.69, 1.56, 1.56, 3.12, 4.69, 1.56, 1.56, 1.56, 4.69, 15.62, 7.81]
mask_mlp_vision:  [74.44, 21.73, 23.0, 24.8, 34.23, 28.86, 39.79, 39.06, 45.97, 52.22, 48.58, 46.07, 52.81, 47.19, 46.0, 45.12, 33.98, 27.0, 24.37, 21.51, 23.71, 23.71, 45.87, 24.32]
mask_mlp_language:  [52.05, 29.43, 20.35, 20.41, 19.89, 17.51, 19.01, 20.35, 23.44, 32.58, 33.27, 24.8]
mask_vision:  0.3687199652194977
mask_language:  0.25709500908851624
mask_attn:  0.1032986119389534
mask_mlp:  0.3421667814254761
Creating model for training
VisionTransformerを作成
Start training
KD:False
Train Epoch: [0]  [    0/17710]  eta: 4:03:17  lr: 0.00001000  loss: 7.6586  time: 0.8242  data: 0.2658  max mem: 65458
KD is False
Train Epoch: [0]  [ 5000/17710]  eta: 1:48:41  lr: 0.00001000  loss: 4.7590  time: 0.5114  data: 0.0001  max mem: 65458
Train Epoch: [0]  [10000/17710]  eta: 1:06:02  lr: 0.00001000  loss: 4.8440  time: 0.5034  data: 0.0001  max mem: 65458
Train Epoch: [0]  [15000/17710]  eta: 0:23:14  lr: 0.00001000  loss: 4.7605  time: 0.5153  data: 0.0001  max mem: 65458
Train Epoch: [0]  [17709/17710]  eta: 0:00:00  lr: 0.00001000  loss: 3.2069  time: 0.5044  data: 0.0006  max mem: 65458
Train Epoch: [0] Total time: 2:31:51 (0.5145 s / it)
Averaged stats: lr: 0.0000  loss: 3.8051
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0467
Text_CKA_Similarity: 0.6206
Image_Cosine_Similarity: 0.1187
Image_CKA_Similarity: 0.7652
sim_matrix_pearson_correlation: 0.6579
{'txt_r1': 58.78, 'txt_r5': 84.28, 'txt_r10': 91.48, 'txt_r_mean': 78.18, 'img_r1': 43.97840863654538, 'img_r5': 72.7469012395042, 'img_r10': 82.45901639344262, 'img_r_mean': 66.39477542316406, 'r_mean': 72.28738771158203}
{'txt_r1': 58.54, 'txt_r5': 83.98, 'txt_r10': 90.82, 'txt_r_mean': 77.78, 'img_r1': 43.406637345061974, 'img_r5': 72.1671331467413, 'img_r10': 81.97121151539385, 'img_r_mean': 65.84832733573238, 'r_mean': 71.81416366786618}
LOG:  {'train_lr': '0.000', 'train_loss': '3.805', 'val_txt_r1': 58.78, 'val_txt_r5': 84.28, 'val_txt_r10': 91.48, 'val_txt_r_mean': 78.18, 'val_img_r1': 43.97840863654538, 'val_img_r5': 72.7469012395042, 'val_img_r10': 82.45901639344262, 'val_img_r_mean': 66.39477542316406, 'val_r_mean': 72.28738771158203, 'test_txt_r1': 58.54, 'test_txt_r5': 83.98, 'test_txt_r10': 90.82, 'test_txt_r_mean': 77.78, 'test_img_r1': 43.406637345061974, 'test_img_r5': 72.1671331467413, 'test_img_r10': 81.97121151539385, 'test_img_r_mean': 65.84832733573238, 'test_r_mean': 71.81416366786618, 'epoch': 0, 'best_epoch': 0}
KD:False
Train Epoch: [1]  [    0/17710]  eta: 5:09:00  lr: 0.00000970  loss: 4.8986  time: 1.0469  data: 0.2011  max mem: 65458
KD is False
Train Epoch: [1]  [ 5000/17710]  eta: 1:49:14  lr: 0.00000970  loss: 3.9948  time: 0.5132  data: 0.0001  max mem: 65458
Train Epoch: [1]  [10000/17710]  eta: 1:05:53  lr: 0.00000970  loss: 3.1468  time: 0.4964  data: 0.0001  max mem: 65458
Train Epoch: [1]  [15000/17710]  eta: 0:23:08  lr: 0.00000970  loss: 3.3855  time: 0.5260  data: 0.0001  max mem: 65458
Train Epoch: [1]  [17709/17710]  eta: 0:00:00  lr: 0.00000970  loss: 2.2756  time: 0.5022  data: 0.0006  max mem: 65458
Train Epoch: [1] Total time: 2:31:22 (0.5129 s / it)
Averaged stats: lr: 0.0000  loss: 3.5403
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0696
Text_CKA_Similarity: 0.5797
Image_Cosine_Similarity: 0.1086
Image_CKA_Similarity: 0.7438
sim_matrix_pearson_correlation: 0.6482
{'txt_r1': 61.56, 'txt_r5': 85.76, 'txt_r10': 92.56, 'txt_r_mean': 79.96, 'img_r1': 45.781687325069974, 'img_r5': 74.15833666533386, 'img_r10': 83.57856857257097, 'img_r_mean': 67.83953085432493, 'r_mean': 73.89976542716246}
{'txt_r1': 60.72, 'txt_r5': 85.26, 'txt_r10': 91.78, 'txt_r_mean': 79.25333333333334, 'img_r1': 44.734106357457016, 'img_r5': 73.87844862055178, 'img_r10': 83.23870451819272, 'img_r_mean': 67.28375316540051, 'r_mean': 73.26854324936693}
LOG:  {'train_lr': '0.000', 'train_loss': '3.540', 'val_txt_r1': 61.56, 'val_txt_r5': 85.76, 'val_txt_r10': 92.56, 'val_txt_r_mean': 79.96, 'val_img_r1': 45.781687325069974, 'val_img_r5': 74.15833666533386, 'val_img_r10': 83.57856857257097, 'val_img_r_mean': 67.83953085432493, 'val_r_mean': 73.89976542716246, 'test_txt_r1': 60.72, 'test_txt_r5': 85.26, 'test_txt_r10': 91.78, 'test_txt_r_mean': 79.25333333333334, 'test_img_r1': 44.734106357457016, 'test_img_r5': 73.87844862055178, 'test_img_r10': 83.23870451819272, 'test_img_r_mean': 67.28375316540051, 'test_r_mean': 73.26854324936693, 'epoch': 1, 'best_epoch': 1}
KD:False
Train Epoch: [2]  [    0/17710]  eta: 4:39:18  lr: 0.00000883  loss: 4.3290  time: 0.9463  data: 0.2550  max mem: 65458
KD is False
Train Epoch: [2]  [ 5000/17710]  eta: 1:49:12  lr: 0.00000883  loss: 3.8337  time: 0.5172  data: 0.0001  max mem: 65458
Train Epoch: [2]  [10000/17710]  eta: 1:06:14  lr: 0.00000883  loss: 2.7742  time: 0.4942  data: 0.0001  max mem: 65458
Train Epoch: [2]  [15000/17710]  eta: 0:23:18  lr: 0.00000883  loss: 3.3849  time: 0.5100  data: 0.0001  max mem: 65458
Train Epoch: [2]  [17709/17710]  eta: 0:00:00  lr: 0.00000883  loss: 2.2324  time: 0.5152  data: 0.0004  max mem: 65458
Train Epoch: [2] Total time: 2:32:31 (0.5167 s / it)
Averaged stats: lr: 0.0000  loss: 3.3077
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.1074
Text_CKA_Similarity: 0.5397
Image_Cosine_Similarity: 0.1049
Image_CKA_Similarity: 0.7238
sim_matrix_pearson_correlation: 0.6056
{'txt_r1': 61.34, 'txt_r5': 86.2, 'txt_r10': 92.44, 'txt_r_mean': 79.99333333333334, 'img_r1': 46.273490603758496, 'img_r5': 74.21431427429029, 'img_r10': 83.5905637744902, 'img_r_mean': 68.02612288417966, 'r_mean': 74.00972810875649}
{'txt_r1': 61.08, 'txt_r5': 85.58, 'txt_r10': 91.64, 'txt_r_mean': 79.43333333333334, 'img_r1': 45.23390643742503, 'img_r5': 73.79448220711716, 'img_r10': 83.43462614954018, 'img_r_mean': 67.48767159802746, 'r_mean': 73.4605024656804}
LOG:  {'train_lr': '0.000', 'train_loss': '3.308', 'val_txt_r1': 61.34, 'val_txt_r5': 86.2, 'val_txt_r10': 92.44, 'val_txt_r_mean': 79.99333333333334, 'val_img_r1': 46.273490603758496, 'val_img_r5': 74.21431427429029, 'val_img_r10': 83.5905637744902, 'val_img_r_mean': 68.02612288417966, 'val_r_mean': 74.00972810875649, 'test_txt_r1': 61.08, 'test_txt_r5': 85.58, 'test_txt_r10': 91.64, 'test_txt_r_mean': 79.43333333333334, 'test_img_r1': 45.23390643742503, 'test_img_r5': 73.79448220711716, 'test_img_r10': 83.43462614954018, 'test_img_r_mean': 67.48767159802746, 'test_r_mean': 73.4605024656804, 'epoch': 2, 'best_epoch': 2}
KD:False
Train Epoch: [3]  [    0/17710]  eta: 4:38:09  lr: 0.00000750  loss: 3.6560  time: 0.9424  data: 0.2175  max mem: 65458
KD is False
Train Epoch: [3]  [ 5000/17710]  eta: 1:48:21  lr: 0.00000750  loss: 3.1179  time: 0.5161  data: 0.0001  max mem: 65458
Train Epoch: [3]  [10000/17710]  eta: 1:05:51  lr: 0.00000750  loss: 1.6868  time: 0.5275  data: 0.0001  max mem: 65458
Train Epoch: [3]  [15000/17710]  eta: 0:23:08  lr: 0.00000750  loss: 3.8658  time: 0.5075  data: 0.0002  max mem: 65458
Train Epoch: [3]  [17709/17710]  eta: 0:00:00  lr: 0.00000750  loss: 3.5754  time: 0.4897  data: 0.0005  max mem: 65458
Train Epoch: [3] Total time: 2:31:14 (0.5124 s / it)
Averaged stats: lr: 0.0000  loss: 3.1027
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.1087
Text_CKA_Similarity: 0.5301
Image_Cosine_Similarity: 0.1349
Image_CKA_Similarity: 0.7177
sim_matrix_pearson_correlation: 0.6122
{'txt_r1': 62.18, 'txt_r5': 86.88, 'txt_r10': 93.3, 'txt_r_mean': 80.78666666666668, 'img_r1': 47.13714514194322, 'img_r5': 75.08196721311475, 'img_r10': 83.90643742502999, 'img_r_mean': 68.70851659336266, 'r_mean': 74.74759163001467}
{'txt_r1': 62.14, 'txt_r5': 86.44, 'txt_r10': 92.12, 'txt_r_mean': 80.23333333333333, 'img_r1': 46.165533786485405, 'img_r5': 74.9780087964814, 'img_r10': 84.16233506597361, 'img_r_mean': 68.4352925496468, 'r_mean': 74.33431294149007}
LOG:  {'train_lr': '0.000', 'train_loss': '3.103', 'val_txt_r1': 62.18, 'val_txt_r5': 86.88, 'val_txt_r10': 93.3, 'val_txt_r_mean': 80.78666666666668, 'val_img_r1': 47.13714514194322, 'val_img_r5': 75.08196721311475, 'val_img_r10': 83.90643742502999, 'val_img_r_mean': 68.70851659336266, 'val_r_mean': 74.74759163001467, 'test_txt_r1': 62.14, 'test_txt_r5': 86.44, 'test_txt_r10': 92.12, 'test_txt_r_mean': 80.23333333333333, 'test_img_r1': 46.165533786485405, 'test_img_r5': 74.9780087964814, 'test_img_r10': 84.16233506597361, 'test_img_r_mean': 68.4352925496468, 'test_r_mean': 74.33431294149007, 'epoch': 3, 'best_epoch': 3}
KD:False
Train Epoch: [4]  [    0/17710]  eta: 4:18:13  lr: 0.00000587  loss: 2.2392  time: 0.8749  data: 0.2721  max mem: 65458
KD is False
Train Epoch: [4]  [ 5000/17710]  eta: 1:47:45  lr: 0.00000587  loss: 2.9421  time: 0.5052  data: 0.0002  max mem: 65458
Train Epoch: [4]  [10000/17710]  eta: 1:05:35  lr: 0.00000587  loss: 2.8907  time: 0.5193  data: 0.0001  max mem: 65458
Train Epoch: [4]  [15000/17710]  eta: 0:23:04  lr: 0.00000587  loss: 3.2244  time: 0.5127  data: 0.0001  max mem: 65458
Train Epoch: [4]  [17709/17710]  eta: 0:00:00  lr: 0.00000587  loss: 2.4597  time: 0.5062  data: 0.0007  max mem: 65458
Train Epoch: [4] Total time: 2:30:59 (0.5115 s / it)
Averaged stats: lr: 0.0000  loss: 2.9064
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.1213
Text_CKA_Similarity: 0.4902
Image_Cosine_Similarity: 0.1308
Image_CKA_Similarity: 0.6995
sim_matrix_pearson_correlation: 0.5962
{'txt_r1': 63.06, 'txt_r5': 87.16, 'txt_r10': 93.1, 'txt_r_mean': 81.10666666666667, 'img_r1': 47.345061975209916, 'img_r5': 75.34586165533787, 'img_r10': 84.34626149540183, 'img_r_mean': 69.01239504198321, 'r_mean': 75.05953085432495}
{'txt_r1': 62.46, 'txt_r5': 86.62, 'txt_r10': 92.68, 'txt_r_mean': 80.58666666666667, 'img_r1': 46.95721711315474, 'img_r5': 75.09796081567373, 'img_r10': 84.01839264294283, 'img_r_mean': 68.69119019059043, 'r_mean': 74.63892842862856}
LOG:  {'train_lr': '0.000', 'train_loss': '2.906', 'val_txt_r1': 63.06, 'val_txt_r5': 87.16, 'val_txt_r10': 93.1, 'val_txt_r_mean': 81.10666666666667, 'val_img_r1': 47.345061975209916, 'val_img_r5': 75.34586165533787, 'val_img_r10': 84.34626149540183, 'val_img_r_mean': 69.01239504198321, 'val_r_mean': 75.05953085432495, 'test_txt_r1': 62.46, 'test_txt_r5': 86.62, 'test_txt_r10': 92.68, 'test_txt_r_mean': 80.58666666666667, 'test_img_r1': 46.95721711315474, 'test_img_r5': 75.09796081567373, 'test_img_r10': 84.01839264294283, 'test_img_r_mean': 68.69119019059043, 'test_r_mean': 74.63892842862856, 'epoch': 4, 'best_epoch': 4}
KD:False
Train Epoch: [5]  [    0/17710]  eta: 4:24:06  lr: 0.00000413  loss: 4.1364  time: 0.8948  data: 0.2446  max mem: 65458
KD is False
Train Epoch: [5]  [ 5000/17710]  eta: 1:48:53  lr: 0.00000413  loss: 1.5139  time: 0.5219  data: 0.0001  max mem: 65458
Train Epoch: [5]  [10000/17710]  eta: 1:05:54  lr: 0.00000413  loss: 2.4059  time: 0.5218  data: 0.0001  max mem: 65458
Train Epoch: [5]  [15000/17710]  eta: 0:23:12  lr: 0.00000413  loss: 3.0733  time: 0.5222  data: 0.0001  max mem: 65458
Train Epoch: [5]  [17709/17710]  eta: 0:00:00  lr: 0.00000413  loss: 1.4465  time: 0.5056  data: 0.0006  max mem: 65458
Train Epoch: [5] Total time: 2:31:59 (0.5150 s / it)
Averaged stats: lr: 0.0000  loss: 2.7193
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.1068
Text_CKA_Similarity: 0.4613
Image_Cosine_Similarity: 0.1100
Image_CKA_Similarity: 0.6861
sim_matrix_pearson_correlation: 0.5821
{'txt_r1': 63.3, 'txt_r5': 88.24, 'txt_r10': 94.04, 'txt_r_mean': 81.86, 'img_r1': 48.36465413834466, 'img_r5': 76.00559776089564, 'img_r10': 84.75409836065573, 'img_r_mean': 69.70811675329868, 'r_mean': 75.78405837664934}
{'txt_r1': 62.72, 'txt_r5': 86.66, 'txt_r10': 93.1, 'txt_r_mean': 80.82666666666667, 'img_r1': 47.524990003998404, 'img_r5': 75.57377049180327, 'img_r10': 84.21031587365054, 'img_r_mean': 69.10302545648408, 'r_mean': 74.96484606157537}
LOG:  {'train_lr': '0.000', 'train_loss': '2.719', 'val_txt_r1': 63.3, 'val_txt_r5': 88.24, 'val_txt_r10': 94.04, 'val_txt_r_mean': 81.86, 'val_img_r1': 48.36465413834466, 'val_img_r5': 76.00559776089564, 'val_img_r10': 84.75409836065573, 'val_img_r_mean': 69.70811675329868, 'val_r_mean': 75.78405837664934, 'test_txt_r1': 62.72, 'test_txt_r5': 86.66, 'test_txt_r10': 93.1, 'test_txt_r_mean': 80.82666666666667, 'test_img_r1': 47.524990003998404, 'test_img_r5': 75.57377049180327, 'test_img_r10': 84.21031587365054, 'test_img_r_mean': 69.10302545648408, 'test_r_mean': 74.96484606157537, 'epoch': 5, 'best_epoch': 5}
KD:False
Train Epoch: [6]  [    0/17710]  eta: 4:28:10  lr: 0.00000250  loss: 3.2956  time: 0.9085  data: 0.2044  max mem: 65458
KD is False
Train Epoch: [6]  [ 5000/17710]  eta: 1:49:42  lr: 0.00000250  loss: 2.2402  time: 0.5139  data: 0.0001  max mem: 65458
Train Epoch: [6]  [10000/17710]  eta: 1:06:29  lr: 0.00000250  loss: 3.0340  time: 0.5123  data: 0.0001  max mem: 65458
Train Epoch: [6]  [15000/17710]  eta: 0:23:21  lr: 0.00000250  loss: 2.7910  time: 0.5192  data: 0.0001  max mem: 65458
Train Epoch: [6]  [17709/17710]  eta: 0:00:00  lr: 0.00000250  loss: 3.6102  time: 0.5022  data: 0.0006  max mem: 65458
Train Epoch: [6] Total time: 2:32:22 (0.5162 s / it)
Averaged stats: lr: 0.0000  loss: 2.5575
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.1225
Text_CKA_Similarity: 0.4278
Image_Cosine_Similarity: 0.1129
Image_CKA_Similarity: 0.6675
sim_matrix_pearson_correlation: 0.5578
{'txt_r1': 64.08, 'txt_r5': 87.66, 'txt_r10': 93.68, 'txt_r_mean': 81.80666666666667, 'img_r1': 48.368652538984406, 'img_r5': 75.84166333466614, 'img_r10': 84.33426629348261, 'img_r_mean': 69.51486072237772, 'r_mean': 75.66076369452219}
LOG:  {'train_lr': '0.000', 'train_loss': '2.557', 'val_txt_r1': 64.08, 'val_txt_r5': 87.66, 'val_txt_r10': 93.68, 'val_txt_r_mean': 81.80666666666667, 'val_img_r1': 48.368652538984406, 'val_img_r5': 75.84166333466614, 'val_img_r10': 84.33426629348261, 'val_img_r_mean': 69.51486072237772, 'val_r_mean': 75.66076369452219, 'test_txt_r1': 62.72, 'test_txt_r5': 86.66, 'test_txt_r10': 93.1, 'test_txt_r_mean': 80.82666666666667, 'test_img_r1': 47.524990003998404, 'test_img_r5': 75.57377049180327, 'test_img_r10': 84.21031587365054, 'test_img_r_mean': 69.10302545648408, 'test_r_mean': 74.96484606157537, 'epoch': 6, 'best_epoch': 5}
KD:False
Train Epoch: [7]  [    0/17710]  eta: 5:00:42  lr: 0.00000117  loss: 2.6990  time: 1.0188  data: 0.2533  max mem: 65458
KD is False
Train Epoch: [7]  [ 5000/17710]  eta: 1:49:25  lr: 0.00000117  loss: 1.5823  time: 0.5043  data: 0.0001  max mem: 65458
Train Epoch: [7]  [10000/17710]  eta: 1:06:12  lr: 0.00000117  loss: 1.8230  time: 0.4957  data: 0.0001  max mem: 65458
Train Epoch: [7]  [15000/17710]  eta: 0:23:15  lr: 0.00000117  loss: 3.3954  time: 0.5251  data: 0.0001  max mem: 65458
Train Epoch: [7]  [17709/17710]  eta: 0:00:00  lr: 0.00000117  loss: 1.9706  time: 0.5078  data: 0.0006  max mem: 65458
Train Epoch: [7] Total time: 2:31:59 (0.5150 s / it)
Averaged stats: lr: 0.0000  loss: 2.4356
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0714
Text_CKA_Similarity: 0.4152
Image_Cosine_Similarity: 0.1038
Image_CKA_Similarity: 0.6447
sim_matrix_pearson_correlation: 0.5449
{'txt_r1': 64.28, 'txt_r5': 87.8, 'txt_r10': 93.88, 'txt_r_mean': 81.98666666666666, 'img_r1': 48.36465413834466, 'img_r5': 75.7936825269892, 'img_r10': 84.2063174730108, 'img_r_mean': 69.45488471278155, 'r_mean': 75.7207756897241}
LOG:  {'train_lr': '0.000', 'train_loss': '2.436', 'val_txt_r1': 64.28, 'val_txt_r5': 87.8, 'val_txt_r10': 93.88, 'val_txt_r_mean': 81.98666666666666, 'val_img_r1': 48.36465413834466, 'val_img_r5': 75.7936825269892, 'val_img_r10': 84.2063174730108, 'val_img_r_mean': 69.45488471278155, 'val_r_mean': 75.7207756897241, 'test_txt_r1': 62.72, 'test_txt_r5': 86.66, 'test_txt_r10': 93.1, 'test_txt_r_mean': 80.82666666666667, 'test_img_r1': 47.524990003998404, 'test_img_r5': 75.57377049180327, 'test_img_r10': 84.21031587365054, 'test_img_r_mean': 69.10302545648408, 'test_r_mean': 74.96484606157537, 'epoch': 7, 'best_epoch': 5}
KD:False
Train Epoch: [8]  [    0/17710]  eta: 4:38:41  lr: 0.00000030  loss: 2.0528  time: 0.9442  data: 0.2682  max mem: 65458
KD is False
Train Epoch: [8]  [ 5000/17710]  eta: 1:48:55  lr: 0.00000030  loss: 2.3506  time: 0.5079  data: 0.0001  max mem: 65458
Train Epoch: [8]  [10000/17710]  eta: 1:06:02  lr: 0.00000030  loss: 2.9670  time: 0.5096  data: 0.0001  max mem: 65458
Train Epoch: [8]  [15000/17710]  eta: 0:23:09  lr: 0.00000030  loss: 2.1803  time: 0.5078  data: 0.0001  max mem: 65458
Train Epoch: [8]  [17709/17710]  eta: 0:00:00  lr: 0.00000030  loss: 2.3237  time: 0.4969  data: 0.0006  max mem: 65458
Train Epoch: [8] Total time: 2:31:26 (0.5131 s / it)
Averaged stats: lr: 0.0000  loss: 2.3882
Computing features for evaluation...
Computing features for evaluation...
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0299
Text_CKA_Similarity: 0.4045
Image_Cosine_Similarity: 0.1039
Image_CKA_Similarity: 0.6313
sim_matrix_pearson_correlation: 0.5357
{'txt_r1': 64.1, 'txt_r5': 87.72, 'txt_r10': 93.84, 'txt_r_mean': 81.88666666666667, 'img_r1': 48.220711715313875, 'img_r5': 75.53378648540584, 'img_r10': 84.04238304678128, 'img_r_mean': 69.26562708250033, 'r_mean': 75.5761468745835}
LOG:  {'train_lr': '0.000', 'train_loss': '2.388', 'val_txt_r1': 64.1, 'val_txt_r5': 87.72, 'val_txt_r10': 93.84, 'val_txt_r_mean': 81.88666666666667, 'val_img_r1': 48.220711715313875, 'val_img_r5': 75.53378648540584, 'val_img_r10': 84.04238304678128, 'val_img_r_mean': 69.26562708250033, 'val_r_mean': 75.5761468745835, 'test_txt_r1': 62.72, 'test_txt_r5': 86.66, 'test_txt_r10': 93.1, 'test_txt_r_mean': 80.82666666666667, 'test_img_r1': 47.524990003998404, 'test_img_r5': 75.57377049180327, 'test_img_r10': 84.21031587365054, 'test_img_r_mean': 69.10302545648408, 'test_r_mean': 74.96484606157537, 'epoch': 8, 'best_epoch': 5}
