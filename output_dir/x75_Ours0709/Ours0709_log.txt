| distributed init (rank 1, word 4): env://
| distributed init (rank 2, word 4): env://
| distributed init (rank 3, word 4): env://
| distributed init (rank 0, word 4): env://
node21:1940261:1940261 [0] NCCL INFO Bootstrap : Using eno1:192.168.170.21<0>
node21:1940261:1940261 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node21:1940261:1940261 [0] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.21<0> [1]eno2:10.0.0.21<0> [2]veth19f1e29:fe80::9cb6:ccff:fee2:96b3%veth19f1e29<0>
node21:1940261:1940261 [0] NCCL INFO Using network Socket
NCCL version 2.10.3+cuda11.3
node21:1940263:1940263 [2] NCCL INFO Bootstrap : Using eno1:192.168.170.21<0>
node21:1940264:1940264 [3] NCCL INFO Bootstrap : Using eno1:192.168.170.21<0>
node21:1940263:1940263 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node21:1940263:1940263 [2] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.21<0> [1]eno2:10.0.0.21<0> [2]veth19f1e29:fe80::9cb6:ccff:fee2:96b3%veth19f1e29<0>
node21:1940263:1940263 [2] NCCL INFO Using network Socket
node21:1940264:1940264 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node21:1940264:1940264 [3] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.21<0> [1]eno2:10.0.0.21<0> [2]veth19f1e29:fe80::9cb6:ccff:fee2:96b3%veth19f1e29<0>
node21:1940264:1940264 [3] NCCL INFO Using network Socket
node21:1940262:1940262 [1] NCCL INFO Bootstrap : Using eno1:192.168.170.21<0>
node21:1940262:1940262 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
node21:1940262:1940262 [1] NCCL INFO NET/Socket : Using [0]eno1:192.168.170.21<0> [1]eno2:10.0.0.21<0> [2]veth19f1e29:fe80::9cb6:ccff:fee2:96b3%veth19f1e29<0>
node21:1940262:1940262 [1] NCCL INFO Using network Socket
node21:1940262:1940313 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
node21:1940261:1940310 [0] NCCL INFO Channel 00/02 :    0   1   2   3
node21:1940262:1940313 [1] NCCL INFO Setting affinity for GPU 1 to ff,ff000000,0000ffff
node21:1940261:1940310 [0] NCCL INFO Channel 01/02 :    0   1   2   3
node21:1940264:1940312 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
node21:1940261:1940310 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
node21:1940264:1940312 [3] NCCL INFO Setting affinity for GPU 3 to 0f,fff00000,00000fff,f0000000
node21:1940261:1940310 [0] NCCL INFO Setting affinity for GPU 0 to ff,ff000000,0000ffff
node21:1940263:1940311 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
node21:1940263:1940311 [2] NCCL INFO Setting affinity for GPU 2 to 0f,fff00000,00000fff,f0000000
node21:1940263:1940311 [2] NCCL INFO Channel 00 : 2[b1000] -> 3[ca000] via direct shared memory
node21:1940263:1940311 [2] NCCL INFO Channel 01 : 2[b1000] -> 3[ca000] via direct shared memory
node21:1940264:1940312 [3] NCCL INFO Channel 00 : 3[ca000] -> 0[31000] via direct shared memory
node21:1940264:1940312 [3] NCCL INFO Channel 01 : 3[ca000] -> 0[31000] via direct shared memory
node21:1940261:1940310 [0] NCCL INFO Channel 00 : 0[31000] -> 1[4b000] via direct shared memory
node21:1940261:1940310 [0] NCCL INFO Channel 01 : 0[31000] -> 1[4b000] via direct shared memory
node21:1940262:1940313 [1] NCCL INFO Channel 00 : 1[4b000] -> 2[b1000] via direct shared memory
node21:1940262:1940313 [1] NCCL INFO Channel 01 : 1[4b000] -> 2[b1000] via direct shared memory
node21:1940264:1940312 [3] NCCL INFO Connected all rings
node21:1940264:1940312 [3] NCCL INFO Channel 00 : 3[ca000] -> 2[b1000] via direct shared memory
node21:1940263:1940311 [2] NCCL INFO Connected all rings
node21:1940264:1940312 [3] NCCL INFO Channel 01 : 3[ca000] -> 2[b1000] via direct shared memory
node21:1940261:1940310 [0] NCCL INFO Connected all rings
node21:1940262:1940313 [1] NCCL INFO Connected all rings
node21:1940263:1940311 [2] NCCL INFO Channel 00 : 2[b1000] -> 1[4b000] via direct shared memory
node21:1940263:1940311 [2] NCCL INFO Channel 01 : 2[b1000] -> 1[4b000] via direct shared memory
node21:1940264:1940312 [3] NCCL INFO Connected all trees
node21:1940264:1940312 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node21:1940264:1940312 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node21:1940262:1940313 [1] NCCL INFO Channel 00 : 1[4b000] -> 0[31000] via direct shared memory
node21:1940262:1940313 [1] NCCL INFO Channel 01 : 1[4b000] -> 0[31000] via direct shared memory
node21:1940261:1940310 [0] NCCL INFO Connected all trees
node21:1940261:1940310 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node21:1940261:1940310 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node21:1940263:1940311 [2] NCCL INFO Connected all trees
node21:1940263:1940311 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node21:1940263:1940311 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node21:1940262:1940313 [1] NCCL INFO Connected all trees
node21:1940262:1940313 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
node21:1940262:1940313 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node21:1940263:1940311 [2] NCCL INFO comm 0x70ea80003070 rank 2 nranks 4 cudaDev 2 busId b1000 - Init COMPLETE
node21:1940262:1940313 [1] NCCL INFO comm 0x7db370003070 rank 1 nranks 4 cudaDev 1 busId 4b000 - Init COMPLETE
node21:1940264:1940312 [3] NCCL INFO comm 0x7af708003070 rank 3 nranks 4 cudaDev 3 busId ca000 - Init COMPLETE
node21:1940261:1940310 [0] NCCL INFO comm 0x7cc418003070 rank 0 nranks 4 cudaDev 0 busId 31000 - Init COMPLETE
node21:1940261:1940261 [0] NCCL INFO Launch mode Parallel
Target compression ratio: 75.0%
Creating retrieval dataset
Using downloaded and verified file: annotation/coco_karpathy_train.json
Using downloaded and verified file: annotation/coco_karpathy_val.json
Using downloaded and verified file: annotation/coco_karpathy_test.json
Creating model for searching
VisionTransformerを作成
VisionTransformerを作成
teacher_model evaluation
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.373996514710598e-05
max_val 5.066959420219064e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.521912731230259e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.5799424949800596e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
do itm_eval
test_result_teacher {'txt_r1': 71.56, 'txt_r5': 90.84, 'txt_r10': 95.4, 'txt_r_mean': 85.93333333333334, 'img_r1': 56.837265093962415, 'img_r5': 80.67572970811675, 'img_r10': 87.65293882447021, 'img_r_mean': 75.05531120884979, 'r_mean': 80.49432227109156}
KD True
Start searching
KD:True
mask_update_step
Current compression ratio of attn:  tensor(0., device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0., device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  5.543308009082199e-06
Search Epoch: [0]  [    0/23614]  eta: 1 day, 16:49:19  lr: 0.00001000  loss: 18.0453  loss_ita: 4.5285  loss_sp_attn: 6.7584  loss_sp_mlp: 6.7584  time: 6.2234  data: 1.0678  max mem: 34277
mask_update_step
Current compression ratio of attn:  tensor(1.9073e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(1.3709e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0011142046580675021
mask_update_step
Current compression ratio of attn:  tensor(8.8811e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(4.3511e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0022228635726734133
mask_update_step
Current compression ratio of attn:  tensor(2.4974e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(7.6890e-06, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0033315176300535753
mask_update_step
Current compression ratio of attn:  tensor(4.8816e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(1.2338e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.004440164407657824
mask_update_step
Current compression ratio of attn:  tensor(7.3850e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(1.8954e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.005548801482967812
mask_update_step
Current compression ratio of attn:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(2.4378e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0066574264334748005
mask_update_step
Current compression ratio of attn:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(3.6180e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.007766036836697048
mask_update_step
Current compression ratio of attn:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(4.9651e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.008874630270188132
mask_update_step
Current compression ratio of attn:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(6.5029e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.00998320431153695
mask_update_step
Current compression ratio of attn:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(7.5102e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01109175653837371
mask_update_step
Current compression ratio of attn:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(9.6023e-05, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01220028452837808
mask_update_step
Current compression ratio of attn:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.013308785859282368
mask_update_step
Current compression ratio of attn:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.014417258108876754
mask_update_step
Current compression ratio of attn:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.015525698855014536
mask_update_step
Current compression ratio of attn:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.01663410567561832
mask_update_step
Current compression ratio of attn:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.017742476148685883
mask_update_step
Current compression ratio of attn:  tensor(0.0009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.018850807852292463
mask_update_step
Current compression ratio of attn:  tensor(0.0010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.019959098364599588
mask_update_step
Current compression ratio of attn:  tensor(0.0011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.021067345263857545
mask_update_step
Current compression ratio of attn:  tensor(0.0012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.022175546128412927
mask_update_step
Current compression ratio of attn:  tensor(0.0013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.023283698536712187
mask_update_step
Current compression ratio of attn:  tensor(0.0014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.024391800067308865
mask_update_step
Current compression ratio of attn:  tensor(0.0016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.02549984829886539
mask_update_step
Current compression ratio of attn:  tensor(0.0017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.026607840810163978
mask_update_step
Current compression ratio of attn:  tensor(0.0018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0005, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.027715775180104932
Search Epoch: [0]  [ 5000/23614]  eta: 5:22:15  lr: 0.00001000  loss: 18.5427  loss_ita: 5.0406  loss_sp_attn: 6.7470  loss_sp_mlp: 6.7552  time: 1.0847  data: 0.0002  max mem: 53486
mask_update_step
Current compression ratio of attn:  tensor(0.0020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.028823648987717908
mask_update_step
Current compression ratio of attn:  tensor(0.0021, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.029931459812165072
mask_update_step
Current compression ratio of attn:  tensor(0.0023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.031039205232744744
mask_update_step
Current compression ratio of attn:  tensor(0.0024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0007, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.032146882828899215
mask_update_step
Current compression ratio of attn:  tensor(0.0026, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0008, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.033254490180218844
mask_update_step
Current compression ratio of attn:  tensor(0.0027, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03436202486644678
mask_update_step
Current compression ratio of attn:  tensor(0.0029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03546948446748646
mask_update_step
Current compression ratio of attn:  tensor(0.0031, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.036576866563403185
mask_update_step
Current compression ratio of attn:  tensor(0.0033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.037684168734433754
mask_update_step
Current compression ratio of attn:  tensor(0.0035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0011, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.03879138856098856
mask_update_step
Current compression ratio of attn:  tensor(0.0036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.039898523623658144
mask_update_step
Current compression ratio of attn:  tensor(0.0038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04100557150321799
mask_update_step
Current compression ratio of attn:  tensor(0.0040, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0013, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.042112529780634525
mask_update_step
Current compression ratio of attn:  tensor(0.0042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0014, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04321939603706959
mask_update_step
Current compression ratio of attn:  tensor(0.0044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0015, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0443261678538861
mask_update_step
Current compression ratio of attn:  tensor(0.0046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04543284281265395
mask_update_step
Current compression ratio of attn:  tensor(0.0048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04653941849515391
mask_update_step
Current compression ratio of attn:  tensor(0.0050, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04764589248338426
mask_update_step
Current compression ratio of attn:  tensor(0.0052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0019, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.04875226235956505
mask_update_step
Current compression ratio of attn:  tensor(0.0055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0498585257061438
mask_update_step
Current compression ratio of attn:  tensor(0.0057, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0021, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05096468010580133
mask_update_step
Current compression ratio of attn:  tensor(0.0059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05207072314145622
mask_update_step
Current compression ratio of attn:  tensor(0.0061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.053176652396270396
mask_update_step
Current compression ratio of attn:  tensor(0.0063, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.054282465453654435
mask_update_step
Current compression ratio of attn:  tensor(0.0066, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0026, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05538815989727243
Search Epoch: [0]  [10000/23614]  eta: 3:59:16  lr: 0.00001000  loss: 18.5908  loss_ita: 5.1334  loss_sp_attn: 6.7155  loss_sp_mlp: 6.7419  time: 1.0826  data: 0.0002  max mem: 53486
mask_update_step
Current compression ratio of attn:  tensor(0.0068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0027, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0564937333110484
mask_update_step
Current compression ratio of attn:  tensor(0.0071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05759918327917027
mask_update_step
Current compression ratio of attn:  tensor(0.0074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05870450738609585
mask_update_step
Current compression ratio of attn:  tensor(0.0075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0031, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.05980970321655843
mask_update_step
Current compression ratio of attn:  tensor(0.0079, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06091476835557037
mask_update_step
Current compression ratio of attn:  tensor(0.0082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06201970038843113
mask_update_step
Current compression ratio of attn:  tensor(0.0084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0631244969007301
mask_update_step
Current compression ratio of attn:  tensor(0.0087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06422915547835281
mask_update_step
Current compression ratio of attn:  tensor(0.0091, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06533367370748645
mask_update_step
Current compression ratio of attn:  tensor(0.0093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0038, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06643804917462523
mask_update_step
Current compression ratio of attn:  tensor(0.0096, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0039, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06754227946657426
mask_update_step
Current compression ratio of attn:  tensor(0.0099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06864636217045694
mask_update_step
Current compression ratio of attn:  tensor(0.0103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.06975029487371878
mask_update_step
Current compression ratio of attn:  tensor(0.0105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0708540751641328
mask_update_step
Current compression ratio of attn:  tensor(0.0108, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0045, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07195770062980542
mask_update_step
Current compression ratio of attn:  tensor(0.0112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07306116885918139
mask_update_step
Current compression ratio of attn:  tensor(0.0115, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07416447744104854
mask_update_step
Current compression ratio of attn:  tensor(0.0119, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07526762396454417
mask_update_step
Current compression ratio of attn:  tensor(0.0124, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0050, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07637060601915938
mask_update_step
Current compression ratio of attn:  tensor(0.0126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0052, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07747342119474471
mask_update_step
Current compression ratio of attn:  tensor(0.0131, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07857606708151532
mask_update_step
Current compression ratio of attn:  tensor(0.0133, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.07967854127005616
mask_update_step
Current compression ratio of attn:  tensor(0.0138, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08078084135132789
mask_update_step
Current compression ratio of attn:  tensor(0.0141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0057, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08188296491667083
mask_update_step
Current compression ratio of attn:  tensor(0.0146, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08298490955781171
Search Epoch: [0]  [15000/23614]  eta: 2:32:54  lr: 0.00001000  loss: 18.2381  loss_ita: 4.8556  loss_sp_attn: 6.6630  loss_sp_mlp: 6.7195  time: 1.1023  data: 0.0002  max mem: 53486
mask_update_step
Current compression ratio of attn:  tensor(0.0149, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08408667286686772
mask_update_step
Current compression ratio of attn:  tensor(0.0152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0062, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08518825243635278
mask_update_step
Current compression ratio of attn:  tensor(0.0156, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0064, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08628964585918168
mask_update_step
Current compression ratio of attn:  tensor(0.0161, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08739085072867661
mask_update_step
Current compression ratio of attn:  tensor(0.0165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08849186463857123
mask_update_step
Current compression ratio of attn:  tensor(0.0170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.08959268518301684
mask_update_step
Current compression ratio of attn:  tensor(0.0173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09069330995658728
mask_update_step
Current compression ratio of attn:  tensor(0.0177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0072, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09179373655428373
mask_update_step
Current compression ratio of attn:  tensor(0.0183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0928939625715408
mask_update_step
Current compression ratio of attn:  tensor(0.0187, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0076, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0939939856042315
mask_update_step
Current compression ratio of attn:  tensor(0.0190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0078, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09509380324867195
mask_update_step
Current compression ratio of attn:  tensor(0.0197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0078, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09619341310162738
mask_update_step
Current compression ratio of attn:  tensor(0.0201, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0080, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.0972928127603169
mask_update_step
Current compression ratio of attn:  tensor(0.0205, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09839199982241917
mask_update_step
Current compression ratio of attn:  tensor(0.0210, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.09949097188607729
mask_update_step
Current compression ratio of attn:  tensor(0.0215, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1005897265499039
mask_update_step
Current compression ratio of attn:  tensor(0.0219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10168826141298701
mask_update_step
Current compression ratio of attn:  tensor(0.0225, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10278657407489494
mask_update_step
Current compression ratio of attn:  tensor(0.0228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10388466213568115
mask_update_step
Current compression ratio of attn:  tensor(0.0234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10498252319589027
mask_update_step
Current compression ratio of attn:  tensor(0.0238, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0096, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10608015485656286
mask_update_step
Current compression ratio of attn:  tensor(0.0246, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0096, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10717755471924056
mask_update_step
Current compression ratio of attn:  tensor(0.0249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10827472038597193
mask_update_step
Current compression ratio of attn:  tensor(0.0254, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0101, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.10937164945931675
mask_update_step
Current compression ratio of attn:  tensor(0.0261, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0102, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11046833954235236
Search Epoch: [0]  [20000/23614]  eta: 1:04:16  lr: 0.00001000  loss: 18.3521  loss_ita: 5.0757  loss_sp_attn: 6.5864  loss_sp_mlp: 6.6900  time: 1.0901  data: 0.0002  max mem: 53486
mask_update_step
Current compression ratio of attn:  tensor(0.0264, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11156478823867766
mask_update_step
Current compression ratio of attn:  tensor(0.0270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0107, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11266099315241962
mask_update_step
Current compression ratio of attn:  tensor(0.0276, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0109, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11375695188823756
mask_update_step
Current compression ratio of attn:  tensor(0.0279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11485266205132884
mask_update_step
Current compression ratio of attn:  tensor(0.0286, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0114, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11594812124743392
mask_update_step
Current compression ratio of attn:  tensor(0.0292, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0115, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1170433270828416
mask_update_step
Current compression ratio of attn:  tensor(0.0295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0119, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11813827716439465
mask_update_step
Current compression ratio of attn:  tensor(0.0300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.11923296909949424
mask_update_step
Current compression ratio of attn:  tensor(0.0307, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12032740049610599
mask_update_step
Current compression ratio of attn:  tensor(0.0312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1214215689627645
mask_update_step
Current compression ratio of attn:  tensor(0.0318, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0128, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12251547210857903
mask_update_step
Current compression ratio of attn:  tensor(0.0326, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0128, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12360910754323876
mask_update_step
Current compression ratio of attn:  tensor(0.0325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12470247287701762
mask_update_step
Current compression ratio of attn:  tensor(0.0335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.12579556572078
mask_update_step
Current compression ratio of attn:  tensor(0.0340, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1268883836859854
mask_update_step
Current compression ratio of attn:  tensor(0.0345, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1279809243846942
mask_update_step
Current compression ratio of attn:  tensor(0.0352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1290731854295725
mask_update_step
Current compression ratio of attn:  tensor(0.0356, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0146, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1301651644338976
Search Epoch: [0]  [23613/23614]  eta: 0:00:01  lr: 0.00001000  loss: 19.0802  loss_ita: 5.9027  loss_sp_attn: 6.5176  loss_sp_mlp: 6.6599  time: 1.1001  data: 0.0005  max mem: 53486
Search Epoch: [0] Total time: 7:00:36 (1.0687 s / it)
Averaged stats: lr: 0.0000  loss: 19.1234  loss_ita: 5.7192  loss_sp_attn: 6.6778  loss_sp_mlp: 6.7264
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
do itm_eval
search_result {'txt_r1': 69.4, 'txt_r5': 90.08, 'txt_r10': 94.94, 'txt_r_mean': 84.80666666666667, 'img_r1': 56.91323470611756, 'img_r5': 80.9516193522591, 'img_r10': 88.29668132746902, 'img_r_mean': 75.38717846194857, 'r_mean': 80.09692256430762}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.7225
Text_CKA_Similarity: 0.8855
Image_Cosine_Similarity: 0.5572
Image_CKA_Similarity: 0.9582
sim_matrix_pearson_correlation: 0.9687
model_search_0.pth saved
KD:True
Search Epoch: [1]  [    0/23614]  eta: 1 day, 16:50:12  lr: 0.00001000  loss: 20.2900  loss_ita: 7.1126  loss_sp_attn: 6.5176  loss_sp_mlp: 6.6599  time: 6.2257  data: 0.2131  max mem: 53486
mask_update_step
Current compression ratio of attn:  tensor(0.0362, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0149, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13125685901156298
mask_update_step
Current compression ratio of attn:  tensor(0.0368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13234826677708367
mask_update_step
Current compression ratio of attn:  tensor(0.0373, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0154, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1334393853456016
mask_update_step
Current compression ratio of attn:  tensor(0.0380, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0156, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13453021233289025
mask_update_step
Current compression ratio of attn:  tensor(0.0388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0157, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13562074535536062
mask_update_step
Current compression ratio of attn:  tensor(0.0395, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1367109820300657
mask_update_step
Current compression ratio of attn:  tensor(0.0399, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1378009199747064
mask_update_step
Current compression ratio of attn:  tensor(0.0408, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13889055680763615
mask_update_step
Current compression ratio of attn:  tensor(0.0412, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0168, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.13997989014786633
mask_update_step
Current compression ratio of attn:  tensor(0.0416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1410689176150716
mask_update_step
Current compression ratio of attn:  tensor(0.0424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0174, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14215763682959515
mask_update_step
Current compression ratio of attn:  tensor(0.0430, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14324604541245328
mask_update_step
Current compression ratio of attn:  tensor(0.0434, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0182, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14433414098534142
mask_update_step
Current compression ratio of attn:  tensor(0.0443, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14542192117063896
mask_update_step
Current compression ratio of attn:  tensor(0.0449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0187, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1465093835914143
mask_update_step
Current compression ratio of attn:  tensor(0.0454, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0190, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14759652587143018
mask_update_step
Current compression ratio of attn:  tensor(0.0463, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0192, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14868334563514912
mask_update_step
Current compression ratio of attn:  tensor(0.0469, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0194, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.14976984050773812
mask_update_step
Current compression ratio of attn:  tensor(0.0477, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1508560081150742
mask_update_step
Current compression ratio of attn:  tensor(0.0483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0200, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15194184608374958
mask_update_step
Current compression ratio of attn:  tensor(0.0489, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0204, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1530273520410766
mask_update_step
Current compression ratio of attn:  tensor(0.0498, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0205, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15411252361509317
mask_update_step
Current compression ratio of attn:  tensor(0.0503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0209, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15519735843456794
mask_update_step
Current compression ratio of attn:  tensor(0.0507, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0214, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15628185412900542
mask_update_step
Current compression ratio of attn:  tensor(0.0514, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1573660083286509
Search Epoch: [1]  [ 5000/23614]  eta: 5:38:36  lr: 0.00001000  loss: 18.9885  loss_ita: 5.9659  loss_sp_attn: 6.4113  loss_sp_mlp: 6.6113  time: 1.1067  data: 0.0002  max mem: 55117
mask_update_step
Current compression ratio of attn:  tensor(0.0524, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.15844981866449628
mask_update_step
Current compression ratio of attn:  tensor(0.0532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1595332827682845
mask_update_step
Current compression ratio of attn:  tensor(0.0541, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0223, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16061639827251514
mask_update_step
Current compression ratio of attn:  tensor(0.0548, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0226, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1616991628104497
mask_update_step
Current compression ratio of attn:  tensor(0.0557, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0228, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16278157401611626
mask_update_step
Current compression ratio of attn:  tensor(0.0559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0233, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16386362952431527
mask_update_step
Current compression ratio of attn:  tensor(0.0574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0233, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16494532697062428
mask_update_step
Current compression ratio of attn:  tensor(0.0577, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0238, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1660266639914033
mask_update_step
Current compression ratio of attn:  tensor(0.0585, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0241, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16710763822379987
mask_update_step
Current compression ratio of attn:  tensor(0.0593, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0244, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16818824730575416
mask_update_step
Current compression ratio of attn:  tensor(0.0600, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.16926848887600462
mask_update_step
Current compression ratio of attn:  tensor(0.0609, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0250, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17034836057409225
mask_update_step
Current compression ratio of attn:  tensor(0.0615, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0255, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17142786004036664
mask_update_step
Current compression ratio of attn:  tensor(0.0626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17250698491599056
mask_update_step
Current compression ratio of attn:  tensor(0.0631, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0261, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17358573284294548
mask_update_step
Current compression ratio of attn:  tensor(0.0641, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17466410146403633
mask_update_step
Current compression ratio of attn:  tensor(0.0650, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0266, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1757420884228971
mask_update_step
Current compression ratio of attn:  tensor(0.0657, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0269, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17681969136399545
mask_update_step
Current compression ratio of attn:  tensor(0.0664, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1778969079326385
mask_update_step
Current compression ratio of attn:  tensor(0.0675, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0275, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.17897373577497744
mask_update_step
Current compression ratio of attn:  tensor(0.0682, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0278, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1800501725380131
mask_update_step
Current compression ratio of attn:  tensor(0.0690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0282, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18112621586960037
mask_update_step
Current compression ratio of attn:  tensor(0.0693, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0289, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1822018634184544
mask_update_step
Current compression ratio of attn:  tensor(0.0700, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0293, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18327711283415482
mask_update_step
Current compression ratio of attn:  tensor(0.0712, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0294, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18435196176715132
Search Epoch: [1]  [10000/23614]  eta: 4:08:13  lr: 0.00001000  loss: 19.2155  loss_ita: 6.3785  loss_sp_attn: 6.2775  loss_sp_mlp: 6.5596  time: 1.0623  data: 0.0002  max mem: 55117
mask_update_step
Current compression ratio of attn:  tensor(0.0719, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0299, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1854264078687689
mask_update_step
Current compression ratio of attn:  tensor(0.0736, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0296, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18650044879121244
mask_update_step
Current compression ratio of attn:  tensor(0.0735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0306, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18757408218757243
mask_update_step
Current compression ratio of attn:  tensor(0.0747, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0307, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18864730571182972
mask_update_step
Current compression ratio of attn:  tensor(0.0751, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0314, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.18972011701886093
mask_update_step
Current compression ratio of attn:  tensor(0.0761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0316, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19079251376444326
mask_update_step
Current compression ratio of attn:  tensor(0.0773, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0318, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1918644936052598
mask_update_step
Current compression ratio of attn:  tensor(0.0775, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19293605419890486
mask_update_step
Current compression ratio of attn:  tensor(0.0789, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19400719320388848
mask_update_step
Current compression ratio of attn:  tensor(0.0794, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0332, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19507790827964222
mask_update_step
Current compression ratio of attn:  tensor(0.0806, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0333, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19614819708652392
mask_update_step
Current compression ratio of attn:  tensor(0.0813, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0338, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19721805728582262
mask_update_step
Current compression ratio of attn:  tensor(0.0822, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0341, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.19828748653976436
mask_update_step
Current compression ratio of attn:  tensor(0.0831, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0345, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.1993564825115165
mask_update_step
Current compression ratio of attn:  tensor(0.0840, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0348, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20042504286519325
mask_update_step
Current compression ratio of attn:  tensor(0.0851, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0351, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2014931652658608
mask_update_step
Current compression ratio of attn:  tensor(0.0863, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0353, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20256084737954222
mask_update_step
Current compression ratio of attn:  tensor(0.0865, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0361, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20362808687322276
mask_update_step
Current compression ratio of attn:  tensor(0.0877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0363, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2046948814148547
mask_update_step
Current compression ratio of attn:  tensor(0.0888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0365, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20576122867336266
mask_update_step
Current compression ratio of attn:  tensor(0.0895, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0370, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.20682712631864875
mask_update_step
Current compression ratio of attn:  tensor(0.0900, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0378, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2078925720215974
mask_update_step
Current compression ratio of attn:  tensor(0.0902, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0385, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2089575634540805
mask_update_step
Current compression ratio of attn:  tensor(0.0915, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21002209828896282
mask_update_step
Current compression ratio of attn:  tensor(0.0924, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0392, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21108617420010667
Search Epoch: [1]  [15000/23614]  eta: 2:36:26  lr: 0.00001000  loss: 18.3337  loss_ita: 5.7057  loss_sp_attn: 6.1343  loss_sp_mlp: 6.4937  time: 1.0950  data: 0.0002  max mem: 55117
mask_update_step
Current compression ratio of attn:  tensor(0.0937, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0393, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21214978886237731
mask_update_step
Current compression ratio of attn:  tensor(0.0951, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0394, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21321293995164778
mask_update_step
Current compression ratio of attn:  tensor(0.0950, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0404, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21427562514480392
mask_update_step
Current compression ratio of attn:  tensor(0.0955, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0412, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21533784211975
mask_update_step
Current compression ratio of attn:  tensor(0.0968, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0413, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21639958855541316
mask_update_step
Current compression ratio of attn:  tensor(0.0974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0419, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2174608621317487
mask_update_step
Current compression ratio of attn:  tensor(0.0988, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0421, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21852166052974534
mask_update_step
Current compression ratio of attn:  tensor(0.0995, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0427, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.21958198143142985
mask_update_step
Current compression ratio of attn:  tensor(0.1000, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0434, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22064182251987263
mask_update_step
Current compression ratio of attn:  tensor(0.1012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0436, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2217011814791925
mask_update_step
Current compression ratio of attn:  tensor(0.1020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0441, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22276005599456172
mask_update_step
Current compression ratio of attn:  tensor(0.1031, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0445, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22381844375221108
mask_update_step
Current compression ratio of attn:  tensor(0.1044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0447, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2248763424394351
mask_update_step
Current compression ratio of attn:  tensor(0.1046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.225933749744597
mask_update_step
Current compression ratio of attn:  tensor(0.1061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0457, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22699066335713364
mask_update_step
Current compression ratio of attn:  tensor(0.1060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0468, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22804708096756066
mask_update_step
Current compression ratio of attn:  tensor(0.1067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.22910300026747746
mask_update_step
Current compression ratio of attn:  tensor(0.1075, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0480, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23015841894957256
mask_update_step
Current compression ratio of attn:  tensor(0.1085, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23121333470762812
mask_update_step
Current compression ratio of attn:  tensor(0.1097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0488, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23226774523652535
mask_update_step
Current compression ratio of attn:  tensor(0.1103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0494, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2333216482322495
mask_update_step
Current compression ratio of attn:  tensor(0.1116, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0497, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23437504139189486
mask_update_step
Current compression ratio of attn:  tensor(0.1125, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23542792241366955
mask_update_step
Current compression ratio of attn:  tensor(0.1133, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0507, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2364802889969011
mask_update_step
Current compression ratio of attn:  tensor(0.1140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0514, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23753213884204089
Search Epoch: [1]  [20000/23614]  eta: 1:05:30  lr: 0.00001000  loss: 18.4095  loss_ita: 6.0103  loss_sp_attn: 5.9882  loss_sp_mlp: 6.4110  time: 1.0984  data: 0.0002  max mem: 55118
mask_update_step
Current compression ratio of attn:  tensor(0.1146, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0521, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23858346965066946
mask_update_step
Current compression ratio of attn:  tensor(0.1148, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0531, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.23963427912550184
mask_update_step
Current compression ratio of attn:  tensor(0.1177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24068456497039162
mask_update_step
Current compression ratio of attn:  tensor(0.1181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24173432489033714
mask_update_step
Current compression ratio of attn:  tensor(0.1184, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0540, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24278355659148582
mask_update_step
Current compression ratio of attn:  tensor(0.1201, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0541, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2438322577811391
mask_update_step
Current compression ratio of attn:  tensor(0.1206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0549, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2448804261677578
mask_update_step
Current compression ratio of attn:  tensor(0.1203, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0562, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2459280594609669
mask_update_step
Current compression ratio of attn:  tensor(0.1226, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24697515537156084
mask_update_step
Current compression ratio of attn:  tensor(0.1220, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0573, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2480217116115081
mask_update_step
Current compression ratio of attn:  tensor(0.1232, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.24906772589395645
mask_update_step
Current compression ratio of attn:  tensor(0.1230, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0590, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25011319593323783
mask_update_step
Current compression ratio of attn:  tensor(0.1246, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0592, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25115811944487365
mask_update_step
Current compression ratio of attn:  tensor(0.1249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0601, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25220249414557927
mask_update_step
Current compression ratio of attn:  tensor(0.1263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25324631775326945
mask_update_step
Current compression ratio of attn:  tensor(0.1282, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0604, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25428958798706314
mask_update_step
Current compression ratio of attn:  tensor(0.1277, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25533230256728834
mask_update_step
Current compression ratio of attn:  tensor(0.1295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2563744592154873
Search Epoch: [1]  [23613/23614]  eta: 0:00:01  lr: 0.00001000  loss: 18.5485  loss_ita: 6.3245  loss_sp_attn: 5.8830  loss_sp_mlp: 6.3410  time: 1.1127  data: 0.0003  max mem: 55118
Search Epoch: [1] Total time: 7:08:06 (1.0878 s / it)
Averaged stats: lr: 0.0000  loss: 18.4224  loss_ita: 5.6762  loss_sp_attn: 6.2200  loss_sp_mlp: 6.5262
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
do itm_eval
search_result {'txt_r1': 70.72, 'txt_r5': 91.1, 'txt_r10': 95.38, 'txt_r_mean': 85.73333333333333, 'img_r1': 56.21351459416233, 'img_r5': 80.53978408636546, 'img_r10': 87.65693722510996, 'img_r_mean': 74.80341196854592, 'r_mean': 80.26837265093963}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.6934
Text_CKA_Similarity: 0.9016
Image_Cosine_Similarity: 0.5298
Image_CKA_Similarity: 0.9223
sim_matrix_pearson_correlation: 0.9657
model_search_1.pth saved
KD:True
Search Epoch: [2]  [    0/23614]  eta: 12:51:26  lr: 0.00001000  loss: 18.4563  loss_ita: 6.2323  loss_sp_attn: 5.8830  loss_sp_mlp: 6.3410  time: 1.9601  data: 0.2116  max mem: 55118
mask_update_step
Current compression ratio of attn:  tensor(0.1312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0619, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2574160556544216
mask_update_step
Current compression ratio of attn:  tensor(0.1310, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0632, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2584570896080767
mask_update_step
Current compression ratio of attn:  tensor(0.1320, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0638, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.25949755880166714
mask_update_step
Current compression ratio of attn:  tensor(0.1324, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0647, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2605374609616418
mask_update_step
Current compression ratio of attn:  tensor(0.1335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0652, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2615767938156883
mask_update_step
Current compression ratio of attn:  tensor(0.1354, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0652, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2626155550927386
mask_update_step
Current compression ratio of attn:  tensor(0.1363, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0658, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2636537425229732
mask_update_step
Current compression ratio of attn:  tensor(0.1365, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0668, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2646913538378267
mask_update_step
Current compression ratio of attn:  tensor(0.1372, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26572838676999283
mask_update_step
Current compression ratio of attn:  tensor(0.1403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0669, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26676483905342885
mask_update_step
Current compression ratio of attn:  tensor(0.1398, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0684, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2678007084233609
mask_update_step
Current compression ratio of attn:  tensor(0.1403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0692, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2688359926162889
mask_update_step
Current compression ratio of attn:  tensor(0.1401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0706, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.26987068936999126
mask_update_step
Current compression ratio of attn:  tensor(0.1422, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0705, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2709047964235304
mask_update_step
Current compression ratio of attn:  tensor(0.1421, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0717, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.271938311517257
mask_update_step
Current compression ratio of attn:  tensor(0.1422, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0729, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2729712323928153
mask_update_step
Current compression ratio of attn:  tensor(0.1424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0740, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2740035567931479
mask_update_step
Current compression ratio of attn:  tensor(0.1436, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0745, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27503528246250114
mask_update_step
Current compression ratio of attn:  tensor(0.1412, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0772, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2760664071464292
mask_update_step
Current compression ratio of attn:  tensor(0.1470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0748, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27709692859179963
mask_update_step
Current compression ratio of attn:  tensor(0.1437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0781, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2781268445467983
mask_update_step
Current compression ratio of attn:  tensor(0.1468, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.27915615276093403
mask_update_step
Current compression ratio of attn:  tensor(0.1472, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0784, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28018485098504353
mask_update_step
Current compression ratio of attn:  tensor(0.1474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0796, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28121293697129657
mask_update_step
Current compression ratio of attn:  tensor(0.1470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0811, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28224040847320064
Search Epoch: [2]  [ 5000/23614]  eta: 5:37:31  lr: 0.00001000  loss: 17.1285  loss_ita: 5.1532  loss_sp_attn: 5.7649  loss_sp_mlp: 6.2104  time: 1.1247  data: 0.0002  max mem: 55125
mask_update_step
Current compression ratio of attn:  tensor(0.1472, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0822, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28326726324560597
mask_update_step
Current compression ratio of attn:  tensor(0.1491, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0823, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2842934990447105
mask_update_step
Current compression ratio of attn:  tensor(0.1456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0856, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2853191136280646
mask_update_step
Current compression ratio of attn:  tensor(0.1503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0841, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2863441047545761
mask_update_step
Current compression ratio of attn:  tensor(0.1495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0858, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28736847018451517
mask_update_step
Current compression ratio of attn:  tensor(0.1480, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0880, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28839220767951923
mask_update_step
Current compression ratio of attn:  tensor(0.1532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0860, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.28941531500259776
mask_update_step
Current compression ratio of attn:  tensor(0.1513, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0886, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2904377899181372
mask_update_step
Current compression ratio of attn:  tensor(0.1570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0863, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29145963019190596
mask_update_step
Current compression ratio of attn:  tensor(0.1533, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0898, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29248083359105925
mask_update_step
Current compression ratio of attn:  tensor(0.1576, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0885, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.293501397884144
mask_update_step
Current compression ratio of attn:  tensor(0.1517, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0934, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2945213208411032
mask_update_step
Current compression ratio of attn:  tensor(0.1597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0898, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2955406002332819
mask_update_step
Current compression ratio of attn:  tensor(0.1570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0927, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29655923383343086
mask_update_step
Current compression ratio of attn:  tensor(0.1603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0920, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29757721941571247
mask_update_step
Current compression ratio of attn:  tensor(0.1555, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.2985945547557046
mask_update_step
Current compression ratio of attn:  tensor(0.1611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0942, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.29961123763040637
mask_update_step
Current compression ratio of attn:  tensor(0.1614, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0952, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30062726581824245
mask_update_step
Current compression ratio of attn:  tensor(0.1627, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0958, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3016426370990682
mask_update_step
Current compression ratio of attn:  tensor(0.1615, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0978, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3026573492541742
mask_update_step
Current compression ratio of attn:  tensor(0.1619, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0989, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30367140006629145
mask_update_step
Current compression ratio of attn:  tensor(0.1626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.0998, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.304684787319596
mask_update_step
Current compression ratio of attn:  tensor(0.1643, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30569750879971386
mask_update_step
Current compression ratio of attn:  tensor(0.1619, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1029, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3067095622937261
mask_update_step
Current compression ratio of attn:  tensor(0.1653, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1021, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3077209455901728
Search Epoch: [2]  [10000/23614]  eta: 4:06:23  lr: 0.00001000  loss: 17.1564  loss_ita: 5.4467  loss_sp_attn: 5.6415  loss_sp_mlp: 6.0681  time: 1.0966  data: 0.0001  max mem: 55125
mask_update_step
Current compression ratio of attn:  tensor(0.1656, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3087316564790591
mask_update_step
Current compression ratio of attn:  tensor(0.1676, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.30974169275185925
mask_update_step
Current compression ratio of attn:  tensor(0.1701, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1032, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31075105220152144
mask_update_step
Current compression ratio of attn:  tensor(0.1687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3117597326224731
mask_update_step
Current compression ratio of attn:  tensor(0.1707, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31276773181062517
mask_update_step
Current compression ratio of attn:  tensor(0.1694, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31377504756337726
mask_update_step
Current compression ratio of attn:  tensor(0.1727, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31478167767962234
mask_update_step
Current compression ratio of attn:  tensor(0.1698, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1103, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31578761995975174
mask_update_step
Current compression ratio of attn:  tensor(0.1742, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3167928722056595
mask_update_step
Current compression ratio of attn:  tensor(0.1714, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1119, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3177974322207477
mask_update_step
Current compression ratio of attn:  tensor(0.1738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1119, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.318801297809931
mask_update_step
Current compression ratio of attn:  tensor(0.1738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1133, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.31980446677964136
mask_update_step
Current compression ratio of attn:  tensor(0.1756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.320806936937833
mask_update_step
Current compression ratio of attn:  tensor(0.1771, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3218087060939872
mask_update_step
Current compression ratio of attn:  tensor(0.1803, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1133, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3228097720591169
mask_update_step
Current compression ratio of attn:  tensor(0.1780, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32381013264577163
mask_update_step
Current compression ratio of attn:  tensor(0.1804, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3248097856680423
mask_update_step
Current compression ratio of attn:  tensor(0.1814, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1168, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3258087289415659
mask_update_step
Current compression ratio of attn:  tensor(0.1817, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1180, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32680696028353023
mask_update_step
Current compression ratio of attn:  tensor(0.1819, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1193, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32780447751267894
mask_update_step
Current compression ratio of attn:  tensor(0.1796, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.32880127844931595
mask_update_step
Current compression ratio of attn:  tensor(0.1826, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3297973609153103
mask_update_step
Current compression ratio of attn:  tensor(0.1838, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1224, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33079272273410126
mask_update_step
Current compression ratio of attn:  tensor(0.1834, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1241, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33178736173070256
mask_update_step
Current compression ratio of attn:  tensor(0.1855, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1241, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3327812757317074
Search Epoch: [2]  [15000/23614]  eta: 2:35:15  lr: 0.00001000  loss: 18.1135  loss_ita: 6.6890  loss_sp_attn: 5.5050  loss_sp_mlp: 5.9195  time: 1.0421  data: 0.0001  max mem: 55125
mask_update_step
Current compression ratio of attn:  tensor(0.1881, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33377446256529325
mask_update_step
Current compression ratio of attn:  tensor(0.1893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33476692006122655
mask_update_step
Current compression ratio of attn:  tensor(0.1883, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1268, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33575864605086736
mask_update_step
Current compression ratio of attn:  tensor(0.1886, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33674963836717414
mask_update_step
Current compression ratio of attn:  tensor(0.1908, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3377398948447087
mask_update_step
Current compression ratio of attn:  tensor(0.1907, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3387294133196405
mask_update_step
Current compression ratio of attn:  tensor(0.1946, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1286, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.33971819162975186
mask_update_step
Current compression ratio of attn:  tensor(0.1926, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34070622761444225
mask_update_step
Current compression ratio of attn:  tensor(0.1932, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1324, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34169351911473334
mask_update_step
Current compression ratio of attn:  tensor(0.1947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1328, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34268006397327355
mask_update_step
Current compression ratio of attn:  tensor(0.1977, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1324, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34366586003434274
mask_update_step
Current compression ratio of attn:  tensor(0.1945, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1358, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3446509051438571
mask_update_step
Current compression ratio of attn:  tensor(0.1970, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1357, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34563519714937374
mask_update_step
Current compression ratio of attn:  tensor(0.1962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3466187339000951
mask_update_step
Current compression ratio of attn:  tensor(0.1987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1375, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3476015132468745
mask_update_step
Current compression ratio of attn:  tensor(0.1973, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1399, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3485835330422198
mask_update_step
Current compression ratio of attn:  tensor(0.2041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1372, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.34956479114029865
mask_update_step
Current compression ratio of attn:  tensor(0.2033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1393, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35054528539694335
mask_update_step
Current compression ratio of attn:  tensor(0.2055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1394, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35152501366965494
mask_update_step
Current compression ratio of attn:  tensor(0.2024, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1428, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3525039738176086
mask_update_step
Current compression ratio of attn:  tensor(0.2060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1420, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35348216370165764
mask_update_step
Current compression ratio of attn:  tensor(0.2035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1450, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3544595811843386
mask_update_step
Current compression ratio of attn:  tensor(0.2082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3554362241298759
mask_update_step
Current compression ratio of attn:  tensor(0.2058, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1466, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3564120904041863
mask_update_step
Current compression ratio of attn:  tensor(0.2099, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3573871778748837
Search Epoch: [2]  [20000/23614]  eta: 1:05:13  lr: 0.00001000  loss: 18.1350  loss_ita: 7.0207  loss_sp_attn: 5.3397  loss_sp_mlp: 5.7746  time: 1.1079  data: 0.0002  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.2070, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1489, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.35836148441128385
mask_update_step
Current compression ratio of attn:  tensor(0.2123, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1469, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3593350078844088
mask_update_step
Current compression ratio of attn:  tensor(0.2112, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1493, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36030774616699185
mask_update_step
Current compression ratio of attn:  tensor(0.2151, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3612796971334819
mask_update_step
Current compression ratio of attn:  tensor(0.2136, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1508, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36225085866004836
mask_update_step
Current compression ratio of attn:  tensor(0.2144, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1519, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3632212286245856
mask_update_step
Current compression ratio of attn:  tensor(0.2135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1539, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3641908049067176
mask_update_step
Current compression ratio of attn:  tensor(0.2185, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36515958538780263
mask_update_step
Current compression ratio of attn:  tensor(0.2163, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1553, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36612756795093804
mask_update_step
Current compression ratio of attn:  tensor(0.2214, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1536, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3670947504809646
mask_update_step
Current compression ratio of attn:  tensor(0.2213, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1552, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3680611308644712
mask_update_step
Current compression ratio of attn:  tensor(0.2240, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1551, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.36902670698979956
mask_update_step
Current compression ratio of attn:  tensor(0.2218, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1579, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3699914767470489
mask_update_step
Current compression ratio of attn:  tensor(0.2233, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1587, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3709554380280803
mask_update_step
Current compression ratio of attn:  tensor(0.2251, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1591, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37191858872652156
mask_update_step
Current compression ratio of attn:  tensor(0.2264, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1598, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37288092673777173
mask_update_step
Current compression ratio of attn:  tensor(0.2280, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37384244995900556
mask_update_step
Current compression ratio of attn:  tensor(0.2256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3748031562891783
Search Epoch: [2]  [23613/23614]  eta: 0:00:01  lr: 0.00001000  loss: 17.4580  loss_ita: 6.5702  loss_sp_attn: 5.2339  loss_sp_mlp: 5.6540  time: 1.1143  data: 0.0004  max mem: 55126
Search Epoch: [2] Total time: 7:06:38 (1.0841 s / it)
Averaged stats: lr: 0.0000  loss: 17.8553  loss_ita: 6.2624  loss_sp_attn: 5.5781  loss_sp_mlp: 6.0148
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
do itm_eval
search_result {'txt_r1': 65.98, 'txt_r5': 89.32, 'txt_r10': 94.46, 'txt_r_mean': 83.25333333333333, 'img_r1': 53.78648540583767, 'img_r5': 79.13234706117554, 'img_r10': 86.72131147540983, 'img_r_mean': 73.21338131414102, 'r_mean': 78.23335732373718}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.5104
Text_CKA_Similarity: 0.9054
Image_Cosine_Similarity: 0.4123
Image_CKA_Similarity: 0.8523
sim_matrix_pearson_correlation: 0.9571
model_search_2.pth saved
KD:True
Search Epoch: [3]  [    0/23614]  eta: 10:01:55  lr: 0.00001000  loss: 18.0028  loss_ita: 7.1150  loss_sp_attn: 5.2339  loss_sp_mlp: 5.6540  time: 1.5294  data: 0.2343  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.2288, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1630, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3757630436290303
mask_update_step
Current compression ratio of attn:  tensor(0.2289, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1644, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3767221098810912
mask_update_step
Current compression ratio of attn:  tensor(0.2347, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1624, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.37768035294968505
mask_update_step
Current compression ratio of attn:  tensor(0.2331, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1650, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3786377707409347
mask_update_step
Current compression ratio of attn:  tensor(0.2337, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1662, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3795943611627661
mask_update_step
Current compression ratio of attn:  tensor(0.2326, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1683, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3805501221249134
mask_update_step
Current compression ratio of attn:  tensor(0.2360, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38150505153892295
mask_update_step
Current compression ratio of attn:  tensor(0.2370, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1688, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3824591473181583
mask_update_step
Current compression ratio of attn:  tensor(0.2341, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1722, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38341240737780447
mask_update_step
Current compression ratio of attn:  tensor(0.2402, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1700, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38436482963487295
mask_update_step
Current compression ratio of attn:  tensor(0.2384, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1727, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38531641200820543
mask_update_step
Current compression ratio of attn:  tensor(0.2437, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1710, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3862671524184791
mask_update_step
Current compression ratio of attn:  tensor(0.2447, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1720, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38721704878821095
mask_update_step
Current compression ratio of attn:  tensor(0.2406, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1760, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.38816609904176236
mask_update_step
Current compression ratio of attn:  tensor(0.2430, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3891143011053435
mask_update_step
Current compression ratio of attn:  tensor(0.2433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1776, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39006165290701783
mask_update_step
Current compression ratio of attn:  tensor(0.2494, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1755, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3910081523767071
mask_update_step
Current compression ratio of attn:  tensor(0.2495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1770, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3919537974461951
mask_update_step
Current compression ratio of attn:  tensor(0.2501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1782, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39289858604913264
mask_update_step
Current compression ratio of attn:  tensor(0.2493, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1803, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39384251612104226
mask_update_step
Current compression ratio of attn:  tensor(0.2527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1798, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3947855855993223
mask_update_step
Current compression ratio of attn:  tensor(0.2496, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1832, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3957277924232517
mask_update_step
Current compression ratio of attn:  tensor(0.2539, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1821, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3966691345339943
mask_update_step
Current compression ratio of attn:  tensor(0.2540, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1838, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.3976096098746036
mask_update_step
Current compression ratio of attn:  tensor(0.2569, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1837, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39854921639002683
Search Epoch: [3]  [ 5000/23614]  eta: 5:34:13  lr: 0.00001000  loss: 17.0475  loss_ita: 6.5083  loss_sp_attn: 5.0219  loss_sp_mlp: 5.5172  time: 1.0329  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.2527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1879, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.39948795202710996
mask_update_step
Current compression ratio of attn:  tensor(0.2588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1857, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40042581473460204
mask_update_step
Current compression ratio of attn:  tensor(0.2594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1868, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40136280246315903
mask_update_step
Current compression ratio of attn:  tensor(0.2619, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4022989131653495
mask_update_step
Current compression ratio of attn:  tensor(0.2586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1907, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40323414479565794
mask_update_step
Current compression ratio of attn:  tensor(0.2603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40416849531049004
mask_update_step
Current compression ratio of attn:  tensor(0.2637, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1908, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4051019626681765
mask_update_step
Current compression ratio of attn:  tensor(0.2639, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1922, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4060345448289781
mask_update_step
Current compression ratio of attn:  tensor(0.2631, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1945, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4069662397550897
mask_update_step
Current compression ratio of attn:  tensor(0.2677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1932, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4078970454106452
mask_update_step
Current compression ratio of attn:  tensor(0.2676, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1949, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40882695976172123
mask_update_step
Current compression ratio of attn:  tensor(0.2656, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1977, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.40975598077634234
mask_update_step
Current compression ratio of attn:  tensor(0.2667, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41068410642448505
mask_update_step
Current compression ratio of attn:  tensor(0.2715, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1974, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4116113346780821
mask_update_step
Current compression ratio of attn:  tensor(0.2705, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1996, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4125376635110277
mask_update_step
Current compression ratio of attn:  tensor(0.2732, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.1997, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4134630908991809
mask_update_step
Current compression ratio of attn:  tensor(0.2739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4143876148203706
mask_update_step
Current compression ratio of attn:  tensor(0.2747, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4153112332544002
mask_update_step
Current compression ratio of attn:  tensor(0.2751, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4162339441830514
mask_update_step
Current compression ratio of attn:  tensor(0.2783, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41715574559008894
mask_update_step
Current compression ratio of attn:  tensor(0.2758, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2063, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41807663546126506
mask_update_step
Current compression ratio of attn:  tensor(0.2832, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4189966117843239
mask_update_step
Current compression ratio of attn:  tensor(0.2780, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.41991567254900547
mask_update_step
Current compression ratio of attn:  tensor(0.2796, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4208338157470509
mask_update_step
Current compression ratio of attn:  tensor(0.2834, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4217510393722057
Search Epoch: [3]  [10000/23614]  eta: 4:04:15  lr: 0.00001000  loss: 17.6503  loss_ita: 7.4563  loss_sp_attn: 4.8433  loss_sp_mlp: 5.3507  time: 1.0716  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.2784, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2131, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4226673414202254
mask_update_step
Current compression ratio of attn:  tensor(0.2866, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42358271988887874
mask_update_step
Current compression ratio of attn:  tensor(0.2847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2125, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4244971727779529
mask_update_step
Current compression ratio of attn:  tensor(0.2848, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42541069808925747
mask_update_step
Current compression ratio of attn:  tensor(0.2847, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2159, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42632329382662904
mask_update_step
Current compression ratio of attn:  tensor(0.2885, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.42723495799593525
mask_update_step
Current compression ratio of attn:  tensor(0.2872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2176, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4281456886050793
mask_update_step
Current compression ratio of attn:  tensor(0.2930, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2158, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4290554836640047
mask_update_step
Current compression ratio of attn:  tensor(0.2909, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2188, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4299643411846986
mask_update_step
Current compression ratio of attn:  tensor(0.2905, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2207, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43087225918119754
mask_update_step
Current compression ratio of attn:  tensor(0.2938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2203, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4317792356695905
mask_update_step
Current compression ratio of attn:  tensor(0.2947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2215, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4326852686680238
mask_update_step
Current compression ratio of attn:  tensor(0.2923, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2245, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4335903561967058
mask_update_step
Current compression ratio of attn:  tensor(0.2937, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2254, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43449449627791026
mask_update_step
Current compression ratio of attn:  tensor(0.2958, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2259, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43539768693598185
mask_update_step
Current compression ratio of attn:  tensor(0.3002, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2248, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43629992619733926
mask_update_step
Current compression ratio of attn:  tensor(0.2980, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4372012120904806
mask_update_step
Current compression ratio of attn:  tensor(0.3009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2278, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43810154264598666
mask_update_step
Current compression ratio of attn:  tensor(0.2977, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2314, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43900091589652634
mask_update_step
Current compression ratio of attn:  tensor(0.3022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2304, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.43989932987685976
mask_update_step
Current compression ratio of attn:  tensor(0.3018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2324, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4407967826238438
mask_update_step
Current compression ratio of attn:  tensor(0.3060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2315, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4416932721764354
mask_update_step
Current compression ratio of attn:  tensor(0.3035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2347, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44258879657569616
mask_update_step
Current compression ratio of attn:  tensor(0.3059, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2349, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44348335386479665
mask_update_step
Current compression ratio of attn:  tensor(0.3068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2361, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.444376942089021
Search Epoch: [3]  [15000/23614]  eta: 2:35:22  lr: 0.00001000  loss: 17.2955  loss_ita: 7.4475  loss_sp_attn: 4.6850  loss_sp_mlp: 5.1630  time: 1.1015  data: 0.0002  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.3074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2373, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4452695592957704
mask_update_step
Current compression ratio of attn:  tensor(0.3080, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2388, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44616120353456834
mask_update_step
Current compression ratio of attn:  tensor(0.3105, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4470518728570637
mask_update_step
Current compression ratio of attn:  tensor(0.3139, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2386, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.44794156531703655
mask_update_step
Current compression ratio of attn:  tensor(0.3106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2423, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4488302789704007
mask_update_step
Current compression ratio of attn:  tensor(0.3107, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2440, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4497180118752092
mask_update_step
Current compression ratio of attn:  tensor(0.3134, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2440, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.450604762091658
mask_update_step
Current compression ratio of attn:  tensor(0.3148, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45149052768209064
mask_update_step
Current compression ratio of attn:  tensor(0.3170, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2452, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45237530671100157
mask_update_step
Current compression ratio of attn:  tensor(0.3203, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2450, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4532590972450418
mask_update_step
Current compression ratio of attn:  tensor(0.3209, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2463, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4541418973530217
mask_update_step
Current compression ratio of attn:  tensor(0.3173, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45502370510591583
mask_update_step
Current compression ratio of attn:  tensor(0.3206, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2500, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45590451857686787
mask_update_step
Current compression ratio of attn:  tensor(0.3230, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4567843358411931
mask_update_step
Current compression ratio of attn:  tensor(0.3226, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2522, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45766315497638466
mask_update_step
Current compression ratio of attn:  tensor(0.3285, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4585409740621159
mask_update_step
Current compression ratio of attn:  tensor(0.3286, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2519, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.45941779118024584
mask_update_step
Current compression ratio of attn:  tensor(0.3300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2528, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4602936044148228
mask_update_step
Current compression ratio of attn:  tensor(0.3291, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2550, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4611684118520886
mask_update_step
Current compression ratio of attn:  tensor(0.3305, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2560, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46204221158048325
mask_update_step
Current compression ratio of attn:  tensor(0.3287, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46291500169064825
mask_update_step
Current compression ratio of attn:  tensor(0.3288, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2605, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46378678027543135
mask_update_step
Current compression ratio of attn:  tensor(0.3313, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2607, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4646575454298909
mask_update_step
Current compression ratio of attn:  tensor(0.3319, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2621, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46552729525129954
mask_update_step
Current compression ratio of attn:  tensor(0.3339, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46639602783914813
Search Epoch: [3]  [20000/23614]  eta: 1:05:16  lr: 0.00001000  loss: 16.9148  loss_ita: 7.4294  loss_sp_attn: 4.5020  loss_sp_mlp: 4.9835  time: 1.1037  data: 0.0002  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.3342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2642, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.467263741295151
mask_update_step
Current compression ratio of attn:  tensor(0.3397, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2625, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.46813043372324903
mask_update_step
Current compression ratio of attn:  tensor(0.3355, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2667, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4689961032296141
mask_update_step
Current compression ratio of attn:  tensor(0.3377, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2672, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4698607479226536
mask_update_step
Current compression ratio of attn:  tensor(0.3359, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2701, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47072436591301386
mask_update_step
Current compression ratio of attn:  tensor(0.3403, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2691, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4715869553135853
mask_update_step
Current compression ratio of attn:  tensor(0.3434, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47244851423950507
mask_update_step
Current compression ratio of attn:  tensor(0.3410, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2722, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4733090408081628
mask_update_step
Current compression ratio of attn:  tensor(0.3436, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2724, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47416853313920354
mask_update_step
Current compression ratio of attn:  tensor(0.3433, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2742, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4750269893545324
mask_update_step
Current compression ratio of attn:  tensor(0.3442, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2754, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47588440757831857
mask_update_step
Current compression ratio of attn:  tensor(0.3473, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2752, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4767407859369992
mask_update_step
Current compression ratio of attn:  tensor(0.3482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2765, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.47759612255928374
mask_update_step
Current compression ratio of attn:  tensor(0.3461, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2795, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4784504155761583
mask_update_step
Current compression ratio of attn:  tensor(0.3520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2778, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4793036631208888
mask_update_step
Current compression ratio of attn:  tensor(0.3451, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2837, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48015586332902616
mask_update_step
Current compression ratio of attn:  tensor(0.3555, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2790, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4810070143384094
mask_update_step
Current compression ratio of attn:  tensor(0.3514, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2834, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48185711428917066
Search Epoch: [3]  [23613/23614]  eta: 0:00:01  lr: 0.00001000  loss: 17.3697  loss_ita: 8.1425  loss_sp_attn: 4.3838  loss_sp_mlp: 4.8434  time: 1.1132  data: 0.0004  max mem: 55126
Search Epoch: [3] Total time: 7:06:29 (1.0837 s / it)
Averaged stats: lr: 0.0000  loss: 17.4154  loss_ita: 7.3458  loss_sp_attn: 4.7956  loss_sp_mlp: 5.2739
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
do itm_eval
search_result {'txt_r1': 58.78, 'txt_r5': 86.12, 'txt_r10': 92.06, 'txt_r_mean': 78.98666666666666, 'img_r1': 49.70411835265894, 'img_r5': 76.20551779288284, 'img_r10': 84.75009996001599, 'img_r_mean': 70.21991203518593, 'r_mean': 74.6032893509263}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.2455
Text_CKA_Similarity: 0.8210
Image_Cosine_Similarity: 0.2312
Image_CKA_Similarity: 0.7858
sim_matrix_pearson_correlation: 0.9433
model_search_3.pth saved
KD:True
Search Epoch: [4]  [    0/23614]  eta: 1 day, 16:44:50  lr: 0.00001000  loss: 16.9424  loss_ita: 7.7153  loss_sp_attn: 4.3838  loss_sp_mlp: 4.8434  time: 6.2120  data: 0.2294  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.3553, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2828, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48270616132373834
mask_update_step
Current compression ratio of attn:  tensor(0.3495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2880, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48355415358684184
mask_update_step
Current compression ratio of attn:  tensor(0.3574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2848, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4844010892255153
mask_update_step
Current compression ratio of attn:  tensor(0.3564, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4852469663891018
mask_update_step
Current compression ratio of attn:  tensor(0.3581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2878, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.48609178322925695
mask_update_step
Current compression ratio of attn:  tensor(0.3582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2897, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4869355378999539
mask_update_step
Current compression ratio of attn:  tensor(0.3574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2918, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4877782285574861
mask_update_step
Current compression ratio of attn:  tensor(0.3574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2936, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4886198533604726
mask_update_step
Current compression ratio of attn:  tensor(0.3583, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4894604104698611
mask_update_step
Current compression ratio of attn:  tensor(0.3621, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2943, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49029989804893237
mask_update_step
Current compression ratio of attn:  tensor(0.3618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49113831426330445
mask_update_step
Current compression ratio of attn:  tensor(0.3650, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2961, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4919756572809364
mask_update_step
Current compression ratio of attn:  tensor(0.3630, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2990, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4928119252721318
mask_update_step
Current compression ratio of attn:  tensor(0.3691, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4936471164095442
mask_update_step
Current compression ratio of attn:  tensor(0.3660, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3008, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4944812288681794
mask_update_step
Current compression ratio of attn:  tensor(0.3712, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.2994, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.495314260825401
mask_update_step
Current compression ratio of attn:  tensor(0.3658, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3043, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49614621046093277
mask_update_step
Current compression ratio of attn:  tensor(0.3687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49697707595686413
mask_update_step
Current compression ratio of attn:  tensor(0.3696, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.49780685549765336
mask_update_step
Current compression ratio of attn:  tensor(0.3708, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4986355472701315
mask_update_step
Current compression ratio of attn:  tensor(0.3711, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.4994631494635065
mask_update_step
Current compression ratio of attn:  tensor(0.3746, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5002896602693674
mask_update_step
Current compression ratio of attn:  tensor(0.3767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5011150778816879
mask_update_step
Current compression ratio of attn:  tensor(0.3773, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3098, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5019394004968305
mask_update_step
Current compression ratio of attn:  tensor(0.3750, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3130, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5027626263135503
Search Epoch: [4]  [ 5000/23614]  eta: 5:36:42  lr: 0.00001000  loss: 16.7416  loss_ita: 7.8746  loss_sp_attn: 4.2238  loss_sp_mlp: 4.6433  time: 1.0568  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.3730, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3155, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5035847535329991
mask_update_step
Current compression ratio of attn:  tensor(0.3789, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5044057803587295
mask_update_step
Current compression ratio of attn:  tensor(0.3754, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5052257049966982
mask_update_step
Current compression ratio of attn:  tensor(0.3807, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3166, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5060445256552706
mask_update_step
Current compression ratio of attn:  tensor(0.3772, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3205, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5068622405452241
mask_update_step
Current compression ratio of attn:  tensor(0.3781, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3217, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5076788478797527
mask_update_step
Current compression ratio of attn:  tensor(0.3858, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3188, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5084943458744706
mask_update_step
Current compression ratio of attn:  tensor(0.3846, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3213, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5093087327474155
mask_update_step
Current compression ratio of attn:  tensor(0.3858, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3223, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5101220067190536
mask_update_step
Current compression ratio of attn:  tensor(0.3844, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3250, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5109341660122827
mask_update_step
Current compression ratio of attn:  tensor(0.3880, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5117452088524362
mask_update_step
Current compression ratio of attn:  tensor(0.3877, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3266, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5125551334672874
mask_update_step
Current compression ratio of attn:  tensor(0.3889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3276, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5133639380870527
mask_update_step
Current compression ratio of attn:  tensor(0.3880, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3299, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.514171620944396
mask_update_step
Current compression ratio of attn:  tensor(0.3889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3312, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5149781802744323
mask_update_step
Current compression ratio of attn:  tensor(0.3937, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3300, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5157836143147317
mask_update_step
Current compression ratio of attn:  tensor(0.3946, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3313, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5165879213053235
mask_update_step
Current compression ratio of attn:  tensor(0.3913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3351, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5173910994886993
mask_update_step
Current compression ratio of attn:  tensor(0.3976, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3330, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5181931471098172
mask_update_step
Current compression ratio of attn:  tensor(0.3925, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3379, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5189940624161062
mask_update_step
Current compression ratio of attn:  tensor(0.3965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3373, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5197938436574694
mask_update_step
Current compression ratio of attn:  tensor(0.3983, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3379, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5205924890862873
mask_update_step
Current compression ratio of attn:  tensor(0.3977, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3399, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5213899969574234
mask_update_step
Current compression ratio of attn:  tensor(0.3986, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3413, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5221863655282262
mask_update_step
Current compression ratio of attn:  tensor(0.4010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5229815930585338
Search Epoch: [4]  [10000/23614]  eta: 4:05:13  lr: 0.00001000  loss: 17.4248  loss_ita: 8.9270  loss_sp_attn: 4.0482  loss_sp_mlp: 4.4496  time: 1.0836  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.4004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3438, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5237756778106776
mask_update_step
Current compression ratio of attn:  tensor(0.4025, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3442, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5245686180494863
mask_update_step
Current compression ratio of attn:  tensor(0.4037, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5253604120422894
mask_update_step
Current compression ratio of attn:  tensor(0.4053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3462, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5261510580589209
mask_update_step
Current compression ratio of attn:  tensor(0.4031, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3492, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5269405543717236
mask_update_step
Current compression ratio of attn:  tensor(0.4065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3490, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5277288992555523
mask_update_step
Current compression ratio of attn:  tensor(0.4089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3493, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.528516090987778
mask_update_step
Current compression ratio of attn:  tensor(0.4071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5293021278482911
mask_update_step
Current compression ratio of attn:  tensor(0.4089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3529, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.530087008119506
mask_update_step
Current compression ratio of attn:  tensor(0.4114, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5308707300863642
mask_update_step
Current compression ratio of attn:  tensor(0.4086, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3566, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5316532920363382
mask_update_step
Current compression ratio of attn:  tensor(0.4129, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.532434692259435
mask_update_step
Current compression ratio of attn:  tensor(0.4138, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5332149290482009
mask_update_step
Current compression ratio of attn:  tensor(0.4178, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3563, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5339940006977237
mask_update_step
Current compression ratio of attn:  tensor(0.4153, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3596, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5347719055056372
mask_update_step
Current compression ratio of attn:  tensor(0.4165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3606, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5355486417721256
mask_update_step
Current compression ratio of attn:  tensor(0.4237, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5363242077999257
mask_update_step
Current compression ratio of attn:  tensor(0.4143, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3655, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5370986018943319
mask_update_step
Current compression ratio of attn:  tensor(0.4246, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5378718223631992
mask_update_step
Current compression ratio of attn:  tensor(0.4165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5386438675169469
mask_update_step
Current compression ratio of attn:  tensor(0.4258, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3640, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5394147356685632
mask_update_step
Current compression ratio of attn:  tensor(0.4226, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5401844251336075
mask_update_step
Current compression ratio of attn:  tensor(0.4273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3666, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5409529342302151
mask_update_step
Current compression ratio of attn:  tensor(0.4235, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3707, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5417202612791004
mask_update_step
Current compression ratio of attn:  tensor(0.4295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3687, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5424864046035611
Search Epoch: [4]  [15000/23614]  eta: 2:35:07  lr: 0.00001000  loss: 17.0856  loss_ita: 8.9629  loss_sp_attn: 3.8559  loss_sp_mlp: 4.2668  time: 1.1235  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.4257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3730, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5432513625294808
mask_update_step
Current compression ratio of attn:  tensor(0.4282, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3731, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.544015133385334
mask_update_step
Current compression ratio of attn:  tensor(0.4329, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3720, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5447777155021886
mask_update_step
Current compression ratio of attn:  tensor(0.4335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5455391072137104
mask_update_step
Current compression ratio of attn:  tensor(0.4303, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3773, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5462993068561661
mask_update_step
Current compression ratio of attn:  tensor(0.4283, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3803, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5470583127684276
mask_update_step
Current compression ratio of attn:  tensor(0.4305, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3806, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5478161232919748
mask_update_step
Current compression ratio of attn:  tensor(0.4397, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5485727367708998
mask_update_step
Current compression ratio of attn:  tensor(0.4349, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3816, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5493281515519106
mask_update_step
Current compression ratio of attn:  tensor(0.4374, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3817, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5500823659843345
mask_update_step
Current compression ratio of attn:  tensor(0.4310, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3876, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5508353784201211
mask_update_step
Current compression ratio of attn:  tensor(0.4424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3823, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5515871872138474
mask_update_step
Current compression ratio of attn:  tensor(0.4353, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3884, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5523377907227197
mask_update_step
Current compression ratio of attn:  tensor(0.4420, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3861, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5530871873065787
mask_update_step
Current compression ratio of attn:  tensor(0.4436, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3868, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5538353753279018
mask_update_step
Current compression ratio of attn:  tensor(0.4426, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3893, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5545823531518077
mask_update_step
Current compression ratio of attn:  tensor(0.4493, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3870, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5553281191460593
mask_update_step
Current compression ratio of attn:  tensor(0.4415, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3935, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5560726716810672
mask_update_step
Current compression ratio of attn:  tensor(0.4482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3912, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5568160091298943
mask_update_step
Current compression ratio of attn:  tensor(0.4469, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5575581298682579
mask_update_step
Current compression ratio of attn:  tensor(0.4484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3946, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5582990322745344
mask_update_step
Current compression ratio of attn:  tensor(0.4497, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3956, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5590387147297622
mask_update_step
Current compression ratio of attn:  tensor(0.4470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3991, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5597771756176453
mask_update_step
Current compression ratio of attn:  tensor(0.4483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5605144133245576
mask_update_step
Current compression ratio of attn:  tensor(0.4570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3963, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.561250426239545
Search Epoch: [4]  [20000/23614]  eta: 1:05:11  lr: 0.00001000  loss: 16.8049  loss_ita: 9.0553  loss_sp_attn: 3.6699  loss_sp_mlp: 4.0798  time: 1.0876  data: 0.0002  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.4498, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4027, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5619852127543302
mask_update_step
Current compression ratio of attn:  tensor(0.4556, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4009, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5627187712633156
mask_update_step
Current compression ratio of attn:  tensor(0.4601, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.3999, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.563451100163587
mask_update_step
Current compression ratio of attn:  tensor(0.4617, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5641821978549169
mask_update_step
Current compression ratio of attn:  tensor(0.4577, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4049, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5649120627397684
mask_update_step
Current compression ratio of attn:  tensor(0.4619, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4041, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5656406932232978
mask_update_step
Current compression ratio of attn:  tensor(0.4559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4096, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5663680877133599
mask_update_step
Current compression ratio of attn:  tensor(0.4634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5670942446205091
mask_update_step
Current compression ratio of attn:  tensor(0.4584, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4114, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5678191623580047
mask_update_step
Current compression ratio of attn:  tensor(0.4639, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5685428393418136
mask_update_step
Current compression ratio of attn:  tensor(0.4658, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5692652739906137
mask_update_step
Current compression ratio of attn:  tensor(0.4681, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4108, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5699864647257982
mask_update_step
Current compression ratio of attn:  tensor(0.4690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5707064099714774
mask_update_step
Current compression ratio of attn:  tensor(0.4676, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4147, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5714251081544839
mask_update_step
Current compression ratio of attn:  tensor(0.4755, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4117, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.572142557704375
mask_update_step
Current compression ratio of attn:  tensor(0.4724, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5728587570534368
mask_update_step
Current compression ratio of attn:  tensor(0.4703, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4184, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5735737046366866
mask_update_step
Current compression ratio of attn:  tensor(0.4759, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5742873988918773
Search Epoch: [4]  [23613/23614]  eta: 0:00:01  lr: 0.00001000  loss: 16.0286  loss_ita: 8.5425  loss_sp_attn: 3.5420  loss_sp_mlp: 3.9440  time: 1.0900  data: 0.0003  max mem: 55126
Search Epoch: [4] Total time: 7:04:50 (1.0795 s / it)
Averaged stats: lr: 0.0000  loss: 16.8435  loss_ita: 8.4766  loss_sp_attn: 3.9843  loss_sp_mlp: 4.3825
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
do itm_eval
search_result {'txt_r1': 50.96, 'txt_r5': 80.94, 'txt_r10': 89.42, 'txt_r_mean': 73.77333333333333, 'img_r1': 47.88084766093563, 'img_r5': 74.75809676129548, 'img_r10': 83.86645341863255, 'img_r_mean': 68.83513261362121, 'r_mean': 71.30423297347727}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0495
Text_CKA_Similarity: 0.7825
Image_Cosine_Similarity: 0.1144
Image_CKA_Similarity: 0.7460
sim_matrix_pearson_correlation: 0.9316
model_search_4.pth saved
KD:True
Search Epoch: [5]  [    0/23614]  eta: 9:59:48  lr: 0.00001000  loss: 16.0212  loss_ita: 8.5352  loss_sp_attn: 3.5420  loss_sp_mlp: 3.9440  time: 1.5240  data: 0.2174  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.4762, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5749998382595005
mask_update_step
Current compression ratio of attn:  tensor(0.4768, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5757110211827899
mask_update_step
Current compression ratio of attn:  tensor(0.4740, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4232, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5764209461077247
mask_update_step
Current compression ratio of attn:  tensor(0.4733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4254, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5771296114830327
mask_update_step
Current compression ratio of attn:  tensor(0.4799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4231, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5778370157601942
mask_update_step
Current compression ratio of attn:  tensor(0.4764, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5785431573934451
mask_update_step
Current compression ratio of attn:  tensor(0.4804, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4261, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5792480348397804
mask_update_step
Current compression ratio of attn:  tensor(0.4830, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5799516465589577
mask_update_step
Current compression ratio of attn:  tensor(0.4822, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4287, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5806539910134997
mask_update_step
Current compression ratio of attn:  tensor(0.4851, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4286, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.581355066668699
mask_update_step
Current compression ratio of attn:  tensor(0.4820, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4321, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.58205487199262
mask_update_step
Current compression ratio of attn:  tensor(0.4870, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4308, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5827534054561034
mask_update_step
Current compression ratio of attn:  tensor(0.4872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4326, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5834506655327691
mask_update_step
Current compression ratio of attn:  tensor(0.4898, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5841466506990189
mask_update_step
Current compression ratio of attn:  tensor(0.4853, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4371, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5848413594340415
mask_update_step
Current compression ratio of attn:  tensor(0.4917, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4351, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5855347902198135
mask_update_step
Current compression ratio of attn:  tensor(0.4848, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4410, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5862269415411049
mask_update_step
Current compression ratio of attn:  tensor(0.4918, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4385, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5869178118854811
mask_update_step
Current compression ratio of attn:  tensor(0.4975, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5876073997433067
mask_update_step
Current compression ratio of attn:  tensor(0.4913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4423, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5882957036077486
mask_update_step
Current compression ratio of attn:  tensor(0.5010, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4381, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5889827219747794
mask_update_step
Current compression ratio of attn:  tensor(0.4972, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4422, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.589668453343181
mask_update_step
Current compression ratio of attn:  tensor(0.5012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4414, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5903528962145469
mask_update_step
Current compression ratio of attn:  tensor(0.4997, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5910360490932867
mask_update_step
Current compression ratio of attn:  tensor(0.5006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4452, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5917179104866284
Search Epoch: [5]  [ 5000/23614]  eta: 5:35:26  lr: 0.00001000  loss: 16.8852  loss_ita: 9.7610  loss_sp_attn: 3.3749  loss_sp_mlp: 3.7493  time: 1.1176  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.4971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4491, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5923984789046223
mask_update_step
Current compression ratio of attn:  tensor(0.5028, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5930777528601439
mask_update_step
Current compression ratio of attn:  tensor(0.5048, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4478, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5937557308688972
mask_update_step
Current compression ratio of attn:  tensor(0.5074, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4480, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5944324114494184
mask_update_step
Current compression ratio of attn:  tensor(0.5083, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4492, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.595107793123078
mask_update_step
Current compression ratio of attn:  tensor(0.5092, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4502, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5957818744140855
mask_update_step
Current compression ratio of attn:  tensor(0.5088, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4524, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5964546538494915
mask_update_step
Current compression ratio of attn:  tensor(0.5104, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4530, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5971261299591913
mask_update_step
Current compression ratio of attn:  tensor(0.5113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4542, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5977963012759284
mask_update_step
Current compression ratio of attn:  tensor(0.5126, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4550, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.598465166335297
mask_update_step
Current compression ratio of attn:  tensor(0.5145, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4557, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.5991327236757462
mask_update_step
Current compression ratio of attn:  tensor(0.5144, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4574, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.599798971838582
mask_update_step
Current compression ratio of attn:  tensor(0.5192, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4563, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6004639093679717
mask_update_step
Current compression ratio of attn:  tensor(0.5180, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4587, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6011275348109458
mask_update_step
Current compression ratio of attn:  tensor(0.5193, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6017898467174027
mask_update_step
Current compression ratio of attn:  tensor(0.5219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4598, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6024508436401105
mask_update_step
Current compression ratio of attn:  tensor(0.5284, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6031105241347108
mask_update_step
Current compression ratio of attn:  tensor(0.5241, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4617, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6037688867597215
mask_update_step
Current compression ratio of attn:  tensor(0.5215, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4651, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.604425930076541
mask_update_step
Current compression ratio of attn:  tensor(0.5221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4665, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6050816526494495
mask_update_step
Current compression ratio of attn:  tensor(0.5307, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4628, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6057360530456141
mask_update_step
Current compression ratio of attn:  tensor(0.5292, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4653, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6063891298350905
mask_update_step
Current compression ratio of attn:  tensor(0.5301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4667, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6070408815908266
mask_update_step
Current compression ratio of attn:  tensor(0.5335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4661, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.607691306888666
mask_update_step
Current compression ratio of attn:  tensor(0.5305, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4698, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6083404043073506
Search Epoch: [5]  [10000/23614]  eta: 4:04:03  lr: 0.00001000  loss: 15.8477  loss_ita: 9.0916  loss_sp_attn: 3.1728  loss_sp_mlp: 3.5834  time: 1.0753  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.5339, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4694, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6089881724285237
mask_update_step
Current compression ratio of attn:  tensor(0.5373, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4689, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6096346098367337
mask_update_step
Current compression ratio of attn:  tensor(0.5354, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4718, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6102797151194364
mask_update_step
Current compression ratio of attn:  tensor(0.5384, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4717, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6109234868669984
mask_update_step
Current compression ratio of attn:  tensor(0.5397, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4726, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6115659236727008
mask_update_step
Current compression ratio of attn:  tensor(0.5399, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4742, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6122070241327409
mask_update_step
Current compression ratio of attn:  tensor(0.5401, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6128467868462368
mask_update_step
Current compression ratio of attn:  tensor(0.5414, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4766, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6134852104152293
mask_update_step
Current compression ratio of attn:  tensor(0.5484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6141222934446856
mask_update_step
Current compression ratio of attn:  tensor(0.5425, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4793, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.614758034542502
mask_update_step
Current compression ratio of attn:  tensor(0.5481, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4776, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6153924323195071
mask_update_step
Current compression ratio of attn:  tensor(0.5483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6160254853894651
mask_update_step
Current compression ratio of attn:  tensor(0.5456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4824, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6166571923690781
mask_update_step
Current compression ratio of attn:  tensor(0.5498, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4814, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6172875518779898
mask_update_step
Current compression ratio of attn:  tensor(0.5550, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4801, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6179165625387883
mask_update_step
Current compression ratio of attn:  tensor(0.5484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4857, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6185442229770092
mask_update_step
Current compression ratio of attn:  tensor(0.5572, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4820, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6191705318211382
mask_update_step
Current compression ratio of attn:  tensor(0.5509, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4874, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6197954877026148
mask_update_step
Current compression ratio of attn:  tensor(0.5579, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4848, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6204190892558344
mask_update_step
Current compression ratio of attn:  tensor(0.5578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4866, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6210413351181521
mask_update_step
Current compression ratio of attn:  tensor(0.5540, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4906, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6216622239298853
mask_update_step
Current compression ratio of attn:  tensor(0.5625, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6222817543343169
mask_update_step
Current compression ratio of attn:  tensor(0.5620, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6228999249776975
mask_update_step
Current compression ratio of attn:  tensor(0.5622, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4906, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6235167345092496
mask_update_step
Current compression ratio of attn:  tensor(0.5551, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4964, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6241321815811696
Search Epoch: [5]  [15000/23614]  eta: 2:34:22  lr: 0.00001000  loss: 16.0140  loss_ita: 9.6037  loss_sp_attn: 3.0065  loss_sp_mlp: 3.4037  time: 1.0738  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.5629, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4934, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6247462648486308
mask_update_step
Current compression ratio of attn:  tensor(0.5642, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4943, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6253589829697872
mask_update_step
Current compression ratio of attn:  tensor(0.5658, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4948, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6259703346057751
mask_update_step
Current compression ratio of attn:  tensor(0.5653, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4969, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6265803184207175
mask_update_step
Current compression ratio of attn:  tensor(0.5717, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4946, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6271889330817254
mask_update_step
Current compression ratio of attn:  tensor(0.5733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4953, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6277961772589022
mask_update_step
Current compression ratio of attn:  tensor(0.5749, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4959, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6284020496253458
mask_update_step
Current compression ratio of attn:  tensor(0.5682, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5017, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6290065488571518
mask_update_step
Current compression ratio of attn:  tensor(0.5757, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6296096736334158
mask_update_step
Current compression ratio of attn:  tensor(0.5773, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4993, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6302114226362372
mask_update_step
Current compression ratio of attn:  tensor(0.5826, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.4977, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6308117945507217
mask_update_step
Current compression ratio of attn:  tensor(0.5755, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5037, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6314107880649835
mask_update_step
Current compression ratio of attn:  tensor(0.5815, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5016, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6320084018701495
mask_update_step
Current compression ratio of attn:  tensor(0.5817, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5030, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6326046346603609
mask_update_step
Current compression ratio of attn:  tensor(0.5837, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5035, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6331994851327769
mask_update_step
Current compression ratio of attn:  tensor(0.5832, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6337929519875773
mask_update_step
Current compression ratio of attn:  tensor(0.5834, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5069, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6343850339279647
mask_update_step
Current compression ratio of attn:  tensor(0.5887, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6349757296601687
mask_update_step
Current compression ratio of attn:  tensor(0.5870, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5078, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6355650378934473
mask_update_step
Current compression ratio of attn:  tensor(0.5901, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5077, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6361529573400906
mask_update_step
Current compression ratio of attn:  tensor(0.5829, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6367394867154235
mask_update_step
Current compression ratio of attn:  tensor(0.5964, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5070, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6373246247378079
mask_update_step
Current compression ratio of attn:  tensor(0.5914, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5117, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6379083701286468
mask_update_step
Current compression ratio of attn:  tensor(0.5978, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6384907216123854
mask_update_step
Current compression ratio of attn:  tensor(0.5928, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6390716779165152
Search Epoch: [5]  [20000/23614]  eta: 1:04:25  lr: 0.00001000  loss: 16.7688  loss_ita: 10.7325  loss_sp_attn: 2.7517  loss_sp_mlp: 3.2846  time: 1.0879  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.5941, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5148, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6396512377715764
mask_update_step
Current compression ratio of attn:  tensor(0.5961, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6402293999111601
mask_update_step
Current compression ratio of attn:  tensor(0.6004, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6408061630719126
mask_update_step
Current compression ratio of attn:  tensor(0.5939, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5196, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.641381525993536
mask_update_step
Current compression ratio of attn:  tensor(0.6044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5148, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6419554874187927
mask_update_step
Current compression ratio of attn:  tensor(0.5990, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5197, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6425280460935076
mask_update_step
Current compression ratio of attn:  tensor(0.6051, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5176, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6430992007665701
mask_update_step
Current compression ratio of attn:  tensor(0.6046, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5195, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6436689501899386
mask_update_step
Current compression ratio of attn:  tensor(0.6055, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5203, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6442372931186413
mask_update_step
Current compression ratio of attn:  tensor(0.6034, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.64480422831078
mask_update_step
Current compression ratio of attn:  tensor(0.6065, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5230, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6453697545275326
mask_update_step
Current compression ratio of attn:  tensor(0.6071, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5242, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.645933870533156
mask_update_step
Current compression ratio of attn:  tensor(0.6087, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5248, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6464965750949879
mask_update_step
Current compression ratio of attn:  tensor(0.6089, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6470578669834512
mask_update_step
Current compression ratio of attn:  tensor(0.6113, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5263, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6476177449720546
mask_update_step
Current compression ratio of attn:  tensor(0.6137, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5264, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6481762078373969
mask_update_step
Current compression ratio of attn:  tensor(0.6104, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5299, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6487332543591696
mask_update_step
Current compression ratio of attn:  tensor(0.6177, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6492888833201579
Search Epoch: [5]  [23613/23614]  eta: 0:00:01  lr: 0.00001000  loss: 16.1546  loss_ita: 10.3745  loss_sp_attn: 2.5836  loss_sp_mlp: 3.1965  time: 1.0725  data: 0.0003  max mem: 55126
Search Epoch: [5] Total time: 7:02:01 (1.0723 s / it)
Averaged stats: lr: 0.0000  loss: 16.2446  loss_ita: 9.6160  loss_sp_attn: 3.0860  loss_sp_mlp: 3.5426
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
do itm_eval
search_result {'txt_r1': 45.06, 'txt_r5': 75.78, 'txt_r10': 85.6, 'txt_r_mean': 68.81333333333333, 'img_r1': 45.02998800479808, 'img_r5': 73.03078768492603, 'img_r10': 82.66293482606957, 'img_r_mean': 66.90790350526456, 'r_mean': 67.86061841929894}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0302
Text_CKA_Similarity: 0.8327
Image_Cosine_Similarity: 0.0698
Image_CKA_Similarity: 0.7505
sim_matrix_pearson_correlation: 0.9228
model_search_5.pth saved
KD:True
Search Epoch: [6]  [    0/23614]  eta: 10:40:25  lr: 0.00001000  loss: 16.0667  loss_ita: 10.2866  loss_sp_attn: 2.5836  loss_sp_mlp: 3.1965  time: 1.6272  data: 0.2332  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.6167, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5292, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6498430935062455
mask_update_step
Current compression ratio of attn:  tensor(0.6158, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5313, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6503958837064159
mask_update_step
Current compression ratio of attn:  tensor(0.6159, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5328, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6509472527127554
mask_update_step
Current compression ratio of attn:  tensor(0.6247, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5289, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6514971993204561
mask_update_step
Current compression ratio of attn:  tensor(0.6211, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.652045722327818
mask_update_step
Current compression ratio of attn:  tensor(0.6239, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6525928205362517
mask_update_step
Current compression ratio of attn:  tensor(0.6184, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5372, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6531384927502814
mask_update_step
Current compression ratio of attn:  tensor(0.6257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5342, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.653682737777547
mask_update_step
Current compression ratio of attn:  tensor(0.6236, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5373, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6542255544288075
mask_update_step
Current compression ratio of attn:  tensor(0.6241, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5385, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6547669415179425
mask_update_step
Current compression ratio of attn:  tensor(0.6257, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5390, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6553068978619556
mask_update_step
Current compression ratio of attn:  tensor(0.6270, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5397, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.655845422280977
mask_update_step
Current compression ratio of attn:  tensor(0.6336, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5372, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6563825135982652
mask_update_step
Current compression ratio of attn:  tensor(0.6280, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5421, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6569181706402106
mask_update_step
Current compression ratio of attn:  tensor(0.6361, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5386, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6574523922363381
mask_update_step
Current compression ratio of attn:  tensor(0.6340, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5414, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6579851772193083
mask_update_step
Current compression ratio of attn:  tensor(0.6368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5413, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6585165244249216
mask_update_step
Current compression ratio of attn:  tensor(0.6358, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5434, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.65904643269212
mask_update_step
Current compression ratio of attn:  tensor(0.6359, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5448, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6595749008629896
mask_update_step
Current compression ratio of attn:  tensor(0.6368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6601019277827637
mask_update_step
Current compression ratio of attn:  tensor(0.6362, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5477, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6606275122998242
mask_update_step
Current compression ratio of attn:  tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5443, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6611516532657054
mask_update_step
Current compression ratio of attn:  tensor(0.6376, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5498, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6616743495350959
mask_update_step
Current compression ratio of attn:  tensor(0.6423, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6621955999658408
mask_update_step
Current compression ratio of attn:  tensor(0.6370, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5531, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6627154034189447
Search Epoch: [6]  [ 5000/23614]  eta: 5:32:57  lr: 0.00001000  loss: 15.5722  loss_ita: 10.0986  loss_sp_attn: 2.4532  loss_sp_mlp: 3.0205  time: 1.0974  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.6452, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6632337587585744
mask_update_step
Current compression ratio of attn:  tensor(0.6511, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6637506648520602
mask_update_step
Current compression ratio of attn:  tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6642661205699
mask_update_step
Current compression ratio of attn:  tensor(0.6525, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5495, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6647801247857605
mask_update_step
Current compression ratio of attn:  tensor(0.6387, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6652926763764802
mask_update_step
Current compression ratio of attn:  tensor(0.6500, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5539, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6658037742220716
mask_update_step
Current compression ratio of attn:  tensor(0.6493, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6663134172057241
mask_update_step
Current compression ratio of attn:  tensor(0.6525, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5553, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.666821604213806
mask_update_step
Current compression ratio of attn:  tensor(0.6523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5569, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.667328334135867
mask_update_step
Current compression ratio of attn:  tensor(0.6516, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5588, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6678336058646411
mask_update_step
Current compression ratio of attn:  tensor(0.6563, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5573, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6683374182960479
mask_update_step
Current compression ratio of attn:  tensor(0.6592, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6688397703291966
mask_update_step
Current compression ratio of attn:  tensor(0.6597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6693406608663869
mask_update_step
Current compression ratio of attn:  tensor(0.6578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5607, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6698400888131122
mask_update_step
Current compression ratio of attn:  tensor(0.6641, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5583, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.670338053078062
mask_update_step
Current compression ratio of attn:  tensor(0.6607, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5617, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6708345525731242
mask_update_step
Current compression ratio of attn:  tensor(0.6597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5639, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.671329586213387
mask_update_step
Current compression ratio of attn:  tensor(0.6640, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6718231529171419
mask_update_step
Current compression ratio of attn:  tensor(0.6599, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5666, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6723152516058859
mask_update_step
Current compression ratio of attn:  tensor(0.6646, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5650, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6728058812043238
mask_update_step
Current compression ratio of attn:  tensor(0.6608, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5689, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6732950406403704
mask_update_step
Current compression ratio of attn:  tensor(0.6644, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5681, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.673782728845153
mask_update_step
Current compression ratio of attn:  tensor(0.6661, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5683, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6742689447530139
mask_update_step
Current compression ratio of attn:  tensor(0.6677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5689, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6747536873015123
mask_update_step
Current compression ratio of attn:  tensor(0.6705, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5685, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6752369554314269
Search Epoch: [6]  [10000/23614]  eta: 4:05:08  lr: 0.00001000  loss: 15.4934  loss_ita: 10.3508  loss_sp_attn: 2.2266  loss_sp_mlp: 2.9160  time: 1.0796  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.6675, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5718, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6757187480867586
mask_update_step
Current compression ratio of attn:  tensor(0.6739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5693, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6761990642147316
mask_update_step
Current compression ratio of attn:  tensor(0.6735, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5709, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6766779027657973
mask_update_step
Current compression ratio of attn:  tensor(0.6717, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5734, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6771552626936354
mask_update_step
Current compression ratio of attn:  tensor(0.6749, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5727, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6776311429551564
mask_update_step
Current compression ratio of attn:  tensor(0.6734, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5751, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6781055425105043
mask_update_step
Current compression ratio of attn:  tensor(0.6747, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6785784603230587
mask_update_step
Current compression ratio of attn:  tensor(0.6771, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5756, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6790498953594368
mask_update_step
Current compression ratio of attn:  tensor(0.6795, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5755, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.679519846589496
mask_update_step
Current compression ratio of attn:  tensor(0.6808, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5761, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6799883129863358
mask_update_step
Current compression ratio of attn:  tensor(0.6805, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5777, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6804552935263004
mask_update_step
Current compression ratio of attn:  tensor(0.6774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5809, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6809207871889806
mask_update_step
Current compression ratio of attn:  tensor(0.6873, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5762, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6813847929572165
mask_update_step
Current compression ratio of attn:  tensor(0.6838, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5796, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6818473098170992
mask_update_step
Current compression ratio of attn:  tensor(0.6870, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6823083367579733
mask_update_step
Current compression ratio of attn:  tensor(0.6879, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6827678727724391
mask_update_step
Current compression ratio of attn:  tensor(0.6888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5807, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6832259168563547
mask_update_step
Current compression ratio of attn:  tensor(0.6853, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5842, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.683682468008838
mask_update_step
Current compression ratio of attn:  tensor(0.6913, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5818, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6841375252322699
mask_update_step
Current compression ratio of attn:  tensor(0.6933, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5819, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6845910875322949
mask_update_step
Current compression ratio of attn:  tensor(0.6942, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5827, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6850431539178244
mask_update_step
Current compression ratio of attn:  tensor(0.6910, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5860, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6854937234010388
mask_update_step
Current compression ratio of attn:  tensor(0.6923, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5865, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6859427949973886
mask_update_step
Current compression ratio of attn:  tensor(0.6979, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5844, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6863903677255987
mask_update_step
Current compression ratio of attn:  tensor(0.6936, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5884, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6868364406076679
Search Epoch: [6]  [15000/23614]  eta: 2:35:21  lr: 0.00001000  loss: 15.6123  loss_ita: 10.7595  loss_sp_attn: 2.0708  loss_sp_mlp: 2.7820  time: 0.9221  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.7044, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5829, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6872810126688731
mask_update_step
Current compression ratio of attn:  tensor(0.6993, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5875, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6877240829377704
mask_update_step
Current compression ratio of attn:  tensor(0.7033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5863, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6881656504461977
mask_update_step
Current compression ratio of attn:  tensor(0.7006, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6886057142292763
mask_update_step
Current compression ratio of attn:  tensor(0.7022, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5896, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6890442733254135
mask_update_step
Current compression ratio of attn:  tensor(0.7042, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5896, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6894813267763047
mask_update_step
Current compression ratio of attn:  tensor(0.7063, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5897, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.689916873626935
mask_update_step
Current compression ratio of attn:  tensor(0.7051, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5917, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6903509129255818
mask_update_step
Current compression ratio of attn:  tensor(0.7100, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5900, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6907834437238166
mask_update_step
Current compression ratio of attn:  tensor(0.7080, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5925, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6912144650765072
mask_update_step
Current compression ratio of attn:  tensor(0.7117, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5915, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6916439760418197
mask_update_step
Current compression ratio of attn:  tensor(0.7061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5962, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6920719756812206
mask_update_step
Current compression ratio of attn:  tensor(0.7121, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6924984630594787
mask_update_step
Current compression ratio of attn:  tensor(0.7142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6929234372446677
mask_update_step
Current compression ratio of attn:  tensor(0.7130, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5955, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6933468973081672
mask_update_step
Current compression ratio of attn:  tensor(0.7150, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5958, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6937688423246656
mask_update_step
Current compression ratio of attn:  tensor(0.7183, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5950, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6941892713721622
mask_update_step
Current compression ratio of attn:  tensor(0.7175, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5968, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6946081835319684
mask_update_step
Current compression ratio of attn:  tensor(0.7188, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5971, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6950255778887103
mask_update_step
Current compression ratio of attn:  tensor(0.7232, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5957, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6954414535303308
mask_update_step
Current compression ratio of attn:  tensor(0.7204, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6958558095480912
mask_update_step
Current compression ratio of attn:  tensor(0.7221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6962686450365732
mask_update_step
Current compression ratio of attn:  tensor(0.7269, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5972, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6966799590936814
mask_update_step
Current compression ratio of attn:  tensor(0.7265, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5987, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6970897508206447
mask_update_step
Current compression ratio of attn:  tensor(0.7278, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.5991, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6974980193220184
Search Epoch: [6]  [20000/23614]  eta: 1:04:56  lr: 0.00001000  loss: 15.0488  loss_ita: 10.4998  loss_sp_attn: 1.8398  loss_sp_mlp: 2.7092  time: 1.1121  data: 0.0002  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.7246, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6023, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6979047637056865
mask_update_step
Current compression ratio of attn:  tensor(0.7282, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6983099830828632
mask_update_step
Current compression ratio of attn:  tensor(0.7290, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6018, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.698713676568095
mask_update_step
Current compression ratio of attn:  tensor(0.7323, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6991158432792627
mask_update_step
Current compression ratio of attn:  tensor(0.7319, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6026, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6995164823375833
mask_update_step
Current compression ratio of attn:  tensor(0.7283, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6061, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.6999155928676121
mask_update_step
Current compression ratio of attn:  tensor(0.7368, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6021, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7003131739972438
mask_update_step
Current compression ratio of attn:  tensor(0.7360, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6036, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7007092248577158
mask_update_step
Current compression ratio of attn:  tensor(0.7352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6054, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7011037445836089
mask_update_step
Current compression ratio of attn:  tensor(0.7405, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6033, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7014967323128496
mask_update_step
Current compression ratio of attn:  tensor(0.7380, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6060, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7018881871867122
mask_update_step
Current compression ratio of attn:  tensor(0.7417, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6050, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7022781083498202
mask_update_step
Current compression ratio of attn:  tensor(0.7409, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6066, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7026664949501487
mask_update_step
Current compression ratio of attn:  tensor(0.7450, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7030533461390258
mask_update_step
Current compression ratio of attn:  tensor(0.7478, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6047, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7034386610711351
mask_update_step
Current compression ratio of attn:  tensor(0.7454, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6072, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7038224389045165
mask_update_step
Current compression ratio of attn:  tensor(0.7421, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6106, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7042046788005688
mask_update_step
Current compression ratio of attn:  tensor(0.7474, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6084, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7045853799240517
Search Epoch: [6]  [23613/23614]  eta: 0:00:01  lr: 0.00001000  loss: 15.5214  loss_ita: 11.1678  loss_sp_attn: 1.7072  loss_sp_mlp: 2.6463  time: 1.0864  data: 0.0005  max mem: 55126
Search Epoch: [6] Total time: 7:05:10 (1.0803 s / it)
Averaged stats: lr: 0.0000  loss: 15.4238  loss_ita: 10.3765  loss_sp_attn: 2.1619  loss_sp_mlp: 2.8854
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
do itm_eval
search_result {'txt_r1': 35.76, 'txt_r5': 67.84, 'txt_r10': 80.34, 'txt_r_mean': 61.31333333333333, 'img_r1': 41.63534586165534, 'img_r5': 70.65573770491804, 'img_r10': 80.97161135545781, 'img_r_mean': 64.42089830734373, 'r_mean': 62.86711582033853}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.1073
Text_CKA_Similarity: 0.8077
Image_Cosine_Similarity: 0.1118
Image_CKA_Similarity: 0.7671
sim_matrix_pearson_correlation: 0.9094
model_search_6.pth saved
KD:True
Search Epoch: [7]  [    0/23614]  eta: 10:28:31  lr: 0.00001000  loss: 15.0148  loss_ita: 10.6613  loss_sp_attn: 1.7072  loss_sp_mlp: 2.6463  time: 1.5970  data: 0.2395  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.7482, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6091, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7049645414430872
mask_update_step
Current compression ratio of attn:  tensor(0.7498, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6093, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7053421625291612
mask_update_step
Current compression ratio of attn:  tensor(0.7511, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6097, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.705718242357126
mask_update_step
Current compression ratio of attn:  tensor(0.7470, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6133, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7060927801052015
mask_update_step
Current compression ratio of attn:  tensor(0.7527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6108, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7064657749549773
mask_update_step
Current compression ratio of attn:  tensor(0.7527, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6120, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7068372260914147
mask_update_step
Current compression ratio of attn:  tensor(0.7522, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6135, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7072071327028477
mask_update_step
Current compression ratio of attn:  tensor(0.7506, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6156, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7075754939809857
mask_update_step
Current compression ratio of attn:  tensor(0.7546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6142, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7079423091209145
mask_update_step
Current compression ratio of attn:  tensor(0.7567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6141, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7083075773210986
mask_update_step
Current compression ratio of attn:  tensor(0.7567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6152, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7086712977833829
mask_update_step
Current compression ratio of attn:  tensor(0.7603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6140, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7090334697129939
mask_update_step
Current compression ratio of attn:  tensor(0.7582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6164, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7093940923185419
mask_update_step
Current compression ratio of attn:  tensor(0.7558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6189, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.709753164812023
mask_update_step
Current compression ratio of attn:  tensor(0.7611, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6169, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7101106864088205
mask_update_step
Current compression ratio of attn:  tensor(0.7635, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6163, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.710466656327706
mask_update_step
Current compression ratio of attn:  tensor(0.7659, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6160, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7108210737908424
mask_update_step
Current compression ratio of attn:  tensor(0.7601, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6203, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7111739380237843
mask_update_step
Current compression ratio of attn:  tensor(0.7638, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6193, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7115252482554808
mask_update_step
Current compression ratio of attn:  tensor(0.7642, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6200, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7118750037182764
mask_update_step
Current compression ratio of attn:  tensor(0.7629, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6219, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7122232036479129
mask_update_step
Current compression ratio of attn:  tensor(0.7691, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6191, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7125698472835315
mask_update_step
Current compression ratio of attn:  tensor(0.7690, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6203, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7129149338676737
mask_update_step
Current compression ratio of attn:  tensor(0.7694, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6212, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7132584626462832
mask_update_step
Current compression ratio of attn:  tensor(0.7669, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6238, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7136004328687087
Search Epoch: [7]  [ 5000/23614]  eta: 5:33:16  lr: 0.00001000  loss: 14.5783  loss_ita: 10.4600  loss_sp_attn: 1.5756  loss_sp_mlp: 2.5428  time: 1.0908  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.7738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6203, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7139408437877031
mask_update_step
Current compression ratio of attn:  tensor(0.7680, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6251, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7142796946594279
mask_update_step
Current compression ratio of attn:  tensor(0.7779, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6199, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7146169847434525
mask_update_step
Current compression ratio of attn:  tensor(0.7774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6214, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.714952713302757
mask_update_step
Current compression ratio of attn:  tensor(0.7757, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6234, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7152868796037342
mask_update_step
Current compression ratio of attn:  tensor(0.7773, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6235, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7156194829161902
mask_update_step
Current compression ratio of attn:  tensor(0.7764, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6250, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7159505225133462
mask_update_step
Current compression ratio of attn:  tensor(0.7826, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6223, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7162799976718408
mask_update_step
Current compression ratio of attn:  tensor(0.7796, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7166079076717307
mask_update_step
Current compression ratio of attn:  tensor(0.7821, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6245, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.716934251796493
mask_update_step
Current compression ratio of attn:  tensor(0.7791, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6275, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7172590293330259
mask_update_step
Current compression ratio of attn:  tensor(0.7857, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6245, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7175822395716515
mask_update_step
Current compression ratio of attn:  tensor(0.7769, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6308, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.717903881806116
mask_update_step
Current compression ratio of attn:  tensor(0.7935, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6216, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7182239553335922
mask_update_step
Current compression ratio of attn:  tensor(0.7822, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6295, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7185424594546808
mask_update_step
Current compression ratio of attn:  tensor(0.7908, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6252, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7188593934734113
mask_update_step
Current compression ratio of attn:  tensor(0.7841, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6301, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7191747566972451
mask_update_step
Current compression ratio of attn:  tensor(0.7865, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6298, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7194885484370747
mask_update_step
Current compression ratio of attn:  tensor(0.7923, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7198007680072274
mask_update_step
Current compression ratio of attn:  tensor(0.7939, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7201114147254656
mask_update_step
Current compression ratio of attn:  tensor(0.7921, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6293, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7204204879129885
mask_update_step
Current compression ratio of attn:  tensor(0.7937, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6293, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.720727986894434
mask_update_step
Current compression ratio of attn:  tensor(0.7865, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6345, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7210339109978792
mask_update_step
Current compression ratio of attn:  tensor(0.7944, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6307, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7213382595548428
mask_update_step
Current compression ratio of attn:  tensor(0.7947, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6315, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7216410319002867
Search Epoch: [7]  [10000/23614]  eta: 4:04:26  lr: 0.00001000  loss: 15.2261  loss_ita: 11.3481  loss_sp_attn: 1.3873  loss_sp_mlp: 2.4907  time: 1.0956  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.7946, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6325, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7219422273726164
mask_update_step
Current compression ratio of attn:  tensor(0.8012, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6293, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7222418453136834
mask_update_step
Current compression ratio of attn:  tensor(0.8003, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6306, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.722539885068786
mask_update_step
Current compression ratio of attn:  tensor(0.7986, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6328, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7228363459866712
mask_update_step
Current compression ratio of attn:  tensor(0.8001, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6327, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7231312274195363
mask_update_step
Current compression ratio of attn:  tensor(0.7959, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6363, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7234245287230294
mask_update_step
Current compression ratio of attn:  tensor(0.8020, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6334, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7237162492562517
mask_update_step
Current compression ratio of attn:  tensor(0.8053, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6323, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7240063883817582
mask_update_step
Current compression ratio of attn:  tensor(0.8073, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6320, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7242949454655603
mask_update_step
Current compression ratio of attn:  tensor(0.8068, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6332, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7245819198771251
mask_update_step
Current compression ratio of attn:  tensor(0.8117, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6309, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7248673109893793
mask_update_step
Current compression ratio of attn:  tensor(0.8082, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6341, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7251511181787085
mask_update_step
Current compression ratio of attn:  tensor(0.8094, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6343, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7254333408249595
mask_update_step
Current compression ratio of attn:  tensor(0.8063, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6369, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7257139783114418
mask_update_step
Current compression ratio of attn:  tensor(0.8067, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6374, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7259930300249284
mask_update_step
Current compression ratio of attn:  tensor(0.8116, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6353, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7262704953556575
mask_update_step
Current compression ratio of attn:  tensor(0.8094, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6375, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7265463736973337
mask_update_step
Current compression ratio of attn:  tensor(0.8168, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6338, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7268206644471294
mask_update_step
Current compression ratio of attn:  tensor(0.8125, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6373, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7270933670056862
mask_update_step
Current compression ratio of attn:  tensor(0.8225, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6320, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7273644807771156
mask_update_step
Current compression ratio of attn:  tensor(0.8186, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6353, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7276340051690016
mask_update_step
Current compression ratio of attn:  tensor(0.8155, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6380, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7279019395924003
mask_update_step
Current compression ratio of attn:  tensor(0.8175, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6376, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.728168283461843
mask_update_step
Current compression ratio of attn:  tensor(0.8165, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6390, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7284330361953356
mask_update_step
Current compression ratio of attn:  tensor(0.8181, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7286961972143616
Search Epoch: [7]  [15000/23614]  eta: 2:35:00  lr: 0.00001000  loss: 14.4704  loss_ita: 10.8003  loss_sp_attn: 1.2294  loss_sp_mlp: 2.4407  time: 1.0524  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.8235, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6364, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7289577659438822
mask_update_step
Current compression ratio of attn:  tensor(0.8216, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6383, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.729217741812338
mask_update_step
Current compression ratio of attn:  tensor(0.8249, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6371, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7294761242516501
mask_update_step
Current compression ratio of attn:  tensor(0.8256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6375, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7297329126972218
mask_update_step
Current compression ratio of attn:  tensor(0.8221, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6405, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7299881065879391
mask_update_step
Current compression ratio of attn:  tensor(0.8287, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6370, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7302417053661724
mask_update_step
Current compression ratio of attn:  tensor(0.8273, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7304937084777775
mask_update_step
Current compression ratio of attn:  tensor(0.8280, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6392, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7307441153720974
mask_update_step
Current compression ratio of attn:  tensor(0.8224, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6435, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7309929255019625
mask_update_step
Current compression ratio of attn:  tensor(0.8256, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6423, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7312401383236924
mask_update_step
Current compression ratio of attn:  tensor(0.8322, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6389, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7314857532970973
mask_update_step
Current compression ratio of attn:  tensor(0.8279, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6424, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7317297698854787
mask_update_step
Current compression ratio of attn:  tensor(0.8311, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6412, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7319721875556306
mask_update_step
Current compression ratio of attn:  tensor(0.8335, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6405, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7322130057778413
mask_update_step
Current compression ratio of attn:  tensor(0.8321, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6421, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7324522240258935
mask_update_step
Current compression ratio of attn:  tensor(0.8332, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6422, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7326898417770666
mask_update_step
Current compression ratio of attn:  tensor(0.8334, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6427, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7329258585121369
mask_update_step
Current compression ratio of attn:  tensor(0.8316, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6446, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7331602737153791
mask_update_step
Current compression ratio of attn:  tensor(0.8416, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6391, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7333930868745678
mask_update_step
Current compression ratio of attn:  tensor(0.8347, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6442, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7336242974809779
mask_update_step
Current compression ratio of attn:  tensor(0.8409, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6411, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7338539050293862
mask_update_step
Current compression ratio of attn:  tensor(0.8352, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6453, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7340819090180724
mask_update_step
Current compression ratio of attn:  tensor(0.8354, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6457, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7343083089488203
mask_update_step
Current compression ratio of attn:  tensor(0.8383, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7345331043269183
mask_update_step
Current compression ratio of attn:  tensor(0.8411, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7347562946611614
Search Epoch: [7]  [20000/23614]  eta: 1:05:02  lr: 0.00001000  loss: 14.4491  loss_ita: 10.9679  loss_sp_attn: 1.0742  loss_sp_mlp: 2.4070  time: 1.0887  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.8345, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6486, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.734977879463852
mask_update_step
Current compression ratio of attn:  tensor(0.8399, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6460, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7351978582507999
mask_update_step
Current compression ratio of attn:  tensor(0.8427, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6449, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.735416230541325
mask_update_step
Current compression ratio of attn:  tensor(0.8467, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6430, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7356329958582575
mask_update_step
Current compression ratio of attn:  tensor(0.8406, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6476, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7358481537279389
mask_update_step
Current compression ratio of attn:  tensor(0.8506, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6420, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7360617036802231
mask_update_step
Current compression ratio of attn:  tensor(0.8419, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6481, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7362736452484774
mask_update_step
Current compression ratio of attn:  tensor(0.8511, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7364839779695841
mask_update_step
Current compression ratio of attn:  tensor(0.8463, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6468, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7366927013839406
mask_update_step
Current compression ratio of attn:  tensor(0.8520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6439, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7368998150354609
mask_update_step
Current compression ratio of attn:  tensor(0.8501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6455, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7371053184715766
mask_update_step
Current compression ratio of attn:  tensor(0.8555, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6431, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7373092112432378
mask_update_step
Current compression ratio of attn:  tensor(0.8481, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.737511492904914
mask_update_step
Current compression ratio of attn:  tensor(0.8526, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6462, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7377121630145954
mask_update_step
Current compression ratio of attn:  tensor(0.8541, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6459, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7379112211337933
mask_update_step
Current compression ratio of attn:  tensor(0.8556, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6456, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7381086668275418
mask_update_step
Current compression ratio of attn:  tensor(0.8532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6476, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.738304499664398
mask_update_step
Current compression ratio of attn:  tensor(0.8590, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6447, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7384987192164434
Search Epoch: [7]  [23613/23614]  eta: 0:00:01  lr: 0.00001000  loss: 14.8424  loss_ita: 11.4882  loss_sp_attn: 0.9528  loss_sp_mlp: 2.4014  time: 1.1016  data: 0.0004  max mem: 55126
Search Epoch: [7] Total time: 7:04:44 (1.0792 s / it)
Averaged stats: lr: 0.0000  loss: 14.8843  loss_ita: 11.0653  loss_sp_attn: 1.3307  loss_sp_mlp: 2.4882
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
do itm_eval
search_result {'txt_r1': 34.28, 'txt_r5': 65.1, 'txt_r10': 77.34, 'txt_r_mean': 58.906666666666666, 'img_r1': 36.141543382646944, 'img_r5': 66.1375449820072, 'img_r10': 77.41303478608556, 'img_r_mean': 59.897374383579894, 'r_mean': 59.40202052512328}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0140
Text_CKA_Similarity: 0.8332
Image_Cosine_Similarity: 0.0228
Image_CKA_Similarity: 0.7448
sim_matrix_pearson_correlation: 0.9035
model_search_7.pth saved
KD:True
Search Epoch: [8]  [    0/23614]  eta: 10:01:11  lr: 0.00001000  loss: 14.7357  loss_ita: 11.3815  loss_sp_attn: 0.9528  loss_sp_mlp: 2.4014  time: 1.5276  data: 0.2232  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.8533, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6488, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7386913250592848
mask_update_step
Current compression ratio of attn:  tensor(0.8582, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6463, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7388823167720551
mask_update_step
Current compression ratio of attn:  tensor(0.8528, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6503, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7390716939374142
mask_update_step
Current compression ratio of attn:  tensor(0.8599, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6464, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7392594561415502
mask_update_step
Current compression ratio of attn:  tensor(0.8550, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6502, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7394456029741796
mask_update_step
Current compression ratio of attn:  tensor(0.8573, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6493, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7396301340285494
mask_update_step
Current compression ratio of attn:  tensor(0.8670, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6440, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7398130489014366
mask_update_step
Current compression ratio of attn:  tensor(0.8573, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6505, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.73999434719315
mask_update_step
Current compression ratio of attn:  tensor(0.8618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6483, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7401740285075312
mask_update_step
Current compression ratio of attn:  tensor(0.8573, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6516, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7403520924519544
mask_update_step
Current compression ratio of attn:  tensor(0.8652, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6473, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7405285386373286
mask_update_step
Current compression ratio of attn:  tensor(0.8633, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6491, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7407033666780972
mask_update_step
Current compression ratio of attn:  tensor(0.8652, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6484, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7408765761922399
mask_update_step
Current compression ratio of attn:  tensor(0.8594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6524, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.741048166801273
mask_update_step
Current compression ratio of attn:  tensor(0.8626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6511, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7412181381302501
mask_update_step
Current compression ratio of attn:  tensor(0.8598, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6534, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7413864898077631
mask_update_step
Current compression ratio of attn:  tensor(0.8677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6489, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7415532214659435
mask_update_step
Current compression ratio of attn:  tensor(0.8688, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6489, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7417183327404624
mask_update_step
Current compression ratio of attn:  tensor(0.8647, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6520, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7418818232705313
mask_update_step
Current compression ratio of attn:  tensor(0.8674, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6508, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7420436926989039
mask_update_step
Current compression ratio of attn:  tensor(0.8642, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6532, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7422039406718758
mask_update_step
Current compression ratio of attn:  tensor(0.8700, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6501, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7423625668392857
mask_update_step
Current compression ratio of attn:  tensor(0.8637, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7425195708545163
mask_update_step
Current compression ratio of attn:  tensor(0.8759, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6476, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7426749523744948
mask_update_step
Current compression ratio of attn:  tensor(0.8679, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6530, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7428287110596935
Search Epoch: [8]  [ 5000/23614]  eta: 5:34:58  lr: 0.00001000  loss: 14.8438  loss_ita: 11.6061  loss_sp_attn: 0.8926  loss_sp_mlp: 2.3451  time: 1.1063  data: 0.0002  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.8728, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6505, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7429808465741313
mask_update_step
Current compression ratio of attn:  tensor(0.8610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7431313585853736
mask_update_step
Current compression ratio of attn:  tensor(0.8646, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6565, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7432802467645336
mask_update_step
Current compression ratio of attn:  tensor(0.8777, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6490, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7434275107862722
mask_update_step
Current compression ratio of attn:  tensor(0.8684, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6551, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7435731503287999
mask_update_step
Current compression ratio of attn:  tensor(0.8741, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6519, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7437171650738765
mask_update_step
Current compression ratio of attn:  tensor(0.8799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6490, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7438595547068125
mask_update_step
Current compression ratio of attn:  tensor(0.8693, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7440003189164693
mask_update_step
Current compression ratio of attn:  tensor(0.8733, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6539, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.74413945739526
mask_update_step
Current compression ratio of attn:  tensor(0.8739, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6540, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.74427696983915
mask_update_step
Current compression ratio of attn:  tensor(0.8715, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7444128559476582
mask_update_step
Current compression ratio of attn:  tensor(0.8751, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6541, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7445471154238567
mask_update_step
Current compression ratio of attn:  tensor(0.8787, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6523, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7446797479743725
mask_update_step
Current compression ratio of attn:  tensor(0.8724, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6566, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7448107533093873
mask_update_step
Current compression ratio of attn:  tensor(0.8777, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6538, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7449401311426387
mask_update_step
Current compression ratio of attn:  tensor(0.8817, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6517, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7450678811914202
mask_update_step
Current compression ratio of attn:  tensor(0.8737, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7451940031765829
mask_update_step
Current compression ratio of attn:  tensor(0.8764, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6558, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7453184968225344
mask_update_step
Current compression ratio of attn:  tensor(0.8774, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6555, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7454413618572414
mask_update_step
Current compression ratio of attn:  tensor(0.8763, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6566, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7455625980122287
mask_update_step
Current compression ratio of attn:  tensor(0.8738, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6585, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7456822050225809
mask_update_step
Current compression ratio of attn:  tensor(0.8787, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6559, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7458001826269418
mask_update_step
Current compression ratio of attn:  tensor(0.8767, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6575, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7459165305675164
mask_update_step
Current compression ratio of attn:  tensor(0.8807, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6554, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7460312485900701
mask_update_step
Current compression ratio of attn:  tensor(0.8800, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6562, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7461443364439302
Search Epoch: [8]  [10000/23614]  eta: 4:02:50  lr: 0.00001000  loss: 14.4485  loss_ita: 11.3140  loss_sp_attn: 0.8110  loss_sp_mlp: 2.3235  time: 0.9875  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.8780, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6578, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7462557938819859
mask_update_step
Current compression ratio of attn:  tensor(0.8677, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6645, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7463656206606895
mask_update_step
Current compression ratio of attn:  tensor(0.8821, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6560, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7464738165400558
mask_update_step
Current compression ratio of attn:  tensor(0.8840, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6552, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.746580381283664
mask_update_step
Current compression ratio of attn:  tensor(0.8880, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6531, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7466853146586572
mask_update_step
Current compression ratio of attn:  tensor(0.8803, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6579, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.746788616435743
mask_update_step
Current compression ratio of attn:  tensor(0.8830, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6565, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7468902863891947
mask_update_step
Current compression ratio of attn:  tensor(0.8801, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6589, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7469903242968512
mask_update_step
Current compression ratio of attn:  tensor(0.8872, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6546, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7470887299401174
mask_update_step
Current compression ratio of attn:  tensor(0.8721, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6644, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7471855031039649
mask_update_step
Current compression ratio of attn:  tensor(0.8852, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.747280643576933
mask_update_step
Current compression ratio of attn:  tensor(0.8836, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6579, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.747374151151128
mask_update_step
Current compression ratio of attn:  tensor(0.8898, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6545, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7474660256222244
mask_update_step
Current compression ratio of attn:  tensor(0.8864, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6568, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7475562667894657
mask_update_step
Current compression ratio of attn:  tensor(0.8822, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7476448744556636
mask_update_step
Current compression ratio of attn:  tensor(0.8793, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6615, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7477318484272
mask_update_step
Current compression ratio of attn:  tensor(0.8833, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6593, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7478171885140259
mask_update_step
Current compression ratio of attn:  tensor(0.8777, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6630, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.747900894529663
mask_update_step
Current compression ratio of attn:  tensor(0.8843, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6592, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7479829662912036
mask_update_step
Current compression ratio of attn:  tensor(0.8888, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6567, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7480634036193109
mask_update_step
Current compression ratio of attn:  tensor(0.8871, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7481422063382196
mask_update_step
Current compression ratio of attn:  tensor(0.8894, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6569, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7482193742757361
mask_update_step
Current compression ratio of attn:  tensor(0.8825, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6613, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7482949072632391
mask_update_step
Current compression ratio of attn:  tensor(0.8835, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6608, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.74836880513568
mask_update_step
Current compression ratio of attn:  tensor(0.8862, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6595, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7484410677315831
Search Epoch: [8]  [15000/23614]  eta: 2:34:15  lr: 0.00001000  loss: 14.5006  loss_ita: 11.4304  loss_sp_attn: 0.7693  loss_sp_mlp: 2.3009  time: 1.0681  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.8845, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6608, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7485116948930456
mask_update_step
Current compression ratio of attn:  tensor(0.8850, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6607, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7485806864657386
mask_update_step
Current compression ratio of attn:  tensor(0.8895, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6580, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7486480422989074
mask_update_step
Current compression ratio of attn:  tensor(0.8891, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7487137622453711
mask_update_step
Current compression ratio of attn:  tensor(0.8887, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6591, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7487778461615238
mask_update_step
Current compression ratio of attn:  tensor(0.8879, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7488402939073343
mask_update_step
Current compression ratio of attn:  tensor(0.8902, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7489011053463468
mask_update_step
Current compression ratio of attn:  tensor(0.8881, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6600, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7489602803456807
mask_update_step
Current compression ratio of attn:  tensor(0.8908, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7490178187760318
mask_update_step
Current compression ratio of attn:  tensor(0.8856, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6619, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7490737205116714
mask_update_step
Current compression ratio of attn:  tensor(0.8939, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6570, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7491279854304475
mask_update_step
Current compression ratio of attn:  tensor(0.8897, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6597, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7491806134137846
mask_update_step
Current compression ratio of attn:  tensor(0.8862, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6620, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7492316043466845
mask_update_step
Current compression ratio of attn:  tensor(0.8919, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6587, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7492809581177254
mask_update_step
Current compression ratio of attn:  tensor(0.8929, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6583, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7493286746190636
mask_update_step
Current compression ratio of attn:  tensor(0.8938, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6579, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7493747537464328
mask_update_step
Current compression ratio of attn:  tensor(0.8886, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6612, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7494191953991441
mask_update_step
Current compression ratio of attn:  tensor(0.8874, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6621, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7494619994800877
mask_update_step
Current compression ratio of attn:  tensor(0.8896, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6609, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7495031658957312
mask_update_step
Current compression ratio of attn:  tensor(0.8862, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6631, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7495426945561209
mask_update_step
Current compression ratio of attn:  tensor(0.8906, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6605, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.749580585374882
mask_update_step
Current compression ratio of attn:  tensor(0.8841, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6646, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496168382692184
mask_update_step
Current compression ratio of attn:  tensor(0.8906, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6607, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496514531599132
mask_update_step
Current compression ratio of attn:  tensor(0.8911, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6605, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7496844299713288
mask_update_step
Current compression ratio of attn:  tensor(0.8929, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6595, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497157686314065
Search Epoch: [8]  [20000/23614]  eta: 1:04:48  lr: 0.00001000  loss: 14.9274  loss_ita: 11.9025  loss_sp_attn: 0.7239  loss_sp_mlp: 2.3010  time: 1.0731  data: 0.0001  max mem: 55126
mask_update_step
Current compression ratio of attn:  tensor(0.8799, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6676, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497454690716681
mask_update_step
Current compression ratio of attn:  tensor(0.8943, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7497735312272139
mask_update_step
Current compression ratio of attn:  tensor(0.8965, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6573, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.749799955036725
mask_update_step
Current compression ratio of attn:  tensor(0.8926, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6598, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498247404424623
mask_update_step
Current compression ratio of attn:  tensor(0.8887, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6621, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498478873902663
mask_update_step
Current compression ratio of attn:  tensor(0.8896, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6618, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498693958295586
mask_update_step
Current compression ratio of attn:  tensor(0.8953, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6586, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7498892657133402
mask_update_step
Current compression ratio of attn:  tensor(0.8901, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6619, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499074969981934
mask_update_step
Current compression ratio of attn:  tensor(0.8957, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6584, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499240896442805
mask_update_step
Current compression ratio of attn:  tensor(0.8853, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6649, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499390436153444
mask_update_step
Current compression ratio of attn:  tensor(0.8919, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6609, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499523588787088
mask_update_step
Current compression ratio of attn:  tensor(0.8910, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6612, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499640354052786
mask_update_step
Current compression ratio of attn:  tensor(0.8936, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6596, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499740731695388
mask_update_step
Current compression ratio of attn:  tensor(0.8915, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6610, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499824721495559
mask_update_step
Current compression ratio of attn:  tensor(0.8945, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6594, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499892323269771
mask_update_step
Current compression ratio of attn:  tensor(0.8889, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6626, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499943536870305
mask_update_step
Current compression ratio of attn:  tensor(0.8876, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6634, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.7499978362185253
mask_update_step
Current compression ratio of attn:  tensor(0.8967, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6581, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.749999679913852
mask_update_step
Current compression ratio of attn:  tensor(0.8928, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio of mlp:  tensor(0.6603, device='cuda:0', grad_fn=<RsubBackward1>)
Current compression ratio:  0.75
Search Epoch: [8]  [23613/23614]  eta: 0:00:01  lr: 0.00001000  loss: 12.5270  loss_ita: 9.5182  loss_sp_attn: 0.6981  loss_sp_mlp: 2.3107  time: 1.0923  data: 0.0003  max mem: 55126
Search Epoch: [8] Total time: 7:03:01 (1.0749 s / it)
Averaged stats: lr: 0.0000  loss: 14.6397  loss_ita: 11.5027  loss_sp_attn: 0.8155  loss_sp_mlp: 2.3215
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
do itm_eval
search_result {'txt_r1': 35.96, 'txt_r5': 65.96, 'txt_r10': 77.28, 'txt_r_mean': 59.73333333333333, 'img_r1': 33.81047580967613, 'img_r5': 63.19072371051579, 'img_r10': 75.17393042782886, 'img_r_mean': 57.391709982673596, 'r_mean': 58.56252165800346}
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0547
Text_CKA_Similarity: 0.8272
Image_Cosine_Similarity: 0.0605
Image_CKA_Similarity: 0.7127
sim_matrix_pearson_correlation: 0.8924
model_search_8.pth saved
mask_attn_vision:   [1.56, 1.56, 1.56, 1.56, 1.56, 1.56, 32.81, 1.56, 26.56, 26.56, 26.56, 23.44, 10.94, 21.88, 20.31, 9.38, 10.94, 7.81, 9.38, 4.69, 9.38, 12.5, 15.62, 12.5]
mask_attn_language:  [48.44, 4.69, 1.56, 1.56, 4.69, 3.12, 1.56, 1.56, 1.56, 4.69, 14.06, 6.25]
mask_mlp_vision:  [48.41, 21.14, 25.44, 26.22, 35.01, 29.32, 39.45, 39.21, 47.34, 52.86, 49.07, 48.83, 56.81, 49.66, 48.05, 48.49, 36.23, 28.1, 22.9, 19.19, 18.07, 19.56, 41.24, 23.9]
mask_mlp_language:  [70.18, 40.98, 27.44, 23.57, 21.74, 17.81, 17.9, 16.5, 18.95, 25.29, 26.79, 21.48]
mask_vision:  0.36063703894615173
mask_language:  0.2698766887187958
mask_attn:  0.1072048619389534
mask_mlp:  0.33968839049339294
Creating model for training
VisionTransformerを作成
Start training
KD:False
Train Epoch: [0]  [    0/23614]  eta: 5:15:30  lr: 0.00001000  loss: 7.0931  time: 0.8017  data: 0.2171  max mem: 55126
KD is False
Train Epoch: [0]  [ 5000/23614]  eta: 2:37:53  lr: 0.00001000  loss: 3.5808  time: 0.5167  data: 0.0001  max mem: 55126
Train Epoch: [0]  [10000/23614]  eta: 1:55:34  lr: 0.00001000  loss: 3.9543  time: 0.5037  data: 0.0001  max mem: 55126
Train Epoch: [0]  [15000/23614]  eta: 1:12:57  lr: 0.00001000  loss: 4.0642  time: 0.5172  data: 0.0001  max mem: 55126
Train Epoch: [0]  [20000/23614]  eta: 0:30:35  lr: 0.00001000  loss: 4.6908  time: 0.5227  data: 0.0001  max mem: 55126
Train Epoch: [0]  [23613/23614]  eta: 0:00:00  lr: 0.00001000  loss: 3.1504  time: 0.5094  data: 0.0004  max mem: 55126
Train Epoch: [0] Total time: 3:20:11 (0.5087 s / it)
Averaged stats: lr: 0.0000  loss: 3.7342
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.1024
Text_CKA_Similarity: 0.5576
Image_Cosine_Similarity: 0.1040
Image_CKA_Similarity: 0.7501
sim_matrix_pearson_correlation: 0.5875
{'txt_r1': 57.92, 'txt_r5': 83.9, 'txt_r10': 90.92, 'txt_r_mean': 77.58, 'img_r1': 43.670531787285086, 'img_r5': 71.83526589364254, 'img_r10': 81.80327868852459, 'img_r_mean': 65.76969212315073, 'r_mean': 71.67484606157537}
{'txt_r1': 56.78, 'txt_r5': 83.08, 'txt_r10': 89.46, 'txt_r_mean': 76.44, 'img_r1': 42.107157137145144, 'img_r5': 71.20751699320272, 'img_r10': 80.84766093562575, 'img_r_mean': 64.72077835532454, 'r_mean': 70.58038917766227}
LOG:  {'train_lr': '0.000', 'train_loss': '3.734', 'val_txt_r1': 57.92, 'val_txt_r5': 83.9, 'val_txt_r10': 90.92, 'val_txt_r_mean': 77.58, 'val_img_r1': 43.670531787285086, 'val_img_r5': 71.83526589364254, 'val_img_r10': 81.80327868852459, 'val_img_r_mean': 65.76969212315073, 'val_r_mean': 71.67484606157537, 'test_txt_r1': 56.78, 'test_txt_r5': 83.08, 'test_txt_r10': 89.46, 'test_txt_r_mean': 76.44, 'test_img_r1': 42.107157137145144, 'test_img_r5': 71.20751699320272, 'test_img_r10': 80.84766093562575, 'test_img_r_mean': 64.72077835532454, 'test_r_mean': 70.58038917766227, 'epoch': 0, 'best_epoch': 0}
KD:False
Train Epoch: [1]  [    0/23614]  eta: 6:20:56  lr: 0.00000970  loss: 4.5767  time: 0.9679  data: 0.1921  max mem: 55126
KD is False
Train Epoch: [1]  [ 5000/23614]  eta: 2:39:02  lr: 0.00000970  loss: 3.1262  time: 0.4888  data: 0.0001  max mem: 55126
Train Epoch: [1]  [10000/23614]  eta: 1:55:48  lr: 0.00000970  loss: 2.3034  time: 0.5153  data: 0.0001  max mem: 55126
Train Epoch: [1]  [15000/23614]  eta: 1:13:31  lr: 0.00000970  loss: 2.5316  time: 0.5142  data: 0.0001  max mem: 55126
Train Epoch: [1]  [20000/23614]  eta: 0:30:46  lr: 0.00000970  loss: 3.3795  time: 0.4927  data: 0.0001  max mem: 55126
Train Epoch: [1]  [23613/23614]  eta: 0:00:00  lr: 0.00000970  loss: 3.4344  time: 0.4957  data: 0.0006  max mem: 55126
Train Epoch: [1] Total time: 3:21:01 (0.5108 s / it)
Averaged stats: lr: 0.0000  loss: 3.5105
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0989
Text_CKA_Similarity: 0.5133
Image_Cosine_Similarity: 0.1229
Image_CKA_Similarity: 0.7304
sim_matrix_pearson_correlation: 0.5916
{'txt_r1': 59.22, 'txt_r5': 85.02, 'txt_r10': 92.0, 'txt_r_mean': 78.74666666666667, 'img_r1': 44.734106357457016, 'img_r5': 73.29868052778889, 'img_r10': 82.84286285485805, 'img_r_mean': 66.95854991336799, 'r_mean': 72.85260829001733}
{'txt_r1': 59.04, 'txt_r5': 84.08, 'txt_r10': 91.08, 'txt_r_mean': 78.06666666666666, 'img_r1': 43.74250299880048, 'img_r5': 72.65493802479008, 'img_r10': 82.36705317872851, 'img_r_mean': 66.25483140077303, 'r_mean': 72.16074903371984}
LOG:  {'train_lr': '0.000', 'train_loss': '3.510', 'val_txt_r1': 59.22, 'val_txt_r5': 85.02, 'val_txt_r10': 92.0, 'val_txt_r_mean': 78.74666666666667, 'val_img_r1': 44.734106357457016, 'val_img_r5': 73.29868052778889, 'val_img_r10': 82.84286285485805, 'val_img_r_mean': 66.95854991336799, 'val_r_mean': 72.85260829001733, 'test_txt_r1': 59.04, 'test_txt_r5': 84.08, 'test_txt_r10': 91.08, 'test_txt_r_mean': 78.06666666666666, 'test_img_r1': 43.74250299880048, 'test_img_r5': 72.65493802479008, 'test_img_r10': 82.36705317872851, 'test_img_r_mean': 66.25483140077303, 'test_r_mean': 72.16074903371984, 'epoch': 1, 'best_epoch': 1}
KD:False
Train Epoch: [2]  [    0/23614]  eta: 5:52:50  lr: 0.00000883  loss: 3.8641  time: 0.8965  data: 0.1780  max mem: 55126
KD is False
Train Epoch: [2]  [ 5000/23614]  eta: 2:38:12  lr: 0.00000883  loss: 3.8929  time: 0.5105  data: 0.0001  max mem: 55126
Train Epoch: [2]  [10000/23614]  eta: 1:55:04  lr: 0.00000883  loss: 2.8738  time: 0.5138  data: 0.0001  max mem: 55126
Train Epoch: [2]  [15000/23614]  eta: 1:12:46  lr: 0.00000883  loss: 4.2728  time: 0.5112  data: 0.0001  max mem: 55126
Train Epoch: [2]  [20000/23614]  eta: 0:30:29  lr: 0.00000883  loss: 3.1316  time: 0.5175  data: 0.0001  max mem: 55126
Train Epoch: [2]  [23613/23614]  eta: 0:00:00  lr: 0.00000883  loss: 1.8008  time: 0.5061  data: 0.0005  max mem: 55126
Train Epoch: [2] Total time: 3:19:25 (0.5067 s / it)
Averaged stats: lr: 0.0000  loss: 3.2958
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0841
Text_CKA_Similarity: 0.4965
Image_Cosine_Similarity: 0.1117
Image_CKA_Similarity: 0.7095
sim_matrix_pearson_correlation: 0.5536
{'txt_r1': 59.38, 'txt_r5': 85.44, 'txt_r10': 92.06, 'txt_r_mean': 78.96, 'img_r1': 45.08996401439424, 'img_r5': 73.61855257896842, 'img_r10': 83.09476209516194, 'img_r_mean': 67.26775956284153, 'r_mean': 73.11387978142076}
{'txt_r1': 59.32, 'txt_r5': 84.36, 'txt_r10': 91.1, 'txt_r_mean': 78.26, 'img_r1': 44.06637345061975, 'img_r5': 72.97481007596961, 'img_r10': 82.55897640943623, 'img_r_mean': 66.53338664534186, 'r_mean': 72.39669332267093}
LOG:  {'train_lr': '0.000', 'train_loss': '3.296', 'val_txt_r1': 59.38, 'val_txt_r5': 85.44, 'val_txt_r10': 92.06, 'val_txt_r_mean': 78.96, 'val_img_r1': 45.08996401439424, 'val_img_r5': 73.61855257896842, 'val_img_r10': 83.09476209516194, 'val_img_r_mean': 67.26775956284153, 'val_r_mean': 73.11387978142076, 'test_txt_r1': 59.32, 'test_txt_r5': 84.36, 'test_txt_r10': 91.1, 'test_txt_r_mean': 78.26, 'test_img_r1': 44.06637345061975, 'test_img_r5': 72.97481007596961, 'test_img_r10': 82.55897640943623, 'test_img_r_mean': 66.53338664534186, 'test_r_mean': 72.39669332267093, 'epoch': 2, 'best_epoch': 2}
KD:False
Train Epoch: [3]  [    0/23614]  eta: 5:37:53  lr: 0.00000750  loss: 4.3535  time: 0.8585  data: 0.1996  max mem: 55126
KD is False
Train Epoch: [3]  [ 5000/23614]  eta: 2:37:16  lr: 0.00000750  loss: 3.7701  time: 0.5079  data: 0.0001  max mem: 55126
Train Epoch: [3]  [10000/23614]  eta: 1:55:14  lr: 0.00000750  loss: 2.8819  time: 0.4711  data: 0.0001  max mem: 55126
Train Epoch: [3]  [15000/23614]  eta: 1:12:53  lr: 0.00000750  loss: 2.5800  time: 0.4884  data: 0.0001  max mem: 55126
Train Epoch: [3]  [20000/23614]  eta: 0:30:35  lr: 0.00000750  loss: 2.3897  time: 0.5184  data: 0.0001  max mem: 55126
Train Epoch: [3]  [23613/23614]  eta: 0:00:00  lr: 0.00000750  loss: 1.9976  time: 0.5083  data: 0.0006  max mem: 55126
Train Epoch: [3] Total time: 3:20:00 (0.5082 s / it)
Averaged stats: lr: 0.0000  loss: 3.1089
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0834
Text_CKA_Similarity: 0.4893
Image_Cosine_Similarity: 0.1087
Image_CKA_Similarity: 0.6973
sim_matrix_pearson_correlation: 0.5665
{'txt_r1': 61.22, 'txt_r5': 86.34, 'txt_r10': 92.44, 'txt_r_mean': 80.0, 'img_r1': 46.38144742103159, 'img_r5': 74.45421831267493, 'img_r10': 83.65853658536585, 'img_r_mean': 68.16473410635746, 'r_mean': 74.08236705317873}
{'txt_r1': 59.96, 'txt_r5': 84.66, 'txt_r10': 91.88, 'txt_r_mean': 78.83333333333333, 'img_r1': 45.641743302678925, 'img_r5': 74.17832866853259, 'img_r10': 83.47461015593763, 'img_r_mean': 67.76489404238305, 'r_mean': 73.29911368785818}
LOG:  {'train_lr': '0.000', 'train_loss': '3.109', 'val_txt_r1': 61.22, 'val_txt_r5': 86.34, 'val_txt_r10': 92.44, 'val_txt_r_mean': 80.0, 'val_img_r1': 46.38144742103159, 'val_img_r5': 74.45421831267493, 'val_img_r10': 83.65853658536585, 'val_img_r_mean': 68.16473410635746, 'val_r_mean': 74.08236705317873, 'test_txt_r1': 59.96, 'test_txt_r5': 84.66, 'test_txt_r10': 91.88, 'test_txt_r_mean': 78.83333333333333, 'test_img_r1': 45.641743302678925, 'test_img_r5': 74.17832866853259, 'test_img_r10': 83.47461015593763, 'test_img_r_mean': 67.76489404238305, 'test_r_mean': 73.29911368785818, 'epoch': 3, 'best_epoch': 3}
KD:False
Train Epoch: [4]  [    0/23614]  eta: 5:56:11  lr: 0.00000587  loss: 2.1671  time: 0.9050  data: 0.1947  max mem: 55126
KD is False
Train Epoch: [4]  [ 5000/23614]  eta: 2:37:48  lr: 0.00000587  loss: 2.9563  time: 0.5193  data: 0.0001  max mem: 55126
Train Epoch: [4]  [10000/23614]  eta: 1:55:23  lr: 0.00000587  loss: 3.1797  time: 0.4834  data: 0.0001  max mem: 55126
Train Epoch: [4]  [15000/23614]  eta: 1:13:01  lr: 0.00000587  loss: 3.5768  time: 0.5112  data: 0.0001  max mem: 55126
Train Epoch: [4]  [20000/23614]  eta: 0:30:39  lr: 0.00000587  loss: 3.0219  time: 0.5079  data: 0.0001  max mem: 55126
Train Epoch: [4]  [23613/23614]  eta: 0:00:00  lr: 0.00000587  loss: 1.8772  time: 0.5036  data: 0.0006  max mem: 55126
Train Epoch: [4] Total time: 3:20:19 (0.5090 s / it)
Averaged stats: lr: 0.0000  loss: 2.9222
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0828
Text_CKA_Similarity: 0.4667
Image_Cosine_Similarity: 0.1022
Image_CKA_Similarity: 0.6910
sim_matrix_pearson_correlation: 0.5672
{'txt_r1': 61.48, 'txt_r5': 86.7, 'txt_r10': 93.2, 'txt_r_mean': 80.46, 'img_r1': 46.58536585365854, 'img_r5': 74.70611755297881, 'img_r10': 84.12235105957618, 'img_r_mean': 68.4712781554045, 'r_mean': 74.46563907770225}
{'txt_r1': 61.54, 'txt_r5': 85.88, 'txt_r10': 92.12, 'txt_r_mean': 79.84666666666666, 'img_r1': 46.141543382646944, 'img_r5': 74.21431427429029, 'img_r10': 83.64254298280687, 'img_r_mean': 67.99946687991469, 'r_mean': 73.92306677329069}
LOG:  {'train_lr': '0.000', 'train_loss': '2.922', 'val_txt_r1': 61.48, 'val_txt_r5': 86.7, 'val_txt_r10': 93.2, 'val_txt_r_mean': 80.46, 'val_img_r1': 46.58536585365854, 'val_img_r5': 74.70611755297881, 'val_img_r10': 84.12235105957618, 'val_img_r_mean': 68.4712781554045, 'val_r_mean': 74.46563907770225, 'test_txt_r1': 61.54, 'test_txt_r5': 85.88, 'test_txt_r10': 92.12, 'test_txt_r_mean': 79.84666666666666, 'test_img_r1': 46.141543382646944, 'test_img_r5': 74.21431427429029, 'test_img_r10': 83.64254298280687, 'test_img_r_mean': 67.99946687991469, 'test_r_mean': 73.92306677329069, 'epoch': 4, 'best_epoch': 4}
KD:False
Train Epoch: [5]  [    0/23614]  eta: 5:50:47  lr: 0.00000413  loss: 2.7054  time: 0.8913  data: 0.2525  max mem: 55126
KD is False
Train Epoch: [5]  [ 5000/23614]  eta: 2:38:31  lr: 0.00000413  loss: 3.0947  time: 0.5164  data: 0.0001  max mem: 55126
Train Epoch: [5]  [10000/23614]  eta: 1:55:36  lr: 0.00000413  loss: 1.9536  time: 0.5164  data: 0.0001  max mem: 55126
Train Epoch: [5]  [15000/23614]  eta: 1:13:13  lr: 0.00000413  loss: 2.7096  time: 0.5125  data: 0.0001  max mem: 55126
Train Epoch: [5]  [20000/23614]  eta: 0:30:45  lr: 0.00000413  loss: 3.0760  time: 0.5202  data: 0.0001  max mem: 55126
Train Epoch: [5]  [23613/23614]  eta: 0:00:00  lr: 0.00000413  loss: 2.4558  time: 0.4918  data: 0.0006  max mem: 55126
Train Epoch: [5] Total time: 3:20:39 (0.5098 s / it)
Averaged stats: lr: 0.0000  loss: 2.7425
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0922
Text_CKA_Similarity: 0.4450
Image_Cosine_Similarity: 0.0955
Image_CKA_Similarity: 0.6658
sim_matrix_pearson_correlation: 0.5496
{'txt_r1': 63.2, 'txt_r5': 87.42, 'txt_r10': 93.48, 'txt_r_mean': 81.36666666666667, 'img_r1': 47.385045981607355, 'img_r5': 75.3218712514994, 'img_r10': 84.43822471011596, 'img_r_mean': 69.0483806477409, 'r_mean': 75.20752365720378}
{'txt_r1': 61.58, 'txt_r5': 86.28, 'txt_r10': 92.92, 'txt_r_mean': 80.26, 'img_r1': 46.70531787285086, 'img_r5': 75.13794482207118, 'img_r10': 84.05037984806077, 'img_r_mean': 68.63121418099426, 'r_mean': 74.44560709049713}
LOG:  {'train_lr': '0.000', 'train_loss': '2.743', 'val_txt_r1': 63.2, 'val_txt_r5': 87.42, 'val_txt_r10': 93.48, 'val_txt_r_mean': 81.36666666666667, 'val_img_r1': 47.385045981607355, 'val_img_r5': 75.3218712514994, 'val_img_r10': 84.43822471011596, 'val_img_r_mean': 69.0483806477409, 'val_r_mean': 75.20752365720378, 'test_txt_r1': 61.58, 'test_txt_r5': 86.28, 'test_txt_r10': 92.92, 'test_txt_r_mean': 80.26, 'test_img_r1': 46.70531787285086, 'test_img_r5': 75.13794482207118, 'test_img_r10': 84.05037984806077, 'test_img_r_mean': 68.63121418099426, 'test_r_mean': 74.44560709049713, 'epoch': 5, 'best_epoch': 5}
KD:False
Train Epoch: [6]  [    0/23614]  eta: 5:47:51  lr: 0.00000250  loss: 3.9780  time: 0.8839  data: 0.2443  max mem: 55126
KD is False
Train Epoch: [6]  [ 5000/23614]  eta: 2:38:19  lr: 0.00000250  loss: 1.3635  time: 0.5103  data: 0.0001  max mem: 55126
Train Epoch: [6]  [10000/23614]  eta: 1:55:59  lr: 0.00000250  loss: 3.9426  time: 0.5209  data: 0.0001  max mem: 55126
Train Epoch: [6]  [15000/23614]  eta: 1:13:23  lr: 0.00000250  loss: 2.0414  time: 0.5109  data: 0.0001  max mem: 55126
Train Epoch: [6]  [20000/23614]  eta: 0:30:45  lr: 0.00000250  loss: 2.7360  time: 0.4962  data: 0.0001  max mem: 55126
Train Epoch: [6]  [23613/23614]  eta: 0:00:00  lr: 0.00000250  loss: 2.4079  time: 0.4883  data: 0.0006  max mem: 55126
Train Epoch: [6] Total time: 3:20:50 (0.5103 s / it)
Averaged stats: lr: 0.0000  loss: 2.5752
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
Computing features for evaluation...
num_text 25010
texts type <class 'list'>
num_images 79
num_sims_matrix_log_copy float32
plot_sims_matrix_log_copy shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([100, 500])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([50, 250])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
limited_sims_matrix_log_copy shape torch.Size([10, 50])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape cosine similarity matrix
sims_matrix shape torch.Size([5000, 25010])
sims_matrix_log shape torch.Size([5000, 25010])
min_val 3.670274600153789e-05
max_val 4.955108670401387e-05
check shape
teacher_text_embeds shape torch.Size([25010, 768])
teacher_image_embeds shape torch.Size([5000, 768])
teacher_sims_matrix shape torch.Size([5000, 25010])
text_embeds_log shape torch.Size([25010, 768])
image_embeds_log shape torch.Size([5000, 768])
sims_matrix_log shape torch.Size([5000, 25010])
Text_Cosine_Similarity: 0.0752
Text_CKA_Similarity: 0.4146
Image_Cosine_Similarity: 0.0969
Image_CKA_Similarity: 0.6507
sim_matrix_pearson_correlation: 0.5438
{'txt_r1': 63.24, 'txt_r5': 87.64, 'txt_r10': 93.34, 'txt_r_mean': 81.40666666666667, 'img_r1': 48.36465413834466, 'img_r5': 75.8296681327469, 'img_r10': 84.93802479008397, 'img_r_mean': 69.71078235372518, 'r_mean': 75.55872451019593}
{'txt_r1': 62.16, 'txt_r5': 86.8, 'txt_r10': 92.96, 'txt_r_mean': 80.63999999999999, 'img_r1': 47.40903638544582, 'img_r5': 75.10995601759296, 'img_r10': 84.05837664934026, 'img_r_mean': 68.85912301745968, 'r_mean': 74.74956150872984}
LOG:  {'train_lr': '0.000', 'train_loss': '2.575', 'val_txt_r1': 63.24, 'val_txt_r5': 87.64, 'val_txt_r10': 93.34, 'val_txt_r_mean': 81.40666666666667, 'val_img_r1': 48.36465413834466, 'val_img_r5': 75.8296681327469, 'val_img_r10': 84.93802479008397, 'val_img_r_mean': 69.71078235372518, 'val_r_mean': 75.55872451019593, 'test_txt_r1': 62.16, 'test_txt_r5': 86.8, 'test_txt_r10': 92.96, 'test_txt_r_mean': 80.63999999999999, 'test_img_r1': 47.40903638544582, 'test_img_r5': 75.10995601759296, 'test_img_r10': 84.05837664934026, 'test_img_r_mean': 68.85912301745968, 'test_r_mean': 74.74956150872984, 'epoch': 6, 'best_epoch': 6}
KD:False
Train Epoch: [7]  [    0/23614]  eta: 5:34:07  lr: 0.00000117  loss: 2.3082  time: 0.8490  data: 0.2002  max mem: 55126
KD is False
Train Epoch: [7]  [ 5000/23614]  eta: 2:37:04  lr: 0.00000117  loss: 2.9898  time: 0.5206  data: 0.0001  max mem: 55126
Train Epoch: [7]  [10000/23614]  eta: 1:55:15  lr: 0.00000117  loss: 2.5729  time: 0.4952  data: 0.0001  max mem: 55126
